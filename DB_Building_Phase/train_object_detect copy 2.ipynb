{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_from_img(img_path, model):\n",
    "    img_cv2 = cv2.imread(img_path)\n",
    "    img_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "    results = model.predict(source=img_cv2, conf=0.5, half=True)\n",
    "\n",
    "    hist = f\"C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/{img_id}_hist.txt\"\n",
    "\n",
    "    objs = []\n",
    "\n",
    "    if results[0].boxes is None or len(results[0].boxes) == 0:\n",
    "        return None\n",
    "\n",
    "    print (len(results[0].boxes))\n",
    "    for track_id, box in enumerate(results[0].boxes):\n",
    "        print(f\"Processing {img_id} - {track_id + 1}...\")\n",
    "        class_label = results[0].names[int(box.cls)]\n",
    "\n",
    "        obj_id = f\"{img_id}_{track_id + 1}\"\n",
    "\n",
    "        obj_info = {\n",
    "            \"ObjID\": obj_id,\n",
    "            \"ImgID\": img_id,\n",
    "            \"Class\": class_label,\n",
    "            \"Feature\": hist\n",
    "        }\n",
    "        objs.append(obj_info)\n",
    "\n",
    "    return objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj_img_to_bovw(img_files, model):\n",
    "    batch_size = 1000\n",
    "    for start_index in range(0, len(img_files), batch_size):\n",
    "        end_index = min(start_index + batch_size, len(img_files))\n",
    "        batch_files = img_files[start_index:end_index]\n",
    "        results = []\n",
    "        for img_path in batch_files:\n",
    "            print(f\"Processing {img_path}...\")\n",
    "            objs = get_item_from_img(img_path, model)\n",
    "            if objs:\n",
    "                results.extend(objs)\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        # Process results or save to file\n",
    "        print(f\"Processed batch {start_index // batch_size + 1}\")\n",
    "        \n",
    "        json_file_path = \"./bovw/new_json/list_bovw_newsmol.json\"\n",
    "        if os.path.exists(json_file_path):\n",
    "            with open(json_file_path, \"r\") as f:\n",
    "                try:\n",
    "                    existing_data = json.load(f)\n",
    "                except json.JSONDecodeError:\n",
    "                    existing_data = []\n",
    "        else:\n",
    "            existing_data = []\n",
    "\n",
    "        # Append new results to existing data\n",
    "        existing_data.extend(results)\n",
    "\n",
    "        with open(json_file_path, \"w\") as f:\n",
    "            json.dump(existing_data, f, indent=4)\n",
    "\n",
    "        # Clear memory\n",
    "        del results\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 63.7ms\n",
      "Speed: 8.9ms preprocess, 63.7ms inference, 37.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 3.5ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 50.2ms\n",
      "Speed: 3.0ms preprocess, 50.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.3ms\n",
      "Speed: 2.0ms preprocess, 49.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.6ms\n",
      "Speed: 2.0ms preprocess, 49.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.4ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.2ms\n",
      "Speed: 3.0ms preprocess, 46.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.0ms\n",
      "Speed: 3.5ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 3.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.1ms\n",
      "Speed: 5.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.6ms\n",
      "Speed: 3.3ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.2ms\n",
      "Speed: 4.0ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 1.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 1.9ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 50.9ms\n",
      "Speed: 2.0ms preprocess, 50.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.4ms\n",
      "Speed: 2.5ms preprocess, 46.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 64.3ms\n",
      "Speed: 4.0ms preprocess, 64.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.2ms\n",
      "Speed: 6.5ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.6ms\n",
      "Speed: 3.5ms preprocess, 45.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.3ms\n",
      "Speed: 3.0ms preprocess, 45.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.2ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.1ms\n",
      "Speed: 3.1ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.6ms\n",
      "Speed: 3.0ms preprocess, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.0ms\n",
      "Speed: 1.5ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.5ms\n",
      "Speed: 3.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.6ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 1.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 3.0ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 3.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.3ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 4.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.3ms\n",
      "Speed: 2.5ms preprocess, 46.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 3.0ms preprocess, 47.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.0ms preprocess, 47.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.3ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.5ms\n",
      "Speed: 1.9ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.0ms\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.8ms\n",
      "Speed: 4.0ms preprocess, 46.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.5ms\n",
      "Speed: 2.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 1.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 3.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.1ms\n",
      "Speed: 1.5ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 3.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 4.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.0ms\n",
      "Speed: 3.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.8ms\n",
      "Speed: 2.0ms preprocess, 46.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 3.0ms preprocess, 47.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 3.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.8ms\n",
      "Speed: 1.0ms preprocess, 46.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 3.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 1.5ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.5ms\n",
      "Speed: 2.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.5ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.0ms\n",
      "Speed: 2.5ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 4.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 4.0ms preprocess, 47.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.6ms\n",
      "Speed: 2.5ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.2ms\n",
      "Speed: 2.5ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.3ms\n",
      "Speed: 4.0ms preprocess, 46.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 3.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.8ms\n",
      "Speed: 1.0ms preprocess, 46.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.0ms\n",
      "Speed: 3.1ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.5ms preprocess, 46.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 4.5ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.5ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 1.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 3.5ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.0ms\n",
      "Speed: 3.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.5ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.1ms\n",
      "Speed: 4.1ms preprocess, 44.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.4ms\n",
      "Speed: 3.0ms preprocess, 46.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.1ms\n",
      "Speed: 3.0ms preprocess, 46.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.5ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.5ms preprocess, 48.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 1.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 1.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.8ms\n",
      "Speed: 2.0ms preprocess, 46.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.5ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.5ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 3.5ms preprocess, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.5ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 1.5ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 1.0ms preprocess, 47.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.5ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.9ms preprocess, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.5ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.8ms\n",
      "Speed: 2.0ms preprocess, 46.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 3.5ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 3.5ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 3.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.5ms preprocess, 47.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 4.0ms preprocess, 48.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.4ms\n",
      "Speed: 5.5ms preprocess, 45.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.3ms\n",
      "Speed: 4.0ms preprocess, 45.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.5ms preprocess, 47.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.0ms\n",
      "Speed: 5.5ms preprocess, 46.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.3ms\n",
      "Speed: 3.0ms preprocess, 46.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 3.0ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.5ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.5ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 1.9ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 3.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.3ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 1.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 3.0ms preprocess, 47.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.6ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.0ms\n",
      "Speed: 2.5ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.2ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.8ms\n",
      "Speed: 1.0ms preprocess, 46.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 3.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 1.9ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 3.1ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 1.5ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 3.5ms preprocess, 46.7ms inference, 0.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.9ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 2.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.2ms preprocess, 48.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 2.5ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 1.4ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.2ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.9ms\n",
      "Speed: 3.0ms preprocess, 46.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 1.9ms preprocess, 46.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 3.0ms preprocess, 47.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.4ms preprocess, 48.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 4.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.5ms preprocess, 46.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 3.5ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.0ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 5.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.5ms\n",
      "Speed: 2.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.6ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 1.0ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 3.0ms preprocess, 47.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.9ms\n",
      "Speed: 3.0ms preprocess, 46.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 1.5ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 1.0ms preprocess, 47.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.5ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 1.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 3.5ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 1.0ms preprocess, 49.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.5ms preprocess, 47.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 3.0ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.1ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.5ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 3.0ms preprocess, 48.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 3.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.4ms preprocess, 47.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.8ms\n",
      "Speed: 2.5ms preprocess, 46.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.5ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.5ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 1.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.4ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 1.5ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.6ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 3.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.5ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.6ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.1ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.1ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.1ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 3.2ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.9ms\n",
      "Speed: 2.0ms preprocess, 48.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.3ms preprocess, 47.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 3.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 3.0ms preprocess, 47.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.9ms preprocess, 48.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.3ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.5ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.5ms preprocess, 46.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 3.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 2.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.5ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 3.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 2.6ms preprocess, 47.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 3.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 3.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 3.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.5ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 3.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.5ms preprocess, 47.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 1.0ms preprocess, 47.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.5ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.4ms\n",
      "Speed: 4.0ms preprocess, 46.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.5ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.5ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.2ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.2ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 3.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.5ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.9ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 2.4ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 4.0ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 1.5ms preprocess, 46.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.1ms\n",
      "Speed: 2.5ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.3ms\n",
      "Speed: 3.0ms preprocess, 46.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.5ms\n",
      "Speed: 2.0ms preprocess, 46.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 1.0ms preprocess, 48.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 1.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 1.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.5ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.5ms\n",
      "Speed: 1.0ms preprocess, 49.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 2.0ms preprocess, 48.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 1.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.6ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.0ms\n",
      "Speed: 1.6ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 1.0ms preprocess, 48.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 1.0ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.6ms\n",
      "Speed: 2.5ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.1ms preprocess, 48.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.1ms preprocess, 47.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.8ms\n",
      "Speed: 2.5ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.5ms preprocess, 47.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.1ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 1.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 1.9ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.2ms\n",
      "Speed: 2.1ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.3ms\n",
      "Speed: 3.0ms preprocess, 45.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.2ms\n",
      "Speed: 3.1ms preprocess, 46.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 1.5ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 2.0ms preprocess, 48.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.5ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 2.5ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 1.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.4ms\n",
      "Speed: 3.0ms preprocess, 46.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 1.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.5ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 3.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 1.6ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.5ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 1.5ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 4.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.5ms preprocess, 47.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.5ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.3ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.5ms preprocess, 47.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 3.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.5ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.5ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 1.0ms preprocess, 48.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 3.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.2ms preprocess, 48.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 3.5ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.5ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.5ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.1ms preprocess, 47.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.0ms\n",
      "Speed: 1.5ms preprocess, 49.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 2.0ms preprocess, 48.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.1ms preprocess, 47.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.1ms preprocess, 47.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.9ms\n",
      "Speed: 3.3ms preprocess, 46.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.3ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.9ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.5ms preprocess, 47.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.3ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 3.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.1ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.5ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.5ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 3.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 3.1ms preprocess, 47.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.9ms\n",
      "Speed: 2.0ms preprocess, 48.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.2ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 1.9ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 1.5ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 1.0ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.5ms preprocess, 47.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.5ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.4ms preprocess, 48.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.1ms preprocess, 47.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 1.9ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 46 Accordions, 3 Airplanes, 1 Antelope, 2 Backpacks, 1 Baked goods, 16 Baseball bats, 22 Beers, 15 Bottles, 138 Boys, 2 Cheeses, 15 Coats, 1 Coffee table, 34 Girls, 2 Goggless, 2 Human arms, 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 95.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.1ms\n",
      "Speed: 3.0ms preprocess, 44.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 3.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.5ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.5ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 1.9ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 1.0ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 1.6ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.7ms\n",
      "Speed: 2.0ms preprocess, 49.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 3.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.5ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.9ms\n",
      "Speed: 2.0ms preprocess, 48.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 2.0ms preprocess, 48.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 3.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 1.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.5ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 1.0ms preprocess, 48.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.5ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 3.0ms preprocess, 48.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.5ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 4.0ms preprocess, 46.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.9ms\n",
      "Speed: 3.0ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.1ms preprocess, 47.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 1.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.3ms preprocess, 47.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 3.5ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.1ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 3.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.4ms\n",
      "Speed: 3.2ms preprocess, 45.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.4ms\n",
      "Speed: 2.5ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.5ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.7ms\n",
      "Speed: 2.1ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.5ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 1.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.7ms\n",
      "Speed: 2.2ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.1ms\n",
      "Speed: 2.5ms preprocess, 46.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 3.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.7ms\n",
      "Speed: 1.4ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 1.5ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.6ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 1.0ms preprocess, 49.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 3.0ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.1ms preprocess, 47.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.5ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.0ms preprocess, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 1.9ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.2ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.9ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 3.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 1.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Airplane, 45.4ms\n",
      "Speed: 4.0ms preprocess, 45.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Airplane, 45.0ms\n",
      "Speed: 2.5ms preprocess, 45.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Airplane, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.6ms\n",
      "Speed: 2.5ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.0ms preprocess, 47.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Airplane, 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.2ms\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.3ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Airplane, 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.4ms\n",
      "Speed: 1.9ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.6ms preprocess, 48.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.5ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 3.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.8ms\n",
      "Speed: 3.0ms preprocess, 46.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.6ms preprocess, 47.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Airplane, 46.9ms\n",
      "Speed: 3.0ms preprocess, 46.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.7ms\n",
      "Speed: 3.2ms preprocess, 43.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 1.0ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.5ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 2.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 3.3ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.5ms preprocess, 47.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 3.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.5ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 3.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.5ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 3.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 2.0ms preprocess, 48.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 1.0ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.5ms\n",
      "Speed: 1.0ms preprocess, 49.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 1.5ms preprocess, 47.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 3.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 3.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.5ms preprocess, 47.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 3.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.5ms preprocess, 47.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.3ms\n",
      "Speed: 2.5ms preprocess, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.6ms\n",
      "Speed: 2.0ms preprocess, 49.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 2.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 3.0ms preprocess, 47.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 1.0ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Laptop, 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Laptop, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Laptop, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Laptop, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.2ms\n",
      "Speed: 3.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.9ms\n",
      "Speed: 2.0ms preprocess, 48.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.5ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 3.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.5ms preprocess, 47.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 1.0ms preprocess, 48.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.5ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.5ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 3.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 3.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.5ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.5ms\n",
      "Speed: 3.0ms preprocess, 49.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 2.0ms preprocess, 48.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 3.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 2.2ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.5ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.5ms preprocess, 48.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 4.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.5ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 2.0ms preprocess, 48.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.6ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 4.0ms preprocess, 47.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.5ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.9ms\n",
      "Speed: 2.0ms preprocess, 48.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.3ms preprocess, 47.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 2.0ms preprocess, 48.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.5ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 4.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.5ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 2.5ms preprocess, 49.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.2ms preprocess, 47.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.9ms\n",
      "Speed: 2.0ms preprocess, 48.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.6ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 3.0ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 2.0ms preprocess, 48.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.5ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.5ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.5ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 2.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 3.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.4ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.4ms\n",
      "Speed: 1.0ms preprocess, 49.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 3.1ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fountain, 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 2.3ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 47.6ms\n",
      "Speed: 3.0ms preprocess, 47.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.5ms\n",
      "Speed: 2.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 43.6ms\n",
      "Speed: 3.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.0ms\n",
      "Speed: 2.1ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 46.1ms\n",
      "Speed: 2.6ms preprocess, 46.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.3ms\n",
      "Speed: 2.0ms preprocess, 44.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.1ms\n",
      "Speed: 2.5ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 43.6ms\n",
      "Speed: 3.0ms preprocess, 43.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.6ms\n",
      "Speed: 3.5ms preprocess, 45.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.1ms\n",
      "Speed: 1.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.5ms\n",
      "Speed: 3.0ms preprocess, 44.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.5ms\n",
      "Speed: 2.5ms preprocess, 44.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.6ms\n",
      "Speed: 3.0ms preprocess, 44.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.5ms\n",
      "Speed: 1.9ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.5ms\n",
      "Speed: 1.9ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.1ms\n",
      "Speed: 3.5ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.5ms\n",
      "Speed: 2.0ms preprocess, 45.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.0ms\n",
      "Speed: 2.5ms preprocess, 45.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.2ms\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.5ms\n",
      "Speed: 3.0ms preprocess, 45.5ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.0ms\n",
      "Speed: 3.2ms preprocess, 45.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.3ms\n",
      "Speed: 1.9ms preprocess, 44.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.7ms\n",
      "Speed: 2.5ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.7ms\n",
      "Speed: 3.0ms preprocess, 44.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.2ms\n",
      "Speed: 1.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.9ms\n",
      "Speed: 3.0ms preprocess, 44.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 46.4ms\n",
      "Speed: 3.0ms preprocess, 46.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.5ms\n",
      "Speed: 2.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.1ms\n",
      "Speed: 2.5ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.7ms\n",
      "Speed: 3.1ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.5ms\n",
      "Speed: 2.5ms preprocess, 44.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.7ms\n",
      "Speed: 1.9ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.6ms\n",
      "Speed: 3.0ms preprocess, 44.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.7ms\n",
      "Speed: 3.0ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.3ms\n",
      "Speed: 3.5ms preprocess, 45.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.1ms\n",
      "Speed: 2.6ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.7ms\n",
      "Speed: 3.0ms preprocess, 45.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.7ms\n",
      "Speed: 2.6ms preprocess, 44.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.6ms\n",
      "Speed: 3.0ms preprocess, 45.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.2ms\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.3ms\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.8ms\n",
      "Speed: 1.0ms preprocess, 44.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.3ms\n",
      "Speed: 2.0ms preprocess, 44.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.1ms\n",
      "Speed: 2.1ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.6ms\n",
      "Speed: 2.5ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.1ms\n",
      "Speed: 1.9ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.3ms\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.8ms\n",
      "Speed: 2.5ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.3ms\n",
      "Speed: 2.0ms preprocess, 44.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.2ms\n",
      "Speed: 3.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.4ms\n",
      "Speed: 3.0ms preprocess, 44.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 148 Bathroom accessorys, 20 Beers, 112 Bottles, 1 Chopsticks, 1 Fast food, 18 Kitchen appliances, 44.9ms\n",
      "Speed: 3.0ms preprocess, 44.9ms inference, 34.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 43.9ms\n",
      "Speed: 2.0ms preprocess, 43.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.1ms\n",
      "Speed: 2.5ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.3ms\n",
      "Speed: 3.0ms preprocess, 45.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.6ms\n",
      "Speed: 3.0ms preprocess, 45.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.2ms\n",
      "Speed: 2.5ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.0ms\n",
      "Speed: 4.0ms preprocess, 45.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 45.6ms\n",
      "Speed: 2.3ms preprocess, 45.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 44.3ms\n",
      "Speed: 2.0ms preprocess, 44.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.6ms\n",
      "Speed: 3.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.4ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 3.0ms preprocess, 48.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.9ms\n",
      "Speed: 2.0ms preprocess, 48.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.0ms\n",
      "Speed: 1.0ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 2.0ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.6ms preprocess, 48.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.9ms\n",
      "Speed: 2.6ms preprocess, 48.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.0ms preprocess, 47.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.3ms\n",
      "Speed: 2.2ms preprocess, 47.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.5ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.5ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.7ms\n",
      "Speed: 3.0ms preprocess, 45.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.8ms\n",
      "Speed: 2.0ms preprocess, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.1ms\n",
      "Speed: 3.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.6ms\n",
      "Speed: 4.0ms preprocess, 45.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.6ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 54.0ms\n",
      "Speed: 4.0ms preprocess, 54.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 55.1ms\n",
      "Speed: 7.5ms preprocess, 55.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 1.0ms preprocess, 47.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.0ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.9ms\n",
      "Speed: 2.0ms preprocess, 48.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.4ms\n",
      "Speed: 2.5ms preprocess, 46.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 1.0ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 2.0ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.0ms\n",
      "Speed: 3.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 3.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 3.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 2.0ms preprocess, 48.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 3.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.5ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 2.0ms preprocess, 49.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.5ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 2.5ms preprocess, 49.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 1.0ms preprocess, 49.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 1.5ms preprocess, 48.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 3.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.1ms preprocess, 48.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 3.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.2ms preprocess, 48.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 3.0ms preprocess, 48.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.5ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.0ms preprocess, 47.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 3.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 3.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.0ms\n",
      "Speed: 2.0ms preprocess, 49.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.1ms\n",
      "Speed: 3.5ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 2.0ms preprocess, 48.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.8ms\n",
      "Speed: 3.0ms preprocess, 46.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.0ms preprocess, 48.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.2ms\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.5ms preprocess, 47.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 1.0ms preprocess, 48.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.6ms\n",
      "Speed: 2.0ms preprocess, 48.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.4ms\n",
      "Speed: 3.0ms preprocess, 48.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.3ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 2.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.2ms\n",
      "Speed: 3.0ms preprocess, 48.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.5ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 1.0ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.4ms\n",
      "Speed: 2.0ms preprocess, 49.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.1ms\n",
      "Speed: 2.0ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.5ms\n",
      "Speed: 2.2ms preprocess, 48.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.7ms\n",
      "Speed: 1.0ms preprocess, 49.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.6ms\n",
      "Speed: 1.0ms preprocess, 49.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.3ms\n",
      "Speed: 2.5ms preprocess, 49.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.6ms\n",
      "Speed: 1.0ms preprocess, 49.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Flower, 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 43.6ms\n",
      "Speed: 3.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 49.8ms\n",
      "Speed: 2.0ms preprocess, 49.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.7ms\n",
      "Speed: 2.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.3ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.8ms\n",
      "Speed: 3.0ms preprocess, 48.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 48.7ms\n",
      "Speed: 2.0ms preprocess, 48.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 45.2ms\n",
      "Speed: 3.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 49.7ms\n",
      "Speed: 1.0ms preprocess, 49.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 45.4ms\n",
      "Speed: 3.0ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 47.6ms\n",
      "Speed: 3.0ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 48.4ms\n",
      "Speed: 3.0ms preprocess, 48.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Clothing, 1 Woman, 45.9ms\n",
      "Speed: 3.0ms preprocess, 45.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 45.8ms\n",
      "Speed: 1.0ms preprocess, 45.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 45.6ms\n",
      "Speed: 3.0ms preprocess, 45.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.6ms\n",
      "Speed: 3.5ms preprocess, 44.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 44.6ms\n",
      "Speed: 3.0ms preprocess, 44.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.1ms\n",
      "Speed: 2.5ms preprocess, 44.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 46.1ms\n",
      "Speed: 1.5ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 2.5ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.2ms\n",
      "Speed: 1.5ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.7ms\n",
      "Speed: 4.0ms preprocess, 45.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 2.5ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.7ms\n",
      "Speed: 2.5ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.8ms\n",
      "Speed: 2.0ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.2ms\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 45.7ms\n",
      "Speed: 3.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 46.0ms\n",
      "Speed: 2.0ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 45.1ms\n",
      "Speed: 1.5ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.2ms\n",
      "Speed: 3.0ms preprocess, 44.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.6ms\n",
      "Speed: 3.0ms preprocess, 45.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 44.6ms\n",
      "Speed: 2.5ms preprocess, 44.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 43.6ms\n",
      "Speed: 3.0ms preprocess, 43.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 44.8ms\n",
      "Speed: 2.0ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 44.5ms\n",
      "Speed: 2.5ms preprocess, 44.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 45.5ms\n",
      "Speed: 3.0ms preprocess, 45.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 46.3ms\n",
      "Speed: 2.0ms preprocess, 46.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 44.0ms\n",
      "Speed: 3.0ms preprocess, 44.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.5ms\n",
      "Speed: 1.5ms preprocess, 45.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 2 Womans, 44.9ms\n",
      "Speed: 3.0ms preprocess, 44.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.5ms\n",
      "Speed: 2.5ms preprocess, 44.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.5ms\n",
      "Speed: 3.5ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.6ms\n",
      "Speed: 1.5ms preprocess, 44.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.7ms\n",
      "Speed: 1.5ms preprocess, 45.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.1ms\n",
      "Speed: 2.1ms preprocess, 44.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.1ms\n",
      "Speed: 2.5ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 43.6ms\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.7ms\n",
      "Speed: 2.1ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.1ms\n",
      "Speed: 3.0ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 45.7ms\n",
      "Speed: 3.0ms preprocess, 45.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Woman, 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 2.5ms preprocess, 45.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.4ms\n",
      "Speed: 2.0ms preprocess, 44.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Womans, 45.2ms\n",
      "Speed: 3.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Womans, 44.9ms\n",
      "Speed: 2.2ms preprocess, 44.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Womans, 45.1ms\n",
      "Speed: 3.6ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Womans, 46.1ms\n",
      "Speed: 2.4ms preprocess, 46.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Womans, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Womans, 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Womans, 45.7ms\n",
      "Speed: 2.5ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 44.8ms\n",
      "Speed: 2.0ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Womans, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Womans, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Womans, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Womans, 44.4ms\n",
      "Speed: 2.5ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Womans, 45.4ms\n",
      "Speed: 3.0ms preprocess, 45.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Dress, 3 Womans, 46.0ms\n",
      "Speed: 2.5ms preprocess, 46.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 44.6ms\n",
      "Speed: 3.0ms preprocess, 44.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 44.8ms\n",
      "Speed: 3.1ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.6ms\n",
      "Speed: 3.0ms preprocess, 45.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.7ms\n",
      "Speed: 1.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.2ms\n",
      "Speed: 2.2ms preprocess, 45.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.6ms\n",
      "Speed: 3.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.2ms\n",
      "Speed: 2.9ms preprocess, 44.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.6ms\n",
      "Speed: 2.2ms preprocess, 45.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 46.0ms\n",
      "Speed: 2.0ms preprocess, 46.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 44.5ms\n",
      "Speed: 3.0ms preprocess, 44.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.5ms\n",
      "Speed: 2.0ms preprocess, 45.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.1ms\n",
      "Speed: 2.5ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.2ms\n",
      "Speed: 4.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.7ms\n",
      "Speed: 1.1ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 44.8ms\n",
      "Speed: 2.0ms preprocess, 44.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 3 Womans, 45.1ms\n",
      "Speed: 1.5ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.0ms\n",
      "Speed: 2.5ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 44.6ms\n",
      "Speed: 4.0ms preprocess, 44.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.2ms\n",
      "Speed: 2.4ms preprocess, 44.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.2ms\n",
      "Speed: 1.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.1ms\n",
      "Speed: 2.5ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 44.8ms\n",
      "Speed: 3.0ms preprocess, 44.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.6ms\n",
      "Speed: 2.5ms preprocess, 45.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.6ms\n",
      "Speed: 3.5ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.1ms\n",
      "Speed: 3.0ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 46.3ms\n",
      "Speed: 1.0ms preprocess, 46.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.8ms\n",
      "Speed: 2.5ms preprocess, 45.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.1ms\n",
      "Speed: 2.1ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.1ms\n",
      "Speed: 3.5ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.1ms\n",
      "Speed: 3.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 44.5ms\n",
      "Speed: 2.5ms preprocess, 44.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 44.2ms\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.1ms\n",
      "Speed: 3.5ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 46.2ms\n",
      "Speed: 1.0ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 46.8ms\n",
      "Speed: 2.0ms preprocess, 46.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.2ms\n",
      "Speed: 2.5ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.3ms\n",
      "Speed: 2.5ms preprocess, 45.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 44.4ms\n",
      "Speed: 2.0ms preprocess, 44.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.3ms\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.4ms\n",
      "Speed: 2.5ms preprocess, 45.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.2ms\n",
      "Speed: 3.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.2ms\n",
      "Speed: 3.0ms preprocess, 44.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 46.1ms\n",
      "Speed: 2.5ms preprocess, 46.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.0ms\n",
      "Speed: 2.9ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 1 Woman, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 1 Woman, 45.3ms\n",
      "Speed: 2.5ms preprocess, 45.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 1 Woman, 45.1ms\n",
      "Speed: 2.5ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 1 Woman, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 1 Woman, 45.2ms\n",
      "Speed: 3.0ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 44.8ms\n",
      "Speed: 1.6ms preprocess, 44.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.1ms\n",
      "Speed: 2.5ms preprocess, 44.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.8ms\n",
      "Speed: 2.5ms preprocess, 45.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 46.1ms\n",
      "Speed: 2.5ms preprocess, 46.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 46.2ms\n",
      "Speed: 2.2ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 1 Woman, 45.3ms\n",
      "Speed: 3.0ms preprocess, 45.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.2ms\n",
      "Speed: 2.5ms preprocess, 44.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.6ms\n",
      "Speed: 2.0ms preprocess, 45.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 1 Woman, 46.7ms\n",
      "Speed: 2.1ms preprocess, 46.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 1 Woman, 45.1ms\n",
      "Speed: 2.0ms preprocess, 45.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 46.0ms\n",
      "Speed: 2.5ms preprocess, 46.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 1 Woman, 45.2ms\n",
      "Speed: 2.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 44.7ms\n",
      "Speed: 2.5ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 Dresss, 2 Womans, 45.1ms\n",
      "Speed: 4.6ms preprocess, 45.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 2 Womans, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 3 Womans, 44.2ms\n",
      "Speed: 2.5ms preprocess, 44.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Dresss, 3 Womans, 45.0ms\n",
      "Speed: 3.0ms preprocess, 45.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 3 Womans, 44.9ms\n",
      "Speed: 3.5ms preprocess, 44.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 3 Womans, 47.5ms\n",
      "Speed: 2.3ms preprocess, 47.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Dresss, 3 Womans, 46.6ms\n",
      "Speed: 2.5ms preprocess, 46.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Dresss, 3 Womans, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 Dresss, 1 Woman, 45.3ms\n",
      "Speed: 2.0ms preprocess, 45.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 Dresss, 1 Woman, 45.6ms\n",
      "Speed: 2.1ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:254\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 254\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:461\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 461\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:130\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:151\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 151\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    152\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 238\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 238\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:346\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:432\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:2379\u001b[0m, in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m-> 2379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m cv2_video\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[1;32m---> 12\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     fname_ \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n\u001b[0;32m     16\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, fname_)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:601\u001b[0m, in \u001b[0;36mModel.track\u001b[1;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# batch-size 1 for tracking in videos\u001b[39;00m\n\u001b[0;32m    600\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:554\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:253\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(im0s)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m--> 253\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprofilers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\ops.py:51\u001b[0m, in \u001b[0;36mProfile.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Stop timing.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart  \u001b[38;5;66;03m# delta-time\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\ops.py:61\u001b[0m, in \u001b[0;36mProfile.time\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get current time.\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda:\n\u001b[1;32m---> 61\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\cuda\\__init__.py:954\u001b[0m, in \u001b[0;36msynchronize\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    952\u001b[0m _lazy_init()\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8x-oiv7\")\n",
    "\n",
    "\n",
    "video_path = \"./video/Close to gray.mp4\"\n",
    "cv2_video = cv2.VideoCapture(video_path)\n",
    "\n",
    "ret = True\n",
    "\n",
    "while ret:\n",
    "    ret, frame = cv2_video.read()\n",
    "    if ret:\n",
    "        results = model.track(source=frame, conf=0.5, persist=True)\n",
    "\n",
    "        fname_ = results[0].plot()\n",
    "\n",
    "        cv2.imshow(\"Frame\", fname_)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cv2_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./img/resize\\0000253ea4ecbf19.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 148.0ms\n",
      "Speed: 6.0ms preprocess, 148.0ms inference, 55.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0000286a5c6a3eb5.jpg...\n",
      "\n",
      "0: 480x640 1 Footwear, 1 Man, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 129.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0000286a5c6a3eb5 - 1...\n",
      "Processing 0000286a5c6a3eb5 - 2...\n",
      "Processing ./img/resize\\00003bfccf5f36c2.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\000045257f66b9e2.jpg...\n",
      "\n",
      "0: 480x640 5 Mans, 7 Womans, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 22.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "12\n",
      "Processing 000045257f66b9e2 - 1...\n",
      "Processing 000045257f66b9e2 - 2...\n",
      "Processing 000045257f66b9e2 - 3...\n",
      "Processing 000045257f66b9e2 - 4...\n",
      "Processing 000045257f66b9e2 - 5...\n",
      "Processing 000045257f66b9e2 - 6...\n",
      "Processing 000045257f66b9e2 - 7...\n",
      "Processing 000045257f66b9e2 - 8...\n",
      "Processing 000045257f66b9e2 - 9...\n",
      "Processing 000045257f66b9e2 - 10...\n",
      "Processing 000045257f66b9e2 - 11...\n",
      "Processing 000045257f66b9e2 - 12...\n",
      "Processing ./img/resize\\0000530c47410921.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00005bf623ff1ac2.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00005bf623ff1ac2 - 1...\n",
      "Processing ./img/resize\\00009cadede2ed69.jpg...\n",
      "\n",
      "0: 480x640 4 Persons, 33.1ms\n",
      "Speed: 1.0ms preprocess, 33.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00009cadede2ed69 - 1...\n",
      "Processing 00009cadede2ed69 - 2...\n",
      "Processing 00009cadede2ed69 - 3...\n",
      "Processing 00009cadede2ed69 - 4...\n",
      "Processing ./img/resize\\0000a54dd13a67a7.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0000d01325742829.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0000d01325742829 - 1...\n",
      "Processing 0000d01325742829 - 2...\n",
      "Processing ./img/resize\\000123034b89f3df.jpg...\n",
      "\n",
      "0: 480x640 1 House, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 000123034b89f3df - 1...\n",
      "Processing ./img/resize\\000132a014faadaf.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 000132a014faadaf - 1...\n",
      "Processing ./img/resize\\000151d10b95b4d3.jpg...\n",
      "\n",
      "0: 480x640 1 Alpaca, 2 Horses, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 000151d10b95b4d3 - 1...\n",
      "Processing 000151d10b95b4d3 - 2...\n",
      "Processing 000151d10b95b4d3 - 3...\n",
      "Processing ./img/resize\\0001771c86cadcd6.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0001771c86cadcd6 - 1...\n",
      "Processing ./img/resize\\0001a2f47097ee27.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0001a2f47097ee27 - 1...\n",
      "Processing 0001a2f47097ee27 - 2...\n",
      "Processing ./img/resize\\0001a646b2a73e94.jpg...\n",
      "\n",
      "0: 480x640 2 Trees, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0001a646b2a73e94 - 1...\n",
      "Processing 0001a646b2a73e94 - 2...\n",
      "Processing ./img/resize\\0001e27f4b156f49.jpg...\n",
      "\n",
      "0: 480x640 3 Clothings, 3 Girls, 3 Human faces, 1 Man, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "10\n",
      "Processing 0001e27f4b156f49 - 1...\n",
      "Processing 0001e27f4b156f49 - 2...\n",
      "Processing 0001e27f4b156f49 - 3...\n",
      "Processing 0001e27f4b156f49 - 4...\n",
      "Processing 0001e27f4b156f49 - 5...\n",
      "Processing 0001e27f4b156f49 - 6...\n",
      "Processing 0001e27f4b156f49 - 7...\n",
      "Processing 0001e27f4b156f49 - 8...\n",
      "Processing 0001e27f4b156f49 - 9...\n",
      "Processing 0001e27f4b156f49 - 10...\n",
      "Processing ./img/resize\\0001ff6b8fc43d43.jpg...\n",
      "\n",
      "0: 480x640 2 Ducks, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0001ff6b8fc43d43 - 1...\n",
      "Processing 0001ff6b8fc43d43 - 2...\n",
      "Processing ./img/resize\\000234a17c124f75.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 2 Tires, 1 Wheel, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 000234a17c124f75 - 1...\n",
      "Processing 000234a17c124f75 - 2...\n",
      "Processing 000234a17c124f75 - 3...\n",
      "Processing 000234a17c124f75 - 4...\n",
      "Processing ./img/resize\\000256419f7c57d8.jpg...\n",
      "\n",
      "0: 480x640 1 Dog, 6 Persons, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 000256419f7c57d8 - 1...\n",
      "Processing 000256419f7c57d8 - 2...\n",
      "Processing 000256419f7c57d8 - 3...\n",
      "Processing 000256419f7c57d8 - 4...\n",
      "Processing 000256419f7c57d8 - 5...\n",
      "Processing 000256419f7c57d8 - 6...\n",
      "Processing 000256419f7c57d8 - 7...\n",
      "Processing ./img/resize\\00028af07aea0ea7.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00028af07aea0ea7 - 1...\n",
      "Processing ./img/resize\\0002ac503f923a95.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0002ac503f923a95 - 1...\n",
      "Processing ./img/resize\\0002c8fa13a79365.jpg...\n",
      "\n",
      "0: 480x640 3 Human faces, 2 Mans, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 0002c8fa13a79365 - 1...\n",
      "Processing 0002c8fa13a79365 - 2...\n",
      "Processing 0002c8fa13a79365 - 3...\n",
      "Processing 0002c8fa13a79365 - 4...\n",
      "Processing 0002c8fa13a79365 - 5...\n",
      "Processing 0002c8fa13a79365 - 6...\n",
      "Processing ./img/resize\\0002d304de1414f0.jpg...\n",
      "\n",
      "0: 480x640 1 Skyscraper, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0002d304de1414f0 - 1...\n",
      "Processing ./img/resize\\0002d5c6b40edcd4.jpg...\n",
      "\n",
      "0: 480x640 2 Skyscrapers, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0002d5c6b40edcd4 - 1...\n",
      "Processing 0002d5c6b40edcd4 - 2...\n",
      "Processing ./img/resize\\00030b8c7652041d.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00030b8c7652041d - 1...\n",
      "Processing ./img/resize\\00033bc5b18e08ad.jpg...\n",
      "\n",
      "0: 480x640 1 House, 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00033bc5b18e08ad - 1...\n",
      "Processing 00033bc5b18e08ad - 2...\n",
      "Processing ./img/resize\\00039573fc999278.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00039573fc999278 - 1...\n",
      "Processing 00039573fc999278 - 2...\n",
      "Processing ./img/resize\\0003dd7fb653f91f.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Picture frame, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0003dd7fb653f91f - 1...\n",
      "Processing 0003dd7fb653f91f - 2...\n",
      "Processing 0003dd7fb653f91f - 3...\n",
      "Processing ./img/resize\\000428518eb0ef73.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 000428518eb0ef73 - 1...\n",
      "Processing ./img/resize\\00047b40c7b664bb.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00047b40c7b664bb - 1...\n",
      "Processing 00047b40c7b664bb - 2...\n",
      "Processing 00047b40c7b664bb - 3...\n",
      "Processing ./img/resize\\00047bab5f8f23b7.jpg...\n",
      "\n",
      "0: 480x640 1 Crocodile, 1 Plant, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00047bab5f8f23b7 - 1...\n",
      "Processing 00047bab5f8f23b7 - 2...\n",
      "Processing ./img/resize\\0004c6db7a801c3f.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 2 Human faces, 1 Wine glass, 1 Woman, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 0004c6db7a801c3f - 1...\n",
      "Processing 0004c6db7a801c3f - 2...\n",
      "Processing 0004c6db7a801c3f - 3...\n",
      "Processing 0004c6db7a801c3f - 4...\n",
      "Processing 0004c6db7a801c3f - 5...\n",
      "Processing ./img/resize\\0004d295cfb46842.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0005133a0bf2ecc1.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 1 Man, 1 Suit, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 0005133a0bf2ecc1 - 1...\n",
      "Processing 0005133a0bf2ecc1 - 2...\n",
      "Processing 0005133a0bf2ecc1 - 3...\n",
      "Processing 0005133a0bf2ecc1 - 4...\n",
      "Processing 0005133a0bf2ecc1 - 5...\n",
      "Processing ./img/resize\\0005151d5347657d.jpg...\n",
      "\n",
      "0: 480x640 2 Buildings, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0005151d5347657d - 1...\n",
      "Processing 0005151d5347657d - 2...\n",
      "Processing ./img/resize\\00056cf5ffe78d8f.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00056cf5ffe78d8f - 1...\n",
      "Processing ./img/resize\\00059a3c8bfda05b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0005ba324cb52a76.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0005f7a1c3ae3c04.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0006578cb5100265.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0006578cb5100265 - 1...\n",
      "Processing ./img/resize\\00066643eae20957.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00066643eae20957 - 1...\n",
      "Processing ./img/resize\\000667c910812879.jpg...\n",
      "\n",
      "0: 480x640 1 Girl, 1 Man, 2 Shortss, 1 Swimwear, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 000667c910812879 - 1...\n",
      "Processing 000667c910812879 - 2...\n",
      "Processing 000667c910812879 - 3...\n",
      "Processing 000667c910812879 - 4...\n",
      "Processing 000667c910812879 - 5...\n",
      "Processing ./img/resize\\00069e311c9a68be.jpg...\n",
      "\n",
      "0: 480x640 1 Girl, 6 Human faces, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00069e311c9a68be - 1...\n",
      "Processing 00069e311c9a68be - 2...\n",
      "Processing 00069e311c9a68be - 3...\n",
      "Processing 00069e311c9a68be - 4...\n",
      "Processing 00069e311c9a68be - 5...\n",
      "Processing 00069e311c9a68be - 6...\n",
      "Processing 00069e311c9a68be - 7...\n",
      "Processing ./img/resize\\00076e166c4645a7.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 2 Wheels, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00076e166c4645a7 - 1...\n",
      "Processing 00076e166c4645a7 - 2...\n",
      "Processing 00076e166c4645a7 - 3...\n",
      "Processing 00076e166c4645a7 - 4...\n",
      "Processing ./img/resize\\000794d648640ade.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0007b266f24a0c12.jpg...\n",
      "\n",
      "0: 480x640 4 Womans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0007b266f24a0c12 - 1...\n",
      "Processing 0007b266f24a0c12 - 2...\n",
      "Processing 0007b266f24a0c12 - 3...\n",
      "Processing 0007b266f24a0c12 - 4...\n",
      "Processing ./img/resize\\0007c5e6448297b8.jpg...\n",
      "\n",
      "0: 480x640 5 Flowers, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 0007c5e6448297b8 - 1...\n",
      "Processing 0007c5e6448297b8 - 2...\n",
      "Processing 0007c5e6448297b8 - 3...\n",
      "Processing 0007c5e6448297b8 - 4...\n",
      "Processing 0007c5e6448297b8 - 5...\n",
      "Processing ./img/resize\\0007c754bc4584e7.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Clothing, 1 Human face, 1 Plant, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0007c754bc4584e7 - 1...\n",
      "Processing 0007c754bc4584e7 - 2...\n",
      "Processing 0007c754bc4584e7 - 3...\n",
      "Processing 0007c754bc4584e7 - 4...\n",
      "Processing ./img/resize\\0007e40c3f905c4a.jpg...\n",
      "\n",
      "0: 480x640 1 House, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0007e40c3f905c4a - 1...\n",
      "Processing ./img/resize\\000819fd2a0433a9.jpg...\n",
      "\n",
      "0: 480x640 4 Bowling equipments, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 000819fd2a0433a9 - 1...\n",
      "Processing 000819fd2a0433a9 - 2...\n",
      "Processing 000819fd2a0433a9 - 3...\n",
      "Processing 000819fd2a0433a9 - 4...\n",
      "Processing ./img/resize\\00081a6248b30e3d.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00081a6248b30e3d - 1...\n",
      "Processing ./img/resize\\0008eee445315885.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0008eee445315885 - 1...\n",
      "Processing ./img/resize\\0008f5ea794738b6.jpg...\n",
      "\n",
      "0: 480x640 1 Window, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0008f5ea794738b6 - 1...\n",
      "Processing ./img/resize\\0008fba87dd4aed2.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 1 Man, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0008fba87dd4aed2 - 1...\n",
      "Processing 0008fba87dd4aed2 - 2...\n",
      "Processing ./img/resize\\0009385220d7720a.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\000955c23be5bb09.jpg...\n",
      "\n",
      "0: 480x640 3 Chairs, 1 Table, 30.1ms\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 000955c23be5bb09 - 1...\n",
      "Processing 000955c23be5bb09 - 2...\n",
      "Processing 000955c23be5bb09 - 3...\n",
      "Processing 000955c23be5bb09 - 4...\n",
      "Processing ./img/resize\\000957f9cbd14b35.jpg...\n",
      "\n",
      "0: 480x640 1 Computer keyboard, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 000957f9cbd14b35 - 1...\n",
      "Processing ./img/resize\\000970c5f9aa6c16.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0009764e44a99385.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0009764e44a99385 - 1...\n",
      "Processing ./img/resize\\000987553e6923f4.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0009d1afd95f318e.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0009d1afd95f318e - 1...\n",
      "Processing 0009d1afd95f318e - 2...\n",
      "Processing ./img/resize\\0009d33f277a43b3.jpg...\n",
      "\n",
      "0: 480x640 2 Trees, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0009d33f277a43b3 - 1...\n",
      "Processing 0009d33f277a43b3 - 2...\n",
      "Processing ./img/resize\\000a05c6c81306c9.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\000a0b93c3852d73.jpg...\n",
      "\n",
      "0: 480x640 3 Houses, 2 Trees, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 000a0b93c3852d73 - 1...\n",
      "Processing 000a0b93c3852d73 - 2...\n",
      "Processing 000a0b93c3852d73 - 3...\n",
      "Processing 000a0b93c3852d73 - 4...\n",
      "Processing 000a0b93c3852d73 - 5...\n",
      "Processing ./img/resize\\000a3de7da1df704.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\000a7b3789b1392e.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 000a7b3789b1392e - 1...\n",
      "Processing ./img/resize\\000aa0232503aafc.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 000aa0232503aafc - 1...\n",
      "Processing ./img/resize\\000aabd8888cfde7.jpg...\n",
      "\n",
      "0: 480x640 1 Table, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 000aabd8888cfde7 - 1...\n",
      "Processing ./img/resize\\000ac3a1acf08904.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 000ac3a1acf08904 - 1...\n",
      "Processing ./img/resize\\000ae28755d2d20e.jpg...\n",
      "\n",
      "0: 480x640 1 Footwear, 1 Man, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 000ae28755d2d20e - 1...\n",
      "Processing 000ae28755d2d20e - 2...\n",
      "Processing ./img/resize\\000b432ae644b679.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 000b432ae644b679 - 1...\n",
      "Processing 000b432ae644b679 - 2...\n",
      "Processing ./img/resize\\000b70a84aab664b.jpg...\n",
      "\n",
      "0: 480x640 1 Guitar, 4 Persons, 30.0ms\n",
      "Speed: 0.9ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 000b70a84aab664b - 1...\n",
      "Processing 000b70a84aab664b - 2...\n",
      "Processing 000b70a84aab664b - 3...\n",
      "Processing 000b70a84aab664b - 4...\n",
      "Processing 000b70a84aab664b - 5...\n",
      "Processing ./img/resize\\000bb846e2629e83.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 000bb846e2629e83 - 1...\n",
      "Processing ./img/resize\\000bbdf0dc8099d8.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\000c21f963a9ca35.jpg...\n",
      "\n",
      "0: 480x640 3 Mans, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 000c21f963a9ca35 - 1...\n",
      "Processing 000c21f963a9ca35 - 2...\n",
      "Processing 000c21f963a9ca35 - 3...\n",
      "Processing 000c21f963a9ca35 - 4...\n",
      "Processing ./img/resize\\000c301961d5b377.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 000c301961d5b377 - 1...\n",
      "Processing 000c301961d5b377 - 2...\n",
      "Processing ./img/resize\\000c5d87a0299be1.jpg...\n",
      "\n",
      "0: 480x640 4 Footwears, 2 Jeanss, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 000c5d87a0299be1 - 1...\n",
      "Processing 000c5d87a0299be1 - 2...\n",
      "Processing 000c5d87a0299be1 - 3...\n",
      "Processing 000c5d87a0299be1 - 4...\n",
      "Processing 000c5d87a0299be1 - 5...\n",
      "Processing 000c5d87a0299be1 - 6...\n",
      "Processing ./img/resize\\000c6c92c80213ff.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\000cf8d4fd1d74ea.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 000cf8d4fd1d74ea - 1...\n",
      "Processing ./img/resize\\000d5eb7c41b4a7a.jpg...\n",
      "\n",
      "0: 480x640 1 House, 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 000d5eb7c41b4a7a - 1...\n",
      "Processing 000d5eb7c41b4a7a - 2...\n",
      "Processing ./img/resize\\000d655d579b9b30.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\000d6fefc49a9a39.jpg...\n",
      "\n",
      "0: 480x640 4 Flowers, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 000d6fefc49a9a39 - 1...\n",
      "Processing 000d6fefc49a9a39 - 2...\n",
      "Processing 000d6fefc49a9a39 - 3...\n",
      "Processing 000d6fefc49a9a39 - 4...\n",
      "Processing ./img/resize\\000de2d23a112361.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 000de2d23a112361 - 1...\n",
      "Processing ./img/resize\\000e09cfd21a1534.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 2 Wheels, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 000e09cfd21a1534 - 1...\n",
      "Processing 000e09cfd21a1534 - 2...\n",
      "Processing 000e09cfd21a1534 - 3...\n",
      "Processing ./img/resize\\000e83dc68db5ca8.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\000eba40a5b0dce6.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Footwear, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 000eba40a5b0dce6 - 1...\n",
      "Processing 000eba40a5b0dce6 - 2...\n",
      "Processing 000eba40a5b0dce6 - 3...\n",
      "Processing ./img/resize\\000ee7182e7bc8e7.jpg...\n",
      "\n",
      "0: 480x640 2 Bicycle wheels, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 000ee7182e7bc8e7 - 1...\n",
      "Processing 000ee7182e7bc8e7 - 2...\n",
      "Processing ./img/resize\\000f2708a72f9de2.jpg...\n",
      "\n",
      "0: 480x640 6 Footwears, 2 Mans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 000f2708a72f9de2 - 1...\n",
      "Processing 000f2708a72f9de2 - 2...\n",
      "Processing 000f2708a72f9de2 - 3...\n",
      "Processing 000f2708a72f9de2 - 4...\n",
      "Processing 000f2708a72f9de2 - 5...\n",
      "Processing 000f2708a72f9de2 - 6...\n",
      "Processing 000f2708a72f9de2 - 7...\n",
      "Processing 000f2708a72f9de2 - 8...\n",
      "Processing ./img/resize\\000f70501d048ef7.jpg...\n",
      "\n",
      "0: 480x640 3 Bicycles, 7 Bicycle wheels, 8 Tires, 5 Wheels, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "23\n",
      "Processing 000f70501d048ef7 - 1...\n",
      "Processing 000f70501d048ef7 - 2...\n",
      "Processing 000f70501d048ef7 - 3...\n",
      "Processing 000f70501d048ef7 - 4...\n",
      "Processing 000f70501d048ef7 - 5...\n",
      "Processing 000f70501d048ef7 - 6...\n",
      "Processing 000f70501d048ef7 - 7...\n",
      "Processing 000f70501d048ef7 - 8...\n",
      "Processing 000f70501d048ef7 - 9...\n",
      "Processing 000f70501d048ef7 - 10...\n",
      "Processing 000f70501d048ef7 - 11...\n",
      "Processing 000f70501d048ef7 - 12...\n",
      "Processing 000f70501d048ef7 - 13...\n",
      "Processing 000f70501d048ef7 - 14...\n",
      "Processing 000f70501d048ef7 - 15...\n",
      "Processing 000f70501d048ef7 - 16...\n",
      "Processing 000f70501d048ef7 - 17...\n",
      "Processing 000f70501d048ef7 - 18...\n",
      "Processing 000f70501d048ef7 - 19...\n",
      "Processing 000f70501d048ef7 - 20...\n",
      "Processing 000f70501d048ef7 - 21...\n",
      "Processing 000f70501d048ef7 - 22...\n",
      "Processing 000f70501d048ef7 - 23...\n",
      "Processing ./img/resize\\000ff7dd49c40834.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00102e56cf417797.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0010618063851449.jpg...\n",
      "\n",
      "0: 480x640 1 Book, 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0010618063851449 - 1...\n",
      "Processing 0010618063851449 - 2...\n",
      "Processing ./img/resize\\00107319659c65ba.jpg...\n",
      "\n",
      "0: 480x640 1 Dress, 1 Human face, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00107319659c65ba - 1...\n",
      "Processing 00107319659c65ba - 2...\n",
      "Processing 00107319659c65ba - 3...\n",
      "Processing ./img/resize\\0010ba221402c8de.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 2 Human faces, 1 Man, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 0010ba221402c8de - 1...\n",
      "Processing 0010ba221402c8de - 2...\n",
      "Processing 0010ba221402c8de - 3...\n",
      "Processing 0010ba221402c8de - 4...\n",
      "Processing 0010ba221402c8de - 5...\n",
      "Processing ./img/resize\\0010f270c8d18725.jpg...\n",
      "\n",
      "0: 480x640 1 Convenience store, 30.1ms\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0010f270c8d18725 - 1...\n",
      "Processing ./img/resize\\0010f4c10f7ab07e.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0010f4c10f7ab07e - 1...\n",
      "Processing 0010f4c10f7ab07e - 2...\n",
      "Processing ./img/resize\\0010fd187d57f183.jpg...\n",
      "\n",
      "0: 480x640 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0010fd187d57f183 - 1...\n",
      "Processing ./img/resize\\001119b7264d31c8.jpg...\n",
      "\n",
      "0: 480x640 1 Bird, 30.0ms\n",
      "Speed: 1.9ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001119b7264d31c8 - 1...\n",
      "Processing ./img/resize\\001139535799c155.jpg...\n",
      "\n",
      "0: 480x640 1 Box, 1 Boy, 1 Human face, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 001139535799c155 - 1...\n",
      "Processing 001139535799c155 - 2...\n",
      "Processing 001139535799c155 - 3...\n",
      "Processing ./img/resize\\00113f812d9e1408.jpg...\n",
      "\n",
      "0: 480x640 5 Human faces, 3 Womans, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00113f812d9e1408 - 1...\n",
      "Processing 00113f812d9e1408 - 2...\n",
      "Processing 00113f812d9e1408 - 3...\n",
      "Processing 00113f812d9e1408 - 4...\n",
      "Processing 00113f812d9e1408 - 5...\n",
      "Processing 00113f812d9e1408 - 6...\n",
      "Processing 00113f812d9e1408 - 7...\n",
      "Processing 00113f812d9e1408 - 8...\n",
      "Processing ./img/resize\\0011d871de471fc3.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0011d871de471fc3 - 1...\n",
      "Processing ./img/resize\\001216805fbf3220.jpg...\n",
      "\n",
      "0: 480x640 1 Coat, 1 Common sunflower, 1 Dress, 1 Fashion accessory, 6 Goggless, 4 Houseplants, 1 Human head, 1 Jacket, 2 Roses, 3 Sun hats, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "21\n",
      "Processing 001216805fbf3220 - 1...\n",
      "Processing 001216805fbf3220 - 2...\n",
      "Processing 001216805fbf3220 - 3...\n",
      "Processing 001216805fbf3220 - 4...\n",
      "Processing 001216805fbf3220 - 5...\n",
      "Processing 001216805fbf3220 - 6...\n",
      "Processing 001216805fbf3220 - 7...\n",
      "Processing 001216805fbf3220 - 8...\n",
      "Processing 001216805fbf3220 - 9...\n",
      "Processing 001216805fbf3220 - 10...\n",
      "Processing 001216805fbf3220 - 11...\n",
      "Processing 001216805fbf3220 - 12...\n",
      "Processing 001216805fbf3220 - 13...\n",
      "Processing 001216805fbf3220 - 14...\n",
      "Processing 001216805fbf3220 - 15...\n",
      "Processing 001216805fbf3220 - 16...\n",
      "Processing 001216805fbf3220 - 17...\n",
      "Processing 001216805fbf3220 - 18...\n",
      "Processing 001216805fbf3220 - 19...\n",
      "Processing 001216805fbf3220 - 20...\n",
      "Processing 001216805fbf3220 - 21...\n",
      "Processing ./img/resize\\00121d71ca832fd3.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00121d71ca832fd3 - 1...\n",
      "Processing ./img/resize\\0012a3d879bdc21e.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0012a988512260d6.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0012a988512260d6 - 1...\n",
      "Processing ./img/resize\\0012ccf63f50a332.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0012ccf63f50a332 - 1...\n",
      "Processing ./img/resize\\0012ee0965f0addb.jpg...\n",
      "\n",
      "0: 480x640 3 Boys, 3 Coffee tables, 2 Goggless, 5 Human heads, 1 Sun hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "14\n",
      "Processing 0012ee0965f0addb - 1...\n",
      "Processing 0012ee0965f0addb - 2...\n",
      "Processing 0012ee0965f0addb - 3...\n",
      "Processing 0012ee0965f0addb - 4...\n",
      "Processing 0012ee0965f0addb - 5...\n",
      "Processing 0012ee0965f0addb - 6...\n",
      "Processing 0012ee0965f0addb - 7...\n",
      "Processing 0012ee0965f0addb - 8...\n",
      "Processing 0012ee0965f0addb - 9...\n",
      "Processing 0012ee0965f0addb - 10...\n",
      "Processing 0012ee0965f0addb - 11...\n",
      "Processing 0012ee0965f0addb - 12...\n",
      "Processing 0012ee0965f0addb - 13...\n",
      "Processing 0012ee0965f0addb - 14...\n",
      "Processing ./img/resize\\00130751dcfc6b36.jpg...\n",
      "\n",
      "0: 480x640 1 Footwear, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00130751dcfc6b36 - 1...\n",
      "Processing ./img/resize\\00130e6bc2723c6b.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle, 1 Bicycle helmet, 2 Bicycle wheels, 1 Person, 2 Wheels, 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00130e6bc2723c6b - 1...\n",
      "Processing 00130e6bc2723c6b - 2...\n",
      "Processing 00130e6bc2723c6b - 3...\n",
      "Processing 00130e6bc2723c6b - 4...\n",
      "Processing 00130e6bc2723c6b - 5...\n",
      "Processing 00130e6bc2723c6b - 6...\n",
      "Processing 00130e6bc2723c6b - 7...\n",
      "Processing ./img/resize\\001322014bb83091.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001322014bb83091 - 1...\n",
      "Processing ./img/resize\\00132b0655fab6d9.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00132b0655fab6d9 - 1...\n",
      "Processing 00132b0655fab6d9 - 2...\n",
      "Processing ./img/resize\\001334fab7b5b1f9.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001334fab7b5b1f9 - 1...\n",
      "Processing ./img/resize\\001379b4a448497d.jpg...\n",
      "\n",
      "0: 480x640 3 Trees, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 001379b4a448497d - 1...\n",
      "Processing 001379b4a448497d - 2...\n",
      "Processing 001379b4a448497d - 3...\n",
      "Processing ./img/resize\\0013957a5d6e987d.jpg...\n",
      "\n",
      "0: 480x640 2 Tents, 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0013957a5d6e987d - 1...\n",
      "Processing 0013957a5d6e987d - 2...\n",
      "Processing 0013957a5d6e987d - 3...\n",
      "Processing ./img/resize\\0013c9a31bffeec2.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0013c9a31bffeec2 - 1...\n",
      "Processing ./img/resize\\0013f6fe2fc426ab.jpg...\n",
      "\n",
      "0: 480x640 3 Human faces, 1 Jeans, 5 Womans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 0013f6fe2fc426ab - 1...\n",
      "Processing 0013f6fe2fc426ab - 2...\n",
      "Processing 0013f6fe2fc426ab - 3...\n",
      "Processing 0013f6fe2fc426ab - 4...\n",
      "Processing 0013f6fe2fc426ab - 5...\n",
      "Processing 0013f6fe2fc426ab - 6...\n",
      "Processing 0013f6fe2fc426ab - 7...\n",
      "Processing 0013f6fe2fc426ab - 8...\n",
      "Processing 0013f6fe2fc426ab - 9...\n",
      "Processing ./img/resize\\00141ce359cbccfe.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\001423b6c1b5b07e.jpg...\n",
      "\n",
      "0: 480x640 1 Window, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001423b6c1b5b07e - 1...\n",
      "Processing ./img/resize\\00143d52face12a4.jpg...\n",
      "\n",
      "0: 480x640 1 Train, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00143d52face12a4 - 1...\n",
      "Processing ./img/resize\\001443707749da02.jpg...\n",
      "\n",
      "0: 480x640 1 Mobile phone, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001443707749da02 - 1...\n",
      "Processing ./img/resize\\00144844bdaf8351.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00144e58479cd186.jpg...\n",
      "\n",
      "0: 480x640 3 Cars, 2 Wheels, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00144e58479cd186 - 1...\n",
      "Processing 00144e58479cd186 - 2...\n",
      "Processing 00144e58479cd186 - 3...\n",
      "Processing 00144e58479cd186 - 4...\n",
      "Processing 00144e58479cd186 - 5...\n",
      "Processing ./img/resize\\0014ae15d83f42f0.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0014ae15d83f42f0 - 1...\n",
      "Processing ./img/resize\\0014ed7dc95a1044.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0014ed7dc95a1044 - 1...\n",
      "Processing ./img/resize\\0014fd078b954222.jpg...\n",
      "\n",
      "0: 480x640 3 Mans, 2 Suits, 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 0014fd078b954222 - 1...\n",
      "Processing 0014fd078b954222 - 2...\n",
      "Processing 0014fd078b954222 - 3...\n",
      "Processing 0014fd078b954222 - 4...\n",
      "Processing 0014fd078b954222 - 5...\n",
      "Processing 0014fd078b954222 - 6...\n",
      "Processing ./img/resize\\00151191be09d864.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 2 Trees, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00151191be09d864 - 1...\n",
      "Processing 00151191be09d864 - 2...\n",
      "Processing 00151191be09d864 - 3...\n",
      "Processing ./img/resize\\001512d120e1e800.jpg...\n",
      "\n",
      "0: 480x640 4 Cats, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 001512d120e1e800 - 1...\n",
      "Processing 001512d120e1e800 - 2...\n",
      "Processing 001512d120e1e800 - 3...\n",
      "Processing 001512d120e1e800 - 4...\n",
      "Processing ./img/resize\\00151a36023916f0.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 2 Human faces, 2 Mans, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00151a36023916f0 - 1...\n",
      "Processing 00151a36023916f0 - 2...\n",
      "Processing 00151a36023916f0 - 3...\n",
      "Processing 00151a36023916f0 - 4...\n",
      "Processing 00151a36023916f0 - 5...\n",
      "Processing 00151a36023916f0 - 6...\n",
      "Processing ./img/resize\\00151debbf4af26d.jpg...\n",
      "\n",
      "0: 480x640 1 Train, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00151debbf4af26d - 1...\n",
      "Processing ./img/resize\\00155bc9538a26ed.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00155bc9538a26ed - 1...\n",
      "Processing ./img/resize\\0015c42fe1a30f67.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0015c629a1c04a9c.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0015c629a1c04a9c - 1...\n",
      "Processing ./img/resize\\0015f87675ca226c.jpg...\n",
      "\n",
      "0: 480x640 1 Motorcycle, 1 Van, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0015f87675ca226c - 1...\n",
      "Processing 0015f87675ca226c - 2...\n",
      "Processing ./img/resize\\001627bf35373371.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Car, 1 Clothing, 1 Human face, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 001627bf35373371 - 1...\n",
      "Processing 001627bf35373371 - 2...\n",
      "Processing 001627bf35373371 - 3...\n",
      "Processing 001627bf35373371 - 4...\n",
      "Processing ./img/resize\\00162d33b27fd1c0.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00162d33b27fd1c0 - 1...\n",
      "Processing ./img/resize\\0017095493836d41.jpg...\n",
      "\n",
      "0: 480x640 1 Goose, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0017095493836d41 - 1...\n",
      "Processing ./img/resize\\00173dd9ce9e733b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\001744b8437a2a3a.jpg...\n",
      "\n",
      "0: 480x640 1 Footwear, 1 Girl, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 001744b8437a2a3a - 1...\n",
      "Processing 001744b8437a2a3a - 2...\n",
      "Processing ./img/resize\\00177ceb15288905.jpg...\n",
      "\n",
      "0: 480x640 1 Fox, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00177ceb15288905 - 1...\n",
      "Processing ./img/resize\\0017c40998b52f43.jpg...\n",
      "\n",
      "0: 480x640 1 Cat, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0017c40998b52f43 - 1...\n",
      "Processing ./img/resize\\0018067e37f55629.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0018067e37f55629 - 1...\n",
      "Processing ./img/resize\\001818c5451b513d.jpg...\n",
      "\n",
      "0: 480x640 1 Cake stand, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001818c5451b513d - 1...\n",
      "Processing ./img/resize\\00184a5822d8e726.jpg...\n",
      "\n",
      "0: 480x640 4 Footwears, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00184a5822d8e726 - 1...\n",
      "Processing 00184a5822d8e726 - 2...\n",
      "Processing 00184a5822d8e726 - 3...\n",
      "Processing 00184a5822d8e726 - 4...\n",
      "Processing 00184a5822d8e726 - 5...\n",
      "Processing ./img/resize\\00184da8d21e6c33.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 4 Persons, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00184da8d21e6c33 - 1...\n",
      "Processing 00184da8d21e6c33 - 2...\n",
      "Processing 00184da8d21e6c33 - 3...\n",
      "Processing 00184da8d21e6c33 - 4...\n",
      "Processing 00184da8d21e6c33 - 5...\n",
      "Processing ./img/resize\\001859f5960396c6.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Woman, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 001859f5960396c6 - 1...\n",
      "Processing 001859f5960396c6 - 2...\n",
      "Processing ./img/resize\\00186377f046098e.jpg...\n",
      "\n",
      "0: 480x640 6 Dresss, 1 Human face, 6 Womans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "13\n",
      "Processing 00186377f046098e - 1...\n",
      "Processing 00186377f046098e - 2...\n",
      "Processing 00186377f046098e - 3...\n",
      "Processing 00186377f046098e - 4...\n",
      "Processing 00186377f046098e - 5...\n",
      "Processing 00186377f046098e - 6...\n",
      "Processing 00186377f046098e - 7...\n",
      "Processing 00186377f046098e - 8...\n",
      "Processing 00186377f046098e - 9...\n",
      "Processing 00186377f046098e - 10...\n",
      "Processing 00186377f046098e - 11...\n",
      "Processing 00186377f046098e - 12...\n",
      "Processing 00186377f046098e - 13...\n",
      "Processing ./img/resize\\0018973d9b1d6579.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0018a1ba94bb4e35.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0018f7ad8f80f3ff.jpg...\n",
      "\n",
      "0: 480x640 2 Fountains, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0018f7ad8f80f3ff - 1...\n",
      "Processing 0018f7ad8f80f3ff - 2...\n",
      "Processing ./img/resize\\001933fd371e56c0.jpg...\n",
      "\n",
      "0: 480x640 3 Boys, 1 Drawer, 1 Egg (Food), 1 Goggles, 1 Human head, 1 Sun hat, 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 001933fd371e56c0 - 1...\n",
      "Processing 001933fd371e56c0 - 2...\n",
      "Processing 001933fd371e56c0 - 3...\n",
      "Processing 001933fd371e56c0 - 4...\n",
      "Processing 001933fd371e56c0 - 5...\n",
      "Processing 001933fd371e56c0 - 6...\n",
      "Processing 001933fd371e56c0 - 7...\n",
      "Processing 001933fd371e56c0 - 8...\n",
      "Processing 001933fd371e56c0 - 9...\n",
      "Processing ./img/resize\\001945ad2301fe7a.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 29.9ms\n",
      "Speed: 1.1ms preprocess, 29.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001945ad2301fe7a - 1...\n",
      "Processing ./img/resize\\0019a7c180fcc81f.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle wheel, 2 Coffee tables, 1 Goggles, 4 Persons, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 0019a7c180fcc81f - 1...\n",
      "Processing 0019a7c180fcc81f - 2...\n",
      "Processing 0019a7c180fcc81f - 3...\n",
      "Processing 0019a7c180fcc81f - 4...\n",
      "Processing 0019a7c180fcc81f - 5...\n",
      "Processing 0019a7c180fcc81f - 6...\n",
      "Processing 0019a7c180fcc81f - 7...\n",
      "Processing 0019a7c180fcc81f - 8...\n",
      "Processing ./img/resize\\0019a9a80bf8a2f9.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0019a9a80bf8a2f9 - 1...\n",
      "Processing ./img/resize\\0019c91cf778e003.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0019d4f468fd8488.jpg...\n",
      "\n",
      "0: 480x640 9 Balls, 2 Boxs, 2 Cabinetrys, 3 Castles, 2 Clothings, 9 Goggless, 1 Helmet, 2 Human faces, 2 Human heads, 1 Human leg, 1 Human nose, 1 Lighthouse, 2 Mans, 1 Skirt, 1 Stool, 1 Suit, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "41\n",
      "Processing 0019d4f468fd8488 - 1...\n",
      "Processing 0019d4f468fd8488 - 2...\n",
      "Processing 0019d4f468fd8488 - 3...\n",
      "Processing 0019d4f468fd8488 - 4...\n",
      "Processing 0019d4f468fd8488 - 5...\n",
      "Processing 0019d4f468fd8488 - 6...\n",
      "Processing 0019d4f468fd8488 - 7...\n",
      "Processing 0019d4f468fd8488 - 8...\n",
      "Processing 0019d4f468fd8488 - 9...\n",
      "Processing 0019d4f468fd8488 - 10...\n",
      "Processing 0019d4f468fd8488 - 11...\n",
      "Processing 0019d4f468fd8488 - 12...\n",
      "Processing 0019d4f468fd8488 - 13...\n",
      "Processing 0019d4f468fd8488 - 14...\n",
      "Processing 0019d4f468fd8488 - 15...\n",
      "Processing 0019d4f468fd8488 - 16...\n",
      "Processing 0019d4f468fd8488 - 17...\n",
      "Processing 0019d4f468fd8488 - 18...\n",
      "Processing 0019d4f468fd8488 - 19...\n",
      "Processing 0019d4f468fd8488 - 20...\n",
      "Processing 0019d4f468fd8488 - 21...\n",
      "Processing 0019d4f468fd8488 - 22...\n",
      "Processing 0019d4f468fd8488 - 23...\n",
      "Processing 0019d4f468fd8488 - 24...\n",
      "Processing 0019d4f468fd8488 - 25...\n",
      "Processing 0019d4f468fd8488 - 26...\n",
      "Processing 0019d4f468fd8488 - 27...\n",
      "Processing 0019d4f468fd8488 - 28...\n",
      "Processing 0019d4f468fd8488 - 29...\n",
      "Processing 0019d4f468fd8488 - 30...\n",
      "Processing 0019d4f468fd8488 - 31...\n",
      "Processing 0019d4f468fd8488 - 32...\n",
      "Processing 0019d4f468fd8488 - 33...\n",
      "Processing 0019d4f468fd8488 - 34...\n",
      "Processing 0019d4f468fd8488 - 35...\n",
      "Processing 0019d4f468fd8488 - 36...\n",
      "Processing 0019d4f468fd8488 - 37...\n",
      "Processing 0019d4f468fd8488 - 38...\n",
      "Processing 0019d4f468fd8488 - 39...\n",
      "Processing 0019d4f468fd8488 - 40...\n",
      "Processing 0019d4f468fd8488 - 41...\n",
      "Processing ./img/resize\\0019e7c9ee9bb6f3.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0019e7c9ee9bb6f3 - 1...\n",
      "Processing ./img/resize\\0019f28581a58655.jpg...\n",
      "\n",
      "0: 480x640 2 Persons, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0019f28581a58655 - 1...\n",
      "Processing 0019f28581a58655 - 2...\n",
      "Processing ./img/resize\\001a084d4e5a43ec.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 001a084d4e5a43ec - 1...\n",
      "Processing 001a084d4e5a43ec - 2...\n",
      "Processing ./img/resize\\001a1368870bb92f.jpg...\n",
      "\n",
      "0: 480x640 2 Trains, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 001a1368870bb92f - 1...\n",
      "Processing 001a1368870bb92f - 2...\n",
      "Processing ./img/resize\\001a45215e6879e8.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001a45215e6879e8 - 1...\n",
      "Processing ./img/resize\\001a4a9fc0d7dce3.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\001a521d8bcffdd0.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\001a6f01e4603256.jpg...\n",
      "\n",
      "0: 480x640 5 Human faces, 3 Mans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 001a6f01e4603256 - 1...\n",
      "Processing 001a6f01e4603256 - 2...\n",
      "Processing 001a6f01e4603256 - 3...\n",
      "Processing 001a6f01e4603256 - 4...\n",
      "Processing 001a6f01e4603256 - 5...\n",
      "Processing 001a6f01e4603256 - 6...\n",
      "Processing 001a6f01e4603256 - 7...\n",
      "Processing 001a6f01e4603256 - 8...\n",
      "Processing ./img/resize\\001a783046ffd7ff.jpg...\n",
      "\n",
      "0: 480x640 3 Birds, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 001a783046ffd7ff - 1...\n",
      "Processing 001a783046ffd7ff - 2...\n",
      "Processing 001a783046ffd7ff - 3...\n",
      "Processing ./img/resize\\001ae662d690368e.jpg...\n",
      "\n",
      "0: 480x640 1 Truck, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001ae662d690368e - 1...\n",
      "Processing ./img/resize\\001b113b52697c49.jpg...\n",
      "\n",
      "0: 480x640 2 Bicycles, 2 Bicycle helmets, 3 Bicycle wheels, 2 Persons, 3 Wheels, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "12\n",
      "Processing 001b113b52697c49 - 1...\n",
      "Processing 001b113b52697c49 - 2...\n",
      "Processing 001b113b52697c49 - 3...\n",
      "Processing 001b113b52697c49 - 4...\n",
      "Processing 001b113b52697c49 - 5...\n",
      "Processing 001b113b52697c49 - 6...\n",
      "Processing 001b113b52697c49 - 7...\n",
      "Processing 001b113b52697c49 - 8...\n",
      "Processing 001b113b52697c49 - 9...\n",
      "Processing 001b113b52697c49 - 10...\n",
      "Processing 001b113b52697c49 - 11...\n",
      "Processing 001b113b52697c49 - 12...\n",
      "Processing ./img/resize\\001b185fbd1ed435.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 5 Womans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 001b185fbd1ed435 - 1...\n",
      "Processing 001b185fbd1ed435 - 2...\n",
      "Processing 001b185fbd1ed435 - 3...\n",
      "Processing 001b185fbd1ed435 - 4...\n",
      "Processing 001b185fbd1ed435 - 5...\n",
      "Processing 001b185fbd1ed435 - 6...\n",
      "Processing ./img/resize\\001b4a14e12401fe.jpg...\n",
      "\n",
      "0: 480x640 1 Umbrella, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001b4a14e12401fe - 1...\n",
      "Processing ./img/resize\\001b64d830bfff5e.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\001b70a3d1aca039.jpg...\n",
      "\n",
      "0: 480x640 1 Door, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001b70a3d1aca039 - 1...\n",
      "Processing ./img/resize\\001c17d1e0d3685c.jpg...\n",
      "\n",
      "0: 480x640 2 Socks, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 001c17d1e0d3685c - 1...\n",
      "Processing 001c17d1e0d3685c - 2...\n",
      "Processing ./img/resize\\001cc045c0f1755b.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001cc045c0f1755b - 1...\n",
      "Processing ./img/resize\\001cca8a2eaedecc.jpg...\n",
      "\n",
      "0: 480x640 2 Drums, 2 Guitars, 2 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 001cca8a2eaedecc - 1...\n",
      "Processing 001cca8a2eaedecc - 2...\n",
      "Processing 001cca8a2eaedecc - 3...\n",
      "Processing 001cca8a2eaedecc - 4...\n",
      "Processing 001cca8a2eaedecc - 5...\n",
      "Processing 001cca8a2eaedecc - 6...\n",
      "Processing ./img/resize\\001ccf6254ebf36f.jpg...\n",
      "\n",
      "0: 480x640 1 Bench, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001ccf6254ebf36f - 1...\n",
      "Processing ./img/resize\\001ce300279f1a81.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\001ce8701d70e3f0.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 5 Tires, 5 Wheels, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 001ce8701d70e3f0 - 1...\n",
      "Processing 001ce8701d70e3f0 - 2...\n",
      "Processing 001ce8701d70e3f0 - 3...\n",
      "Processing 001ce8701d70e3f0 - 4...\n",
      "Processing 001ce8701d70e3f0 - 5...\n",
      "Processing 001ce8701d70e3f0 - 6...\n",
      "Processing 001ce8701d70e3f0 - 7...\n",
      "Processing 001ce8701d70e3f0 - 8...\n",
      "Processing 001ce8701d70e3f0 - 9...\n",
      "Processing 001ce8701d70e3f0 - 10...\n",
      "Processing 001ce8701d70e3f0 - 11...\n",
      "Processing ./img/resize\\001cf31fd22c6ef9.jpg...\n",
      "\n",
      "0: 480x640 1 French fries, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001cf31fd22c6ef9 - 1...\n",
      "Processing ./img/resize\\001d39a9f454a7f3.jpg...\n",
      "\n",
      "0: 480x640 8 Human faces, 2 Mans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "10\n",
      "Processing 001d39a9f454a7f3 - 1...\n",
      "Processing 001d39a9f454a7f3 - 2...\n",
      "Processing 001d39a9f454a7f3 - 3...\n",
      "Processing 001d39a9f454a7f3 - 4...\n",
      "Processing 001d39a9f454a7f3 - 5...\n",
      "Processing 001d39a9f454a7f3 - 6...\n",
      "Processing 001d39a9f454a7f3 - 7...\n",
      "Processing 001d39a9f454a7f3 - 8...\n",
      "Processing 001d39a9f454a7f3 - 9...\n",
      "Processing 001d39a9f454a7f3 - 10...\n",
      "Processing ./img/resize\\001d68f8ca067a69.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001d68f8ca067a69 - 1...\n",
      "Processing ./img/resize\\001d7f70710c1cdd.jpg...\n",
      "\n",
      "0: 480x640 4 Trees, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 001d7f70710c1cdd - 1...\n",
      "Processing 001d7f70710c1cdd - 2...\n",
      "Processing 001d7f70710c1cdd - 3...\n",
      "Processing 001d7f70710c1cdd - 4...\n",
      "Processing ./img/resize\\001dc908f3792240.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001dc908f3792240 - 1...\n",
      "Processing ./img/resize\\001dfa5785fa95d2.jpg...\n",
      "\n",
      "0: 480x640 2 Doors, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 001dfa5785fa95d2 - 1...\n",
      "Processing 001dfa5785fa95d2 - 2...\n",
      "Processing ./img/resize\\001e2b6845a27739.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\001e5e7a81e5d7e3.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\001e7cd628da5b6c.jpg...\n",
      "\n",
      "0: 480x640 3 Cars, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 001e7cd628da5b6c - 1...\n",
      "Processing 001e7cd628da5b6c - 2...\n",
      "Processing 001e7cd628da5b6c - 3...\n",
      "Processing ./img/resize\\001ed5fa8edd784f.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 2 Suits, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 001ed5fa8edd784f - 1...\n",
      "Processing 001ed5fa8edd784f - 2...\n",
      "Processing 001ed5fa8edd784f - 3...\n",
      "Processing 001ed5fa8edd784f - 4...\n",
      "Processing ./img/resize\\001edeee73440b15.jpg...\n",
      "\n",
      "0: 480x640 2 Persons, 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 001edeee73440b15 - 1...\n",
      "Processing 001edeee73440b15 - 2...\n",
      "Processing 001edeee73440b15 - 3...\n",
      "Processing ./img/resize\\001ee3a82aca555c.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001ee3a82aca555c - 1...\n",
      "Processing ./img/resize\\001ef908d8a207d4.jpg...\n",
      "\n",
      "0: 480x640 2 Footwears, 3 Mans, 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 001ef908d8a207d4 - 1...\n",
      "Processing 001ef908d8a207d4 - 2...\n",
      "Processing 001ef908d8a207d4 - 3...\n",
      "Processing 001ef908d8a207d4 - 4...\n",
      "Processing 001ef908d8a207d4 - 5...\n",
      "Processing ./img/resize\\001efea83860c797.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 001efea83860c797 - 1...\n",
      "Processing ./img/resize\\001f7f584ad258a7.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\002015e4c344d706.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002015e4c344d706 - 1...\n",
      "Processing ./img/resize\\0020349493b1086c.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0020349493b1086c - 1...\n",
      "Processing ./img/resize\\002072dd508bad95.jpg...\n",
      "\n",
      "0: 480x640 3 Houses, 2 Trees, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 002072dd508bad95 - 1...\n",
      "Processing 002072dd508bad95 - 2...\n",
      "Processing 002072dd508bad95 - 3...\n",
      "Processing 002072dd508bad95 - 4...\n",
      "Processing 002072dd508bad95 - 5...\n",
      "Processing ./img/resize\\0020b616878d2bf2.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Fashion accessory, 1 Girl, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0020b616878d2bf2 - 1...\n",
      "Processing 0020b616878d2bf2 - 2...\n",
      "Processing 0020b616878d2bf2 - 3...\n",
      "Processing ./img/resize\\0020cef0e92d1b88.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0020cef0e92d1b88 - 1...\n",
      "Processing ./img/resize\\0020d9105abf3486.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0020d9105abf3486 - 1...\n",
      "Processing ./img/resize\\0020e7c442c88e93.jpg...\n",
      "\n",
      "0: 480x640 1 Dress, 1 Flowerpot, 1 Houseplant, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0020e7c442c88e93 - 1...\n",
      "Processing 0020e7c442c88e93 - 2...\n",
      "Processing 0020e7c442c88e93 - 3...\n",
      "Processing ./img/resize\\002107c2cdc1b568.jpg...\n",
      "\n",
      "0: 480x640 1 Helmet, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 002107c2cdc1b568 - 1...\n",
      "Processing 002107c2cdc1b568 - 2...\n",
      "Processing ./img/resize\\002136e5f6aefe6b.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 002136e5f6aefe6b - 1...\n",
      "Processing 002136e5f6aefe6b - 2...\n",
      "Processing ./img/resize\\002143ba08772b52.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002143ba08772b52 - 1...\n",
      "Processing ./img/resize\\00216b18d4aeb3b5.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0021807acdf66115.jpg...\n",
      "\n",
      "0: 480x640 2 Clothings, 1 Man, 3 Womans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 0021807acdf66115 - 1...\n",
      "Processing 0021807acdf66115 - 2...\n",
      "Processing 0021807acdf66115 - 3...\n",
      "Processing 0021807acdf66115 - 4...\n",
      "Processing 0021807acdf66115 - 5...\n",
      "Processing 0021807acdf66115 - 6...\n",
      "Processing ./img/resize\\0021c515128a6b1b.jpg...\n",
      "\n",
      "0: 480x640 5 Boys, 1 Coffee table, 1 Goggles, 1 Human face, 1 Person, 1 Shirt, 1 Suit, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 0021c515128a6b1b - 1...\n",
      "Processing 0021c515128a6b1b - 2...\n",
      "Processing 0021c515128a6b1b - 3...\n",
      "Processing 0021c515128a6b1b - 4...\n",
      "Processing 0021c515128a6b1b - 5...\n",
      "Processing 0021c515128a6b1b - 6...\n",
      "Processing 0021c515128a6b1b - 7...\n",
      "Processing 0021c515128a6b1b - 8...\n",
      "Processing 0021c515128a6b1b - 9...\n",
      "Processing 0021c515128a6b1b - 10...\n",
      "Processing 0021c515128a6b1b - 11...\n",
      "Processing ./img/resize\\0022449a9546b5c1.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 2 Mans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0022449a9546b5c1 - 1...\n",
      "Processing 0022449a9546b5c1 - 2...\n",
      "Processing 0022449a9546b5c1 - 3...\n",
      "Processing 0022449a9546b5c1 - 4...\n",
      "Processing ./img/resize\\0022a377c2eb43f4.jpg...\n",
      "\n",
      "0: 480x640 1 Bookcase, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0022a377c2eb43f4 - 1...\n",
      "Processing ./img/resize\\0022c4cb896e7c9c.jpg...\n",
      "\n",
      "0: 480x640 4 Boys, 1 Coffee table, 3 Egg (Food)s, 1 Footwear, 1 Human foot, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 0022c4cb896e7c9c - 1...\n",
      "Processing 0022c4cb896e7c9c - 2...\n",
      "Processing 0022c4cb896e7c9c - 3...\n",
      "Processing 0022c4cb896e7c9c - 4...\n",
      "Processing 0022c4cb896e7c9c - 5...\n",
      "Processing 0022c4cb896e7c9c - 6...\n",
      "Processing 0022c4cb896e7c9c - 7...\n",
      "Processing 0022c4cb896e7c9c - 8...\n",
      "Processing 0022c4cb896e7c9c - 9...\n",
      "Processing 0022c4cb896e7c9c - 10...\n",
      "Processing 0022c4cb896e7c9c - 11...\n",
      "Processing ./img/resize\\0022f10af6d46840.jpg...\n",
      "\n",
      "0: 480x640 1 Girl, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0022f10af6d46840 - 1...\n",
      "Processing 0022f10af6d46840 - 2...\n",
      "Processing ./img/resize\\0022fdfc1880d432.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Wheel, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0022fdfc1880d432 - 1...\n",
      "Processing 0022fdfc1880d432 - 2...\n",
      "Processing ./img/resize\\002315390300f882.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00231a669cd3b183.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 1 Human face, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00231a669cd3b183 - 1...\n",
      "Processing 00231a669cd3b183 - 2...\n",
      "Processing 00231a669cd3b183 - 3...\n",
      "Processing ./img/resize\\0023dce3438b89c5.jpg...\n",
      "\n",
      "0: 480x640 1 Miniskirt, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0023dce3438b89c5 - 1...\n",
      "Processing ./img/resize\\00242aecec762482.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00242aecec762482 - 1...\n",
      "Processing ./img/resize\\002433c05e0ef11f.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002433c05e0ef11f - 1...\n",
      "Processing ./img/resize\\00244c734e918d82.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00244c734e918d82 - 1...\n",
      "Processing ./img/resize\\002453dd6bee632f.jpg...\n",
      "\n",
      "0: 480x640 3 Aircrafts, 2 Artichokes, 2 Bat (Animal)s, 2 Birds, 1 Bronze sculpture, 1 Cat, 2 Chairs, 4 Windows, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "17\n",
      "Processing 002453dd6bee632f - 1...\n",
      "Processing 002453dd6bee632f - 2...\n",
      "Processing 002453dd6bee632f - 3...\n",
      "Processing 002453dd6bee632f - 4...\n",
      "Processing 002453dd6bee632f - 5...\n",
      "Processing 002453dd6bee632f - 6...\n",
      "Processing 002453dd6bee632f - 7...\n",
      "Processing 002453dd6bee632f - 8...\n",
      "Processing 002453dd6bee632f - 9...\n",
      "Processing 002453dd6bee632f - 10...\n",
      "Processing 002453dd6bee632f - 11...\n",
      "Processing 002453dd6bee632f - 12...\n",
      "Processing 002453dd6bee632f - 13...\n",
      "Processing 002453dd6bee632f - 14...\n",
      "Processing 002453dd6bee632f - 15...\n",
      "Processing 002453dd6bee632f - 16...\n",
      "Processing 002453dd6bee632f - 17...\n",
      "Processing ./img/resize\\0024646120c939de.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Man, 1 Poster, 38.0ms\n",
      "Speed: 2.0ms preprocess, 38.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0024646120c939de - 1...\n",
      "Processing 0024646120c939de - 2...\n",
      "Processing 0024646120c939de - 3...\n",
      "Processing ./img/resize\\002469afe027814c.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00249293b99eadb7.jpg...\n",
      "\n",
      "0: 480x640 1 Food, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00249293b99eadb7 - 1...\n",
      "Processing ./img/resize\\0024b022596955c4.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0024b022596955c4 - 1...\n",
      "Processing 0024b022596955c4 - 2...\n",
      "Processing ./img/resize\\0024bf494d632834.jpg...\n",
      "\n",
      "0: 480x640 2 Womans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0024bf494d632834 - 1...\n",
      "Processing 0024bf494d632834 - 2...\n",
      "Processing ./img/resize\\0024e3566b144949.jpg...\n",
      "\n",
      "0: 480x640 2 Flowers, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0024e3566b144949 - 1...\n",
      "Processing 0024e3566b144949 - 2...\n",
      "Processing ./img/resize\\0024e78cd03726f0.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0024e78cd03726f0 - 1...\n",
      "Processing 0024e78cd03726f0 - 2...\n",
      "Processing 0024e78cd03726f0 - 3...\n",
      "Processing ./img/resize\\0024fc6e90a442b7.jpg...\n",
      "\n",
      "0: 480x640 1 Toy, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0024fc6e90a442b7 - 1...\n",
      "Processing ./img/resize\\002516c10d5c2ff9.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00253256ed79e2f1.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00253256ed79e2f1 - 1...\n",
      "Processing ./img/resize\\00253aa4533fd53a.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\002542c5f36c5fe4.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002542c5f36c5fe4 - 1...\n",
      "Processing ./img/resize\\00255392a087eceb.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 1 Human face, 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00255392a087eceb - 1...\n",
      "Processing 00255392a087eceb - 2...\n",
      "Processing 00255392a087eceb - 3...\n",
      "Processing ./img/resize\\0025653d1ca01838.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00259b9c1624c245.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 1 Car, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00259b9c1624c245 - 1...\n",
      "Processing 00259b9c1624c245 - 2...\n",
      "Processing ./img/resize\\0025aeb66e9d0785.jpg...\n",
      "\n",
      "0: 480x640 5 Mans, 29.0ms\n",
      "Speed: 1.9ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 0025aeb66e9d0785 - 1...\n",
      "Processing 0025aeb66e9d0785 - 2...\n",
      "Processing 0025aeb66e9d0785 - 3...\n",
      "Processing 0025aeb66e9d0785 - 4...\n",
      "Processing 0025aeb66e9d0785 - 5...\n",
      "Processing ./img/resize\\0025cecdac634ec0.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0025f1760b656c34.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00264fb0bf48ff9a.jpg...\n",
      "\n",
      "0: 480x640 2 Footwears, 1 Man, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00264fb0bf48ff9a - 1...\n",
      "Processing 00264fb0bf48ff9a - 2...\n",
      "Processing 00264fb0bf48ff9a - 3...\n",
      "Processing ./img/resize\\00267d051bb87b02.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 1 Woman, 30.0ms\n",
      "Speed: 0.9ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00267d051bb87b02 - 1...\n",
      "Processing 00267d051bb87b02 - 2...\n",
      "Processing 00267d051bb87b02 - 3...\n",
      "Processing ./img/resize\\002693801dfaca28.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle, 2 Bicycle wheels, 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 002693801dfaca28 - 1...\n",
      "Processing 002693801dfaca28 - 2...\n",
      "Processing 002693801dfaca28 - 3...\n",
      "Processing 002693801dfaca28 - 4...\n",
      "Processing ./img/resize\\0026d0c5a6d3c67e.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00272c8990ce05be.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00272c8990ce05be - 1...\n",
      "Processing 00272c8990ce05be - 2...\n",
      "Processing ./img/resize\\0027c669c5b22409.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0027c669c5b22409 - 1...\n",
      "Processing ./img/resize\\0027ee74c186cbea.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0027ee74c186cbea - 1...\n",
      "Processing ./img/resize\\0027f97cfa83e177.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Human face, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0027f97cfa83e177 - 1...\n",
      "Processing 0027f97cfa83e177 - 2...\n",
      "Processing 0027f97cfa83e177 - 3...\n",
      "Processing ./img/resize\\00287d32cad2b40d.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00287d32cad2b40d - 1...\n",
      "Processing ./img/resize\\002893c59ac4fb8c.jpg...\n",
      "\n",
      "0: 480x640 8 Bicycles, 7 Bicycle wheels, 4 Persons, 7 Wheels, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "26\n",
      "Processing 002893c59ac4fb8c - 1...\n",
      "Processing 002893c59ac4fb8c - 2...\n",
      "Processing 002893c59ac4fb8c - 3...\n",
      "Processing 002893c59ac4fb8c - 4...\n",
      "Processing 002893c59ac4fb8c - 5...\n",
      "Processing 002893c59ac4fb8c - 6...\n",
      "Processing 002893c59ac4fb8c - 7...\n",
      "Processing 002893c59ac4fb8c - 8...\n",
      "Processing 002893c59ac4fb8c - 9...\n",
      "Processing 002893c59ac4fb8c - 10...\n",
      "Processing 002893c59ac4fb8c - 11...\n",
      "Processing 002893c59ac4fb8c - 12...\n",
      "Processing 002893c59ac4fb8c - 13...\n",
      "Processing 002893c59ac4fb8c - 14...\n",
      "Processing 002893c59ac4fb8c - 15...\n",
      "Processing 002893c59ac4fb8c - 16...\n",
      "Processing 002893c59ac4fb8c - 17...\n",
      "Processing 002893c59ac4fb8c - 18...\n",
      "Processing 002893c59ac4fb8c - 19...\n",
      "Processing 002893c59ac4fb8c - 20...\n",
      "Processing 002893c59ac4fb8c - 21...\n",
      "Processing 002893c59ac4fb8c - 22...\n",
      "Processing 002893c59ac4fb8c - 23...\n",
      "Processing 002893c59ac4fb8c - 24...\n",
      "Processing 002893c59ac4fb8c - 25...\n",
      "Processing 002893c59ac4fb8c - 26...\n",
      "Processing ./img/resize\\0028c0157a81cc3c.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0028e126ab55ebfc.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Clothing, 1 Man, 1 Table, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0028e126ab55ebfc - 1...\n",
      "Processing 0028e126ab55ebfc - 2...\n",
      "Processing 0028e126ab55ebfc - 3...\n",
      "Processing 0028e126ab55ebfc - 4...\n",
      "Processing ./img/resize\\002938002b987270.jpg...\n",
      "\n",
      "0: 480x640 1 Surfboard, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002938002b987270 - 1...\n",
      "Processing ./img/resize\\00294ef7e2d70469.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00294ef7e2d70469 - 1...\n",
      "Processing ./img/resize\\002971db9d5c2b4d.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Tire, 1 Wheel, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 002971db9d5c2b4d - 1...\n",
      "Processing 002971db9d5c2b4d - 2...\n",
      "Processing 002971db9d5c2b4d - 3...\n",
      "Processing ./img/resize\\002973443937b47f.jpg...\n",
      "\n",
      "0: 480x640 1 Apple, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002973443937b47f - 1...\n",
      "Processing ./img/resize\\00298a01af277ed7.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00298a01af277ed7 - 1...\n",
      "Processing ./img/resize\\0029a56cccaaa054.jpg...\n",
      "\n",
      "0: 480x640 1 Sushi, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0029a56cccaaa054 - 1...\n",
      "Processing ./img/resize\\0029fa455ab89581.jpg...\n",
      "\n",
      "0: 480x640 12 Picture frames, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "12\n",
      "Processing 0029fa455ab89581 - 1...\n",
      "Processing 0029fa455ab89581 - 2...\n",
      "Processing 0029fa455ab89581 - 3...\n",
      "Processing 0029fa455ab89581 - 4...\n",
      "Processing 0029fa455ab89581 - 5...\n",
      "Processing 0029fa455ab89581 - 6...\n",
      "Processing 0029fa455ab89581 - 7...\n",
      "Processing 0029fa455ab89581 - 8...\n",
      "Processing 0029fa455ab89581 - 9...\n",
      "Processing 0029fa455ab89581 - 10...\n",
      "Processing 0029fa455ab89581 - 11...\n",
      "Processing 0029fa455ab89581 - 12...\n",
      "Processing ./img/resize\\002a2328c9431937.jpg...\n",
      "\n",
      "0: 480x640 2 Foods, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 002a2328c9431937 - 1...\n",
      "Processing 002a2328c9431937 - 2...\n",
      "Processing ./img/resize\\002a48e1ccaac0ea.jpg...\n",
      "\n",
      "0: 480x640 7 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 002a48e1ccaac0ea - 1...\n",
      "Processing 002a48e1ccaac0ea - 2...\n",
      "Processing 002a48e1ccaac0ea - 3...\n",
      "Processing 002a48e1ccaac0ea - 4...\n",
      "Processing 002a48e1ccaac0ea - 5...\n",
      "Processing 002a48e1ccaac0ea - 6...\n",
      "Processing 002a48e1ccaac0ea - 7...\n",
      "Processing ./img/resize\\002a57b606fd9946.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002a57b606fd9946 - 1...\n",
      "Processing ./img/resize\\002a860e50cd3172.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\002abae39de7f4b0.jpg...\n",
      "\n",
      "0: 480x640 1 Billboard, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002abae39de7f4b0 - 1...\n",
      "Processing ./img/resize\\002abe8747e84c36.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 1 Human face, 1 Man, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 002abe8747e84c36 - 1...\n",
      "Processing 002abe8747e84c36 - 2...\n",
      "Processing 002abe8747e84c36 - 3...\n",
      "Processing ./img/resize\\002ae5f2490ce216.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 002ae5f2490ce216 - 1...\n",
      "Processing 002ae5f2490ce216 - 2...\n",
      "Processing ./img/resize\\002aeb35743fbd69.jpg...\n",
      "\n",
      "0: 480x640 1 Girl, 1 Human face, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 002aeb35743fbd69 - 1...\n",
      "Processing 002aeb35743fbd69 - 2...\n",
      "Processing ./img/resize\\002af7108d184bf9.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 1 Microphone, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 002af7108d184bf9 - 1...\n",
      "Processing 002af7108d184bf9 - 2...\n",
      "Processing ./img/resize\\002b1007ce90187f.jpg...\n",
      "\n",
      "0: 480x640 1 Adhesive tape, 1 Aircraft, 2 Alarm clocks, 3 Animals, 2 Artichokes, 1 Backpack, 1 Baked goods, 2 Banjos, 1 Barrel, 3 Bicycle wheels, 1 Building, 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "19\n",
      "Processing 002b1007ce90187f - 1...\n",
      "Processing 002b1007ce90187f - 2...\n",
      "Processing 002b1007ce90187f - 3...\n",
      "Processing 002b1007ce90187f - 4...\n",
      "Processing 002b1007ce90187f - 5...\n",
      "Processing 002b1007ce90187f - 6...\n",
      "Processing 002b1007ce90187f - 7...\n",
      "Processing 002b1007ce90187f - 8...\n",
      "Processing 002b1007ce90187f - 9...\n",
      "Processing 002b1007ce90187f - 10...\n",
      "Processing 002b1007ce90187f - 11...\n",
      "Processing 002b1007ce90187f - 12...\n",
      "Processing 002b1007ce90187f - 13...\n",
      "Processing 002b1007ce90187f - 14...\n",
      "Processing 002b1007ce90187f - 15...\n",
      "Processing 002b1007ce90187f - 16...\n",
      "Processing 002b1007ce90187f - 17...\n",
      "Processing 002b1007ce90187f - 18...\n",
      "Processing 002b1007ce90187f - 19...\n",
      "Processing ./img/resize\\002b538709a1d8e8.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\002b593973aa77ca.jpg...\n",
      "\n",
      "0: 480x640 2 Boys, 2 Coffee tables, 2 Human faces, 1 Human hair, 2 Human heads, 1 Man, 1 Shirt, 4 Suits, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "15\n",
      "Processing 002b593973aa77ca - 1...\n",
      "Processing 002b593973aa77ca - 2...\n",
      "Processing 002b593973aa77ca - 3...\n",
      "Processing 002b593973aa77ca - 4...\n",
      "Processing 002b593973aa77ca - 5...\n",
      "Processing 002b593973aa77ca - 6...\n",
      "Processing 002b593973aa77ca - 7...\n",
      "Processing 002b593973aa77ca - 8...\n",
      "Processing 002b593973aa77ca - 9...\n",
      "Processing 002b593973aa77ca - 10...\n",
      "Processing 002b593973aa77ca - 11...\n",
      "Processing 002b593973aa77ca - 12...\n",
      "Processing 002b593973aa77ca - 13...\n",
      "Processing 002b593973aa77ca - 14...\n",
      "Processing 002b593973aa77ca - 15...\n",
      "Processing ./img/resize\\002b6c92fb40a674.jpg...\n",
      "\n",
      "0: 480x640 2 Houses, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 002b6c92fb40a674 - 1...\n",
      "Processing 002b6c92fb40a674 - 2...\n",
      "Processing ./img/resize\\002bd556e124bb3d.jpg...\n",
      "\n",
      "0: 480x640 1 Horse, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002bd556e124bb3d - 1...\n",
      "Processing ./img/resize\\002c3cfbadaa29c4.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.9ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\002c8c0d1e3fff48.jpg...\n",
      "\n",
      "0: 480x640 1 Coffee table, 1 Land vehicle, 1 Person, 1 Sun hat, 1 Wheel, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 002c8c0d1e3fff48 - 1...\n",
      "Processing 002c8c0d1e3fff48 - 2...\n",
      "Processing 002c8c0d1e3fff48 - 3...\n",
      "Processing 002c8c0d1e3fff48 - 4...\n",
      "Processing 002c8c0d1e3fff48 - 5...\n",
      "Processing ./img/resize\\002c97f5a037ba12.jpg...\n",
      "\n",
      "0: 480x640 2 Persons, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 002c97f5a037ba12 - 1...\n",
      "Processing 002c97f5a037ba12 - 2...\n",
      "Processing ./img/resize\\002cdf0aab95d2ac.jpg...\n",
      "\n",
      "0: 480x640 1 House, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002cdf0aab95d2ac - 1...\n",
      "Processing ./img/resize\\002cff1919a39fe7.jpg...\n",
      "\n",
      "0: 480x640 1 Van, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002cff1919a39fe7 - 1...\n",
      "Processing ./img/resize\\002d1d05a2fac63c.jpg...\n",
      "\n",
      "0: 480x640 1 Bird, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002d1d05a2fac63c - 1...\n",
      "Processing ./img/resize\\002d289269dc7715.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002d289269dc7715 - 1...\n",
      "Processing ./img/resize\\002d84dbf9010335.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\002da2980c667c52.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\002dd80c5cbdf5bd.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Human face, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 002dd80c5cbdf5bd - 1...\n",
      "Processing 002dd80c5cbdf5bd - 2...\n",
      "Processing ./img/resize\\002e09fe056ff0a9.jpg...\n",
      "\n",
      "0: 480x640 1 Table, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002e09fe056ff0a9 - 1...\n",
      "Processing ./img/resize\\002e166132e0f34f.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\002e1bb998b9a6ab.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\002e3728932fc244.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002e3728932fc244 - 1...\n",
      "Processing ./img/resize\\002eb736a46afc9b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\002f4a36c482f5fb.jpg...\n",
      "\n",
      "0: 480x640 1 Baked goods, 2 Bicycle helmets, 1 Bicycle wheel, 1 Building, 1 Common sunflower, 1 Dress, 4 Goggless, 1 Human hair, 1 Human head, 2 Mans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "15\n",
      "Processing 002f4a36c482f5fb - 1...\n",
      "Processing 002f4a36c482f5fb - 2...\n",
      "Processing 002f4a36c482f5fb - 3...\n",
      "Processing 002f4a36c482f5fb - 4...\n",
      "Processing 002f4a36c482f5fb - 5...\n",
      "Processing 002f4a36c482f5fb - 6...\n",
      "Processing 002f4a36c482f5fb - 7...\n",
      "Processing 002f4a36c482f5fb - 8...\n",
      "Processing 002f4a36c482f5fb - 9...\n",
      "Processing 002f4a36c482f5fb - 10...\n",
      "Processing 002f4a36c482f5fb - 11...\n",
      "Processing 002f4a36c482f5fb - 12...\n",
      "Processing 002f4a36c482f5fb - 13...\n",
      "Processing 002f4a36c482f5fb - 14...\n",
      "Processing 002f4a36c482f5fb - 15...\n",
      "Processing ./img/resize\\002f6311bbbd41b1.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Footwear, 8 Mans, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "10\n",
      "Processing 002f6311bbbd41b1 - 1...\n",
      "Processing 002f6311bbbd41b1 - 2...\n",
      "Processing 002f6311bbbd41b1 - 3...\n",
      "Processing 002f6311bbbd41b1 - 4...\n",
      "Processing 002f6311bbbd41b1 - 5...\n",
      "Processing 002f6311bbbd41b1 - 6...\n",
      "Processing 002f6311bbbd41b1 - 7...\n",
      "Processing 002f6311bbbd41b1 - 8...\n",
      "Processing 002f6311bbbd41b1 - 9...\n",
      "Processing 002f6311bbbd41b1 - 10...\n",
      "Processing ./img/resize\\002f699f321e9810.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002f699f321e9810 - 1...\n",
      "Processing ./img/resize\\002f74d4181e63e7.jpg...\n",
      "\n",
      "0: 480x640 1 Cart, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 002f74d4181e63e7 - 1...\n",
      "Processing ./img/resize\\002fb1f61fef25de.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 002fb1f61fef25de - 1...\n",
      "Processing 002fb1f61fef25de - 2...\n",
      "Processing ./img/resize\\003005690e4ab5bf.jpg...\n",
      "\n",
      "0: 480x640 1 Bowl, 1 Boy, 1 Goggles, 1 Grapefruit, 1 Human arm, 1 Human hair, 1 Human head, 1 Sun hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 003005690e4ab5bf - 1...\n",
      "Processing 003005690e4ab5bf - 2...\n",
      "Processing 003005690e4ab5bf - 3...\n",
      "Processing 003005690e4ab5bf - 4...\n",
      "Processing 003005690e4ab5bf - 5...\n",
      "Processing 003005690e4ab5bf - 6...\n",
      "Processing 003005690e4ab5bf - 7...\n",
      "Processing 003005690e4ab5bf - 8...\n",
      "Processing ./img/resize\\003015e067e6d449.jpg...\n",
      "\n",
      "0: 480x640 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003015e067e6d449 - 1...\n",
      "Processing ./img/resize\\003053ab90a1f0a6.jpg...\n",
      "\n",
      "0: 480x640 1 Accordion, 1 Apple, 2 Backpacks, 1 Bench, 1 Bicycle helmet, 1 Bicycle wheel, 1 Bookcase, 1 Bowl, 6 Boys, 4 Brassieres, 1 Car, 2 Coats, 5 Coffee tables, 1 Desk, 1 Girl, 13 Goggless, 1 Human head, 1 Man, 1 Palm tree, 1 Person, 1 Shirt, 6 Suits, 1 Tart, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "54\n",
      "Processing 003053ab90a1f0a6 - 1...\n",
      "Processing 003053ab90a1f0a6 - 2...\n",
      "Processing 003053ab90a1f0a6 - 3...\n",
      "Processing 003053ab90a1f0a6 - 4...\n",
      "Processing 003053ab90a1f0a6 - 5...\n",
      "Processing 003053ab90a1f0a6 - 6...\n",
      "Processing 003053ab90a1f0a6 - 7...\n",
      "Processing 003053ab90a1f0a6 - 8...\n",
      "Processing 003053ab90a1f0a6 - 9...\n",
      "Processing 003053ab90a1f0a6 - 10...\n",
      "Processing 003053ab90a1f0a6 - 11...\n",
      "Processing 003053ab90a1f0a6 - 12...\n",
      "Processing 003053ab90a1f0a6 - 13...\n",
      "Processing 003053ab90a1f0a6 - 14...\n",
      "Processing 003053ab90a1f0a6 - 15...\n",
      "Processing 003053ab90a1f0a6 - 16...\n",
      "Processing 003053ab90a1f0a6 - 17...\n",
      "Processing 003053ab90a1f0a6 - 18...\n",
      "Processing 003053ab90a1f0a6 - 19...\n",
      "Processing 003053ab90a1f0a6 - 20...\n",
      "Processing 003053ab90a1f0a6 - 21...\n",
      "Processing 003053ab90a1f0a6 - 22...\n",
      "Processing 003053ab90a1f0a6 - 23...\n",
      "Processing 003053ab90a1f0a6 - 24...\n",
      "Processing 003053ab90a1f0a6 - 25...\n",
      "Processing 003053ab90a1f0a6 - 26...\n",
      "Processing 003053ab90a1f0a6 - 27...\n",
      "Processing 003053ab90a1f0a6 - 28...\n",
      "Processing 003053ab90a1f0a6 - 29...\n",
      "Processing 003053ab90a1f0a6 - 30...\n",
      "Processing 003053ab90a1f0a6 - 31...\n",
      "Processing 003053ab90a1f0a6 - 32...\n",
      "Processing 003053ab90a1f0a6 - 33...\n",
      "Processing 003053ab90a1f0a6 - 34...\n",
      "Processing 003053ab90a1f0a6 - 35...\n",
      "Processing 003053ab90a1f0a6 - 36...\n",
      "Processing 003053ab90a1f0a6 - 37...\n",
      "Processing 003053ab90a1f0a6 - 38...\n",
      "Processing 003053ab90a1f0a6 - 39...\n",
      "Processing 003053ab90a1f0a6 - 40...\n",
      "Processing 003053ab90a1f0a6 - 41...\n",
      "Processing 003053ab90a1f0a6 - 42...\n",
      "Processing 003053ab90a1f0a6 - 43...\n",
      "Processing 003053ab90a1f0a6 - 44...\n",
      "Processing 003053ab90a1f0a6 - 45...\n",
      "Processing 003053ab90a1f0a6 - 46...\n",
      "Processing 003053ab90a1f0a6 - 47...\n",
      "Processing 003053ab90a1f0a6 - 48...\n",
      "Processing 003053ab90a1f0a6 - 49...\n",
      "Processing 003053ab90a1f0a6 - 50...\n",
      "Processing 003053ab90a1f0a6 - 51...\n",
      "Processing 003053ab90a1f0a6 - 52...\n",
      "Processing 003053ab90a1f0a6 - 53...\n",
      "Processing 003053ab90a1f0a6 - 54...\n",
      "Processing ./img/resize\\00307ca5ade75b20.jpg...\n",
      "\n",
      "0: 480x640 3 Flowers, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00307ca5ade75b20 - 1...\n",
      "Processing 00307ca5ade75b20 - 2...\n",
      "Processing 00307ca5ade75b20 - 3...\n",
      "Processing ./img/resize\\00308e0f381874b3.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00308e0f381874b3 - 1...\n",
      "Processing 00308e0f381874b3 - 2...\n",
      "Processing ./img/resize\\0030b2384b0acdb8.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0030cd9b42e7923b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0030e6595caf40cb.jpg...\n",
      "\n",
      "0: 480x640 1 Castle, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0030e6595caf40cb - 1...\n",
      "Processing ./img/resize\\0030eb93846ab89a.jpg...\n",
      "\n",
      "0: 480x640 1 Poster, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0030eb93846ab89a - 1...\n",
      "Processing ./img/resize\\00311b3a6663be6a.jpg...\n",
      "\n",
      "0: 480x640 1 Swimming pool, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00311b3a6663be6a - 1...\n",
      "Processing ./img/resize\\003127ee9b5c7ada.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003127ee9b5c7ada - 1...\n",
      "Processing ./img/resize\\00319c62fce5c8ad.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00319c62fce5c8ad - 1...\n",
      "Processing ./img/resize\\00323826cfcdf466.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0032fde6c0e9fc4b.jpg...\n",
      "\n",
      "0: 480x640 2 Trees, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0032fde6c0e9fc4b - 1...\n",
      "Processing 0032fde6c0e9fc4b - 2...\n",
      "Processing ./img/resize\\00335c6b32bb1b97.jpg...\n",
      "\n",
      "0: 480x640 1 Fish, 1 Jeans, 1 Man, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00335c6b32bb1b97 - 1...\n",
      "Processing 00335c6b32bb1b97 - 2...\n",
      "Processing 00335c6b32bb1b97 - 3...\n",
      "Processing ./img/resize\\00336bd08f30f7f0.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 2 Human faces, 1 Man, 1 Woman, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00336bd08f30f7f0 - 1...\n",
      "Processing 00336bd08f30f7f0 - 2...\n",
      "Processing 00336bd08f30f7f0 - 3...\n",
      "Processing 00336bd08f30f7f0 - 4...\n",
      "Processing 00336bd08f30f7f0 - 5...\n",
      "Processing ./img/resize\\003392645676d89e.jpg...\n",
      "\n",
      "0: 480x640 1 Bust, 1 Human face, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 003392645676d89e - 1...\n",
      "Processing 003392645676d89e - 2...\n",
      "Processing ./img/resize\\003392abf1e2fa13.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0033a0101a1b8647.jpg...\n",
      "\n",
      "0: 480x640 4 Bicycle wheels, 2 Human faces, 1 Man, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 0033a0101a1b8647 - 1...\n",
      "Processing 0033a0101a1b8647 - 2...\n",
      "Processing 0033a0101a1b8647 - 3...\n",
      "Processing 0033a0101a1b8647 - 4...\n",
      "Processing 0033a0101a1b8647 - 5...\n",
      "Processing 0033a0101a1b8647 - 6...\n",
      "Processing 0033a0101a1b8647 - 7...\n",
      "Processing 0033a0101a1b8647 - 8...\n",
      "Processing ./img/resize\\00340a9deedeb9f1.jpg...\n",
      "\n",
      "0: 480x640 1 House, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00340a9deedeb9f1 - 1...\n",
      "Processing ./img/resize\\0034155f93b5ac5c.jpg...\n",
      "\n",
      "0: 480x640 1 Train, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0034155f93b5ac5c - 1...\n",
      "Processing ./img/resize\\003419ab06b82e6c.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0034545a530a9602.jpg...\n",
      "\n",
      "0: 480x640 2 Fruits, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0034545a530a9602 - 1...\n",
      "Processing 0034545a530a9602 - 2...\n",
      "Processing ./img/resize\\00346913fd2e3556.jpg...\n",
      "\n",
      "0: 480x640 1 Dress, 6 Human faces, 6 Mans, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "14\n",
      "Processing 00346913fd2e3556 - 1...\n",
      "Processing 00346913fd2e3556 - 2...\n",
      "Processing 00346913fd2e3556 - 3...\n",
      "Processing 00346913fd2e3556 - 4...\n",
      "Processing 00346913fd2e3556 - 5...\n",
      "Processing 00346913fd2e3556 - 6...\n",
      "Processing 00346913fd2e3556 - 7...\n",
      "Processing 00346913fd2e3556 - 8...\n",
      "Processing 00346913fd2e3556 - 9...\n",
      "Processing 00346913fd2e3556 - 10...\n",
      "Processing 00346913fd2e3556 - 11...\n",
      "Processing 00346913fd2e3556 - 12...\n",
      "Processing 00346913fd2e3556 - 13...\n",
      "Processing 00346913fd2e3556 - 14...\n",
      "Processing ./img/resize\\00347cbbeed4bedb.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\003494fb02fd5ada.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0034bd401ead3239.jpg...\n",
      "\n",
      "0: 480x640 7 Swimwears, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 0034bd401ead3239 - 1...\n",
      "Processing 0034bd401ead3239 - 2...\n",
      "Processing 0034bd401ead3239 - 3...\n",
      "Processing 0034bd401ead3239 - 4...\n",
      "Processing 0034bd401ead3239 - 5...\n",
      "Processing 0034bd401ead3239 - 6...\n",
      "Processing 0034bd401ead3239 - 7...\n",
      "Processing ./img/resize\\0034c7d615675754.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0034dff0499938b0.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0035005d78bf8c89.jpg...\n",
      "\n",
      "0: 480x640 1 Bird, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0035005d78bf8c89 - 1...\n",
      "Processing ./img/resize\\0035074f3d2a3c2d.jpg...\n",
      "\n",
      "0: 480x640 2 Boys, 3 Coats, 1 Coffee table, 1 Dress, 2 Human heads, 2 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 0035074f3d2a3c2d - 1...\n",
      "Processing 0035074f3d2a3c2d - 2...\n",
      "Processing 0035074f3d2a3c2d - 3...\n",
      "Processing 0035074f3d2a3c2d - 4...\n",
      "Processing 0035074f3d2a3c2d - 5...\n",
      "Processing 0035074f3d2a3c2d - 6...\n",
      "Processing 0035074f3d2a3c2d - 7...\n",
      "Processing 0035074f3d2a3c2d - 8...\n",
      "Processing 0035074f3d2a3c2d - 9...\n",
      "Processing 0035074f3d2a3c2d - 10...\n",
      "Processing 0035074f3d2a3c2d - 11...\n",
      "Processing ./img/resize\\00352028279b318c.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 1 Sun hat, 1 Swimwear, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00352028279b318c - 1...\n",
      "Processing 00352028279b318c - 2...\n",
      "Processing 00352028279b318c - 3...\n",
      "Processing 00352028279b318c - 4...\n",
      "Processing 00352028279b318c - 5...\n",
      "Processing ./img/resize\\00353d876cedc513.jpg...\n",
      "\n",
      "0: 480x640 1 Bench, 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00353d876cedc513 - 1...\n",
      "Processing 00353d876cedc513 - 2...\n",
      "Processing ./img/resize\\003585723efc7d22.jpg...\n",
      "\n",
      "0: 480x640 4 Accordions, 4 Adhesive tapes, 4 Aircrafts, 1 Airplane, 1 Alpaca, 1 Animal, 1 Food, 1 Palm tree, 1 Sports uniform, 1 Watercraft, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "19\n",
      "Processing 003585723efc7d22 - 1...\n",
      "Processing 003585723efc7d22 - 2...\n",
      "Processing 003585723efc7d22 - 3...\n",
      "Processing 003585723efc7d22 - 4...\n",
      "Processing 003585723efc7d22 - 5...\n",
      "Processing 003585723efc7d22 - 6...\n",
      "Processing 003585723efc7d22 - 7...\n",
      "Processing 003585723efc7d22 - 8...\n",
      "Processing 003585723efc7d22 - 9...\n",
      "Processing 003585723efc7d22 - 10...\n",
      "Processing 003585723efc7d22 - 11...\n",
      "Processing 003585723efc7d22 - 12...\n",
      "Processing 003585723efc7d22 - 13...\n",
      "Processing 003585723efc7d22 - 14...\n",
      "Processing 003585723efc7d22 - 15...\n",
      "Processing 003585723efc7d22 - 16...\n",
      "Processing 003585723efc7d22 - 17...\n",
      "Processing 003585723efc7d22 - 18...\n",
      "Processing 003585723efc7d22 - 19...\n",
      "Processing ./img/resize\\003596912035e6ca.jpg...\n",
      "\n",
      "0: 480x640 1 Ant, 2 Bathroom accessorys, 1 Belt, 2 Bicycle wheels, 1 Bowl, 1 Cowboy hat, 2 Fashion accessorys, 1 Flying disc, 8 Goggless, 4 Hats, 1 Human head, 1 Person, 2 Shirts, 1 Skirt, 1 Sun hat, 1 Tie, 1 Trousers, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "31\n",
      "Processing 003596912035e6ca - 1...\n",
      "Processing 003596912035e6ca - 2...\n",
      "Processing 003596912035e6ca - 3...\n",
      "Processing 003596912035e6ca - 4...\n",
      "Processing 003596912035e6ca - 5...\n",
      "Processing 003596912035e6ca - 6...\n",
      "Processing 003596912035e6ca - 7...\n",
      "Processing 003596912035e6ca - 8...\n",
      "Processing 003596912035e6ca - 9...\n",
      "Processing 003596912035e6ca - 10...\n",
      "Processing 003596912035e6ca - 11...\n",
      "Processing 003596912035e6ca - 12...\n",
      "Processing 003596912035e6ca - 13...\n",
      "Processing 003596912035e6ca - 14...\n",
      "Processing 003596912035e6ca - 15...\n",
      "Processing 003596912035e6ca - 16...\n",
      "Processing 003596912035e6ca - 17...\n",
      "Processing 003596912035e6ca - 18...\n",
      "Processing 003596912035e6ca - 19...\n",
      "Processing 003596912035e6ca - 20...\n",
      "Processing 003596912035e6ca - 21...\n",
      "Processing 003596912035e6ca - 22...\n",
      "Processing 003596912035e6ca - 23...\n",
      "Processing 003596912035e6ca - 24...\n",
      "Processing 003596912035e6ca - 25...\n",
      "Processing 003596912035e6ca - 26...\n",
      "Processing 003596912035e6ca - 27...\n",
      "Processing 003596912035e6ca - 28...\n",
      "Processing 003596912035e6ca - 29...\n",
      "Processing 003596912035e6ca - 30...\n",
      "Processing 003596912035e6ca - 31...\n",
      "Processing ./img/resize\\0035a583e4e7e9cf.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 2 Mans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0035a583e4e7e9cf - 1...\n",
      "Processing 0035a583e4e7e9cf - 2...\n",
      "Processing 0035a583e4e7e9cf - 3...\n",
      "Processing 0035a583e4e7e9cf - 4...\n",
      "Processing ./img/resize\\0036001355c7bcf5.jpg...\n",
      "\n",
      "0: 480x640 2 Clothings, 2 Mans, 3 Womans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 0036001355c7bcf5 - 1...\n",
      "Processing 0036001355c7bcf5 - 2...\n",
      "Processing 0036001355c7bcf5 - 3...\n",
      "Processing 0036001355c7bcf5 - 4...\n",
      "Processing 0036001355c7bcf5 - 5...\n",
      "Processing 0036001355c7bcf5 - 6...\n",
      "Processing 0036001355c7bcf5 - 7...\n",
      "Processing ./img/resize\\003611d6d4cb7aed.jpg...\n",
      "\n",
      "0: 480x640 1 Bench, 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 003611d6d4cb7aed - 1...\n",
      "Processing 003611d6d4cb7aed - 2...\n",
      "Processing ./img/resize\\0036505e31905bfe.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0036545353017235.jpg...\n",
      "\n",
      "0: 480x640 1 Dress, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0036545353017235 - 1...\n",
      "Processing 0036545353017235 - 2...\n",
      "Processing ./img/resize\\00365aa0bd08d5a0.jpg...\n",
      "\n",
      "0: 480x640 2 Womans, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00365aa0bd08d5a0 - 1...\n",
      "Processing 00365aa0bd08d5a0 - 2...\n",
      "Processing ./img/resize\\00369894b8338b1c.jpg...\n",
      "\n",
      "0: 480x640 1 Plant, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00369894b8338b1c - 1...\n",
      "Processing ./img/resize\\0036c37619289b0c.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 2 Wheels, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0036c37619289b0c - 1...\n",
      "Processing 0036c37619289b0c - 2...\n",
      "Processing 0036c37619289b0c - 3...\n",
      "Processing 0036c37619289b0c - 4...\n",
      "Processing ./img/resize\\0036d2b9eddd940a.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00374669034dd568.jpg...\n",
      "\n",
      "0: 480x640 1 Canoe, 2 Paddles, 3 Persons, 2 Personal flotation devices, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00374669034dd568 - 1...\n",
      "Processing 00374669034dd568 - 2...\n",
      "Processing 00374669034dd568 - 3...\n",
      "Processing 00374669034dd568 - 4...\n",
      "Processing 00374669034dd568 - 5...\n",
      "Processing 00374669034dd568 - 6...\n",
      "Processing 00374669034dd568 - 7...\n",
      "Processing 00374669034dd568 - 8...\n",
      "Processing ./img/resize\\00375ec227c0b2a9.jpg...\n",
      "\n",
      "0: 480x640 2 Bottles, 1 Umbrella, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00375ec227c0b2a9 - 1...\n",
      "Processing 00375ec227c0b2a9 - 2...\n",
      "Processing 00375ec227c0b2a9 - 3...\n",
      "Processing ./img/resize\\00377e51fe533b84.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\003861c15d191858.jpg...\n",
      "\n",
      "0: 480x640 1 Book, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003861c15d191858 - 1...\n",
      "Processing ./img/resize\\003876dd8a4d275a.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 1 Table, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 003876dd8a4d275a - 1...\n",
      "Processing 003876dd8a4d275a - 2...\n",
      "Processing ./img/resize\\0038d299de7ff49c.jpg...\n",
      "\n",
      "0: 480x640 3 Mans, 6 Womans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 0038d299de7ff49c - 1...\n",
      "Processing 0038d299de7ff49c - 2...\n",
      "Processing 0038d299de7ff49c - 3...\n",
      "Processing 0038d299de7ff49c - 4...\n",
      "Processing 0038d299de7ff49c - 5...\n",
      "Processing 0038d299de7ff49c - 6...\n",
      "Processing 0038d299de7ff49c - 7...\n",
      "Processing 0038d299de7ff49c - 8...\n",
      "Processing 0038d299de7ff49c - 9...\n",
      "Processing ./img/resize\\0038f0f3222dd7f8.jpg...\n",
      "\n",
      "0: 480x640 2 Balls, 3 Bowls, 2 Coffee tables, 2 Goggless, 2 Grapefruits, 1 Human face, 1 Suit, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "13\n",
      "Processing 0038f0f3222dd7f8 - 1...\n",
      "Processing 0038f0f3222dd7f8 - 2...\n",
      "Processing 0038f0f3222dd7f8 - 3...\n",
      "Processing 0038f0f3222dd7f8 - 4...\n",
      "Processing 0038f0f3222dd7f8 - 5...\n",
      "Processing 0038f0f3222dd7f8 - 6...\n",
      "Processing 0038f0f3222dd7f8 - 7...\n",
      "Processing 0038f0f3222dd7f8 - 8...\n",
      "Processing 0038f0f3222dd7f8 - 9...\n",
      "Processing 0038f0f3222dd7f8 - 10...\n",
      "Processing 0038f0f3222dd7f8 - 11...\n",
      "Processing 0038f0f3222dd7f8 - 12...\n",
      "Processing 0038f0f3222dd7f8 - 13...\n",
      "Processing ./img/resize\\00391a7cc8aeca4b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00392bcf46ff4a31.jpg...\n",
      "\n",
      "0: 480x640 1 Train, 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00392bcf46ff4a31 - 1...\n",
      "Processing 00392bcf46ff4a31 - 2...\n",
      "Processing ./img/resize\\00392c3784fa2664.jpg...\n",
      "\n",
      "0: 480x640 2 Chairs, 1 Curtain, 1 Kitchen & dining room table, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00392c3784fa2664 - 1...\n",
      "Processing 00392c3784fa2664 - 2...\n",
      "Processing 00392c3784fa2664 - 3...\n",
      "Processing 00392c3784fa2664 - 4...\n",
      "Processing ./img/resize\\00392e9b893f91ef.jpg...\n",
      "\n",
      "0: 480x640 1 Goose, 1 Sports uniform, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00392e9b893f91ef - 1...\n",
      "Processing 00392e9b893f91ef - 2...\n",
      "Processing ./img/resize\\003961833e4ef66d.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 2 Wheels, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 003961833e4ef66d - 1...\n",
      "Processing 003961833e4ef66d - 2...\n",
      "Processing 003961833e4ef66d - 3...\n",
      "Processing ./img/resize\\003980e2756a7133.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.1ms\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\003997e9940c67fc.jpg...\n",
      "\n",
      "0: 480x640 1 Rose, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003997e9940c67fc - 1...\n",
      "Processing ./img/resize\\0039c81f53b104bb.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Picture frame, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0039c81f53b104bb - 1...\n",
      "Processing 0039c81f53b104bb - 2...\n",
      "Processing 0039c81f53b104bb - 3...\n",
      "Processing ./img/resize\\0039d00a129dfbe7.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 1 Table, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0039d00a129dfbe7 - 1...\n",
      "Processing 0039d00a129dfbe7 - 2...\n",
      "Processing ./img/resize\\0039e9930110f20f.jpg...\n",
      "\n",
      "0: 480x640 1 Owl, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0039e9930110f20f - 1...\n",
      "Processing ./img/resize\\0039ec230c9ce5af.jpg...\n",
      "\n",
      "0: 480x640 3 Football helmets, 3 Footwears, 2 Mans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 0039ec230c9ce5af - 1...\n",
      "Processing 0039ec230c9ce5af - 2...\n",
      "Processing 0039ec230c9ce5af - 3...\n",
      "Processing 0039ec230c9ce5af - 4...\n",
      "Processing 0039ec230c9ce5af - 5...\n",
      "Processing 0039ec230c9ce5af - 6...\n",
      "Processing 0039ec230c9ce5af - 7...\n",
      "Processing 0039ec230c9ce5af - 8...\n",
      "Processing ./img/resize\\003a12af7e85a862.jpg...\n",
      "\n",
      "0: 480x640 1 Skyscraper, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003a12af7e85a862 - 1...\n",
      "Processing ./img/resize\\003a17ee9d38e7c6.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 4 Mans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 003a17ee9d38e7c6 - 1...\n",
      "Processing 003a17ee9d38e7c6 - 2...\n",
      "Processing 003a17ee9d38e7c6 - 3...\n",
      "Processing 003a17ee9d38e7c6 - 4...\n",
      "Processing 003a17ee9d38e7c6 - 5...\n",
      "Processing ./img/resize\\003a2f543935230c.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\003a87a684878db3.jpg...\n",
      "\n",
      "0: 480x640 1 House, 2 Windows, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 003a87a684878db3 - 1...\n",
      "Processing 003a87a684878db3 - 2...\n",
      "Processing 003a87a684878db3 - 3...\n",
      "Processing ./img/resize\\003ad398625cf21c.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 37.0ms\n",
      "Speed: 2.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\003ba9575468f8e1.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003ba9575468f8e1 - 1...\n",
      "Processing ./img/resize\\003ba9e788fc1b12.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003ba9e788fc1b12 - 1...\n",
      "Processing ./img/resize\\003bc013f9dd0aef.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 003bc013f9dd0aef - 1...\n",
      "Processing 003bc013f9dd0aef - 2...\n",
      "Processing ./img/resize\\003bc6ffe8d4bb4e.jpg...\n",
      "\n",
      "0: 480x640 1 Plant, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003bc6ffe8d4bb4e - 1...\n",
      "Processing ./img/resize\\003bc827f96b6440.jpg...\n",
      "\n",
      "0: 480x640 1 House, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003bc827f96b6440 - 1...\n",
      "Processing ./img/resize\\003bd3139f1b0b94.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\003bd55940c3a6f7.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\003c0cac1ea19d3e.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003c0cac1ea19d3e - 1...\n",
      "Processing ./img/resize\\003c399360f08328.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\003cd026e80b5053.jpg...\n",
      "\n",
      "0: 480x640 2 Carnivores, 2 Clothings, 1 Coffee table, 13 Goggless, 2 Human faces, 1 Jacket, 1 Kitchen & dining room table, 1 Mammal, 3 Persons, 2 Sun hats, 2 Sunglassess, 1 Van, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "31\n",
      "Processing 003cd026e80b5053 - 1...\n",
      "Processing 003cd026e80b5053 - 2...\n",
      "Processing 003cd026e80b5053 - 3...\n",
      "Processing 003cd026e80b5053 - 4...\n",
      "Processing 003cd026e80b5053 - 5...\n",
      "Processing 003cd026e80b5053 - 6...\n",
      "Processing 003cd026e80b5053 - 7...\n",
      "Processing 003cd026e80b5053 - 8...\n",
      "Processing 003cd026e80b5053 - 9...\n",
      "Processing 003cd026e80b5053 - 10...\n",
      "Processing 003cd026e80b5053 - 11...\n",
      "Processing 003cd026e80b5053 - 12...\n",
      "Processing 003cd026e80b5053 - 13...\n",
      "Processing 003cd026e80b5053 - 14...\n",
      "Processing 003cd026e80b5053 - 15...\n",
      "Processing 003cd026e80b5053 - 16...\n",
      "Processing 003cd026e80b5053 - 17...\n",
      "Processing 003cd026e80b5053 - 18...\n",
      "Processing 003cd026e80b5053 - 19...\n",
      "Processing 003cd026e80b5053 - 20...\n",
      "Processing 003cd026e80b5053 - 21...\n",
      "Processing 003cd026e80b5053 - 22...\n",
      "Processing 003cd026e80b5053 - 23...\n",
      "Processing 003cd026e80b5053 - 24...\n",
      "Processing 003cd026e80b5053 - 25...\n",
      "Processing 003cd026e80b5053 - 26...\n",
      "Processing 003cd026e80b5053 - 27...\n",
      "Processing 003cd026e80b5053 - 28...\n",
      "Processing 003cd026e80b5053 - 29...\n",
      "Processing 003cd026e80b5053 - 30...\n",
      "Processing 003cd026e80b5053 - 31...\n",
      "Processing ./img/resize\\003ce875a2579acd.jpg...\n",
      "\n",
      "0: 480x640 1 Mushroom, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003ce875a2579acd - 1...\n",
      "Processing ./img/resize\\003ce901008b4cb5.jpg...\n",
      "\n",
      "0: 480x640 1 Monkey, 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 003ce901008b4cb5 - 1...\n",
      "Processing 003ce901008b4cb5 - 2...\n",
      "Processing ./img/resize\\003d552a8c003a71.jpg...\n",
      "\n",
      "0: 480x640 3 Human faces, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 003d552a8c003a71 - 1...\n",
      "Processing 003d552a8c003a71 - 2...\n",
      "Processing 003d552a8c003a71 - 3...\n",
      "Processing 003d552a8c003a71 - 4...\n",
      "Processing ./img/resize\\003d95e6cd092860.jpg...\n",
      "\n",
      "0: 480x640 1 Bird, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003d95e6cd092860 - 1...\n",
      "Processing ./img/resize\\003da671ae0e922b.jpg...\n",
      "\n",
      "0: 480x640 2 Aircrafts, 2 Alarm clocks, 3 Animals, 1 Auto part, 1 Baked goods, 2 Beds, 2 Books, 1 Bus, 1 Carnivore, 1 Dog, 1 Human body, 2 Human faces, 2 Salads, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "21\n",
      "Processing 003da671ae0e922b - 1...\n",
      "Processing 003da671ae0e922b - 2...\n",
      "Processing 003da671ae0e922b - 3...\n",
      "Processing 003da671ae0e922b - 4...\n",
      "Processing 003da671ae0e922b - 5...\n",
      "Processing 003da671ae0e922b - 6...\n",
      "Processing 003da671ae0e922b - 7...\n",
      "Processing 003da671ae0e922b - 8...\n",
      "Processing 003da671ae0e922b - 9...\n",
      "Processing 003da671ae0e922b - 10...\n",
      "Processing 003da671ae0e922b - 11...\n",
      "Processing 003da671ae0e922b - 12...\n",
      "Processing 003da671ae0e922b - 13...\n",
      "Processing 003da671ae0e922b - 14...\n",
      "Processing 003da671ae0e922b - 15...\n",
      "Processing 003da671ae0e922b - 16...\n",
      "Processing 003da671ae0e922b - 17...\n",
      "Processing 003da671ae0e922b - 18...\n",
      "Processing 003da671ae0e922b - 19...\n",
      "Processing 003da671ae0e922b - 20...\n",
      "Processing 003da671ae0e922b - 21...\n",
      "Processing ./img/resize\\003dbab6c081d6a1.jpg...\n",
      "\n",
      "0: 480x640 1 Moths and butterflies, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003dbab6c081d6a1 - 1...\n",
      "Processing ./img/resize\\003e107262a4213a.jpg...\n",
      "\n",
      "0: 480x640 1 Tank, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003e107262a4213a - 1...\n",
      "Processing ./img/resize\\003e363ce1f302cd.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\003e3ce72a55c426.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle helmet, 2 Bicycle wheels, 2 Coffee tables, 1 Common sunflower, 1 Footwear, 5 Goggless, 4 Persons, 1 Rose, 1 Tick, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "18\n",
      "Processing 003e3ce72a55c426 - 1...\n",
      "Processing 003e3ce72a55c426 - 2...\n",
      "Processing 003e3ce72a55c426 - 3...\n",
      "Processing 003e3ce72a55c426 - 4...\n",
      "Processing 003e3ce72a55c426 - 5...\n",
      "Processing 003e3ce72a55c426 - 6...\n",
      "Processing 003e3ce72a55c426 - 7...\n",
      "Processing 003e3ce72a55c426 - 8...\n",
      "Processing 003e3ce72a55c426 - 9...\n",
      "Processing 003e3ce72a55c426 - 10...\n",
      "Processing 003e3ce72a55c426 - 11...\n",
      "Processing 003e3ce72a55c426 - 12...\n",
      "Processing 003e3ce72a55c426 - 13...\n",
      "Processing 003e3ce72a55c426 - 14...\n",
      "Processing 003e3ce72a55c426 - 15...\n",
      "Processing 003e3ce72a55c426 - 16...\n",
      "Processing 003e3ce72a55c426 - 17...\n",
      "Processing 003e3ce72a55c426 - 18...\n",
      "Processing ./img/resize\\003e6c483db36d02.jpg...\n",
      "\n",
      "0: 480x640 3 Trees, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 003e6c483db36d02 - 1...\n",
      "Processing 003e6c483db36d02 - 2...\n",
      "Processing 003e6c483db36d02 - 3...\n",
      "Processing ./img/resize\\003e81428eb2dede.jpg...\n",
      "\n",
      "0: 480x640 2 Boxs, 1 Boy, 3 Cabinetrys, 1 Clothing, 6 Goggless, 2 Human faces, 1 Human head, 1 Human leg, 1 Man, 3 Trouserss, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "22\n",
      "Processing 003e81428eb2dede - 1...\n",
      "Processing 003e81428eb2dede - 2...\n",
      "Processing 003e81428eb2dede - 3...\n",
      "Processing 003e81428eb2dede - 4...\n",
      "Processing 003e81428eb2dede - 5...\n",
      "Processing 003e81428eb2dede - 6...\n",
      "Processing 003e81428eb2dede - 7...\n",
      "Processing 003e81428eb2dede - 8...\n",
      "Processing 003e81428eb2dede - 9...\n",
      "Processing 003e81428eb2dede - 10...\n",
      "Processing 003e81428eb2dede - 11...\n",
      "Processing 003e81428eb2dede - 12...\n",
      "Processing 003e81428eb2dede - 13...\n",
      "Processing 003e81428eb2dede - 14...\n",
      "Processing 003e81428eb2dede - 15...\n",
      "Processing 003e81428eb2dede - 16...\n",
      "Processing 003e81428eb2dede - 17...\n",
      "Processing 003e81428eb2dede - 18...\n",
      "Processing 003e81428eb2dede - 19...\n",
      "Processing 003e81428eb2dede - 20...\n",
      "Processing 003e81428eb2dede - 21...\n",
      "Processing 003e81428eb2dede - 22...\n",
      "Processing ./img/resize\\003ef1d321797f95.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\003f3bfa30c1a41c.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Candle, 1 Egg (Food), 2 Flowers, 1 Glasses, 1 Goggles, 1 Human head, 1 Sun hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 003f3bfa30c1a41c - 1...\n",
      "Processing 003f3bfa30c1a41c - 2...\n",
      "Processing 003f3bfa30c1a41c - 3...\n",
      "Processing 003f3bfa30c1a41c - 4...\n",
      "Processing 003f3bfa30c1a41c - 5...\n",
      "Processing 003f3bfa30c1a41c - 6...\n",
      "Processing 003f3bfa30c1a41c - 7...\n",
      "Processing 003f3bfa30c1a41c - 8...\n",
      "Processing 003f3bfa30c1a41c - 9...\n",
      "Processing ./img/resize\\003f414021b21407.jpg...\n",
      "\n",
      "0: 480x640 2 Houses, 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 003f414021b21407 - 1...\n",
      "Processing 003f414021b21407 - 2...\n",
      "Processing 003f414021b21407 - 3...\n",
      "Processing ./img/resize\\003f511905b3d29b.jpg...\n",
      "\n",
      "0: 480x640 1 Table, 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 003f511905b3d29b - 1...\n",
      "Processing ./img/resize\\003fc78237fc8e79.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0040231eafa37906.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Clothing, 1 Coffee table, 4 Egg (Food)s, 2 Sun hats, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 0040231eafa37906 - 1...\n",
      "Processing 0040231eafa37906 - 2...\n",
      "Processing 0040231eafa37906 - 3...\n",
      "Processing 0040231eafa37906 - 4...\n",
      "Processing 0040231eafa37906 - 5...\n",
      "Processing 0040231eafa37906 - 6...\n",
      "Processing 0040231eafa37906 - 7...\n",
      "Processing 0040231eafa37906 - 8...\n",
      "Processing 0040231eafa37906 - 9...\n",
      "Processing ./img/resize\\00402d44c6135333.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00408efc3cabdc4e.jpg...\n",
      "\n",
      "0: 480x640 1 Food, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00408efc3cabdc4e - 1...\n",
      "Processing ./img/resize\\0040a6ccec24886e.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0040a6ccec24886e - 1...\n",
      "Processing 0040a6ccec24886e - 2...\n",
      "Processing ./img/resize\\004104019f543c94.jpg...\n",
      "\n",
      "0: 480x640 2 Footwears, 1 Motorcycle, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 004104019f543c94 - 1...\n",
      "Processing 004104019f543c94 - 2...\n",
      "Processing 004104019f543c94 - 3...\n",
      "Processing ./img/resize\\0041397aa6ad08e6.jpg...\n",
      "\n",
      "0: 480x640 3 Boys, 1 Human face, 2 Mans, 1 Person, 1 Shirt, 2 Suits, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "10\n",
      "Processing 0041397aa6ad08e6 - 1...\n",
      "Processing 0041397aa6ad08e6 - 2...\n",
      "Processing 0041397aa6ad08e6 - 3...\n",
      "Processing 0041397aa6ad08e6 - 4...\n",
      "Processing 0041397aa6ad08e6 - 5...\n",
      "Processing 0041397aa6ad08e6 - 6...\n",
      "Processing 0041397aa6ad08e6 - 7...\n",
      "Processing 0041397aa6ad08e6 - 8...\n",
      "Processing 0041397aa6ad08e6 - 9...\n",
      "Processing 0041397aa6ad08e6 - 10...\n",
      "Processing ./img/resize\\0041d256e6445030.jpg...\n",
      "\n",
      "0: 480x640 1 Palm tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0041d256e6445030 - 1...\n",
      "Processing ./img/resize\\0042be9528ce34ea.jpg...\n",
      "\n",
      "0: 480x640 1 Mobile phone, 1 Tablet computer, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0042be9528ce34ea - 1...\n",
      "Processing 0042be9528ce34ea - 2...\n",
      "Processing ./img/resize\\0042ddc40f670a51.jpg...\n",
      "\n",
      "0: 480x640 1 Aircraft, 2 Animals, 2 Artichokes, 1 Boy, 1 Human face, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 0042ddc40f670a51 - 1...\n",
      "Processing 0042ddc40f670a51 - 2...\n",
      "Processing 0042ddc40f670a51 - 3...\n",
      "Processing 0042ddc40f670a51 - 4...\n",
      "Processing 0042ddc40f670a51 - 5...\n",
      "Processing 0042ddc40f670a51 - 6...\n",
      "Processing 0042ddc40f670a51 - 7...\n",
      "Processing ./img/resize\\00433c6e377ddca4.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 4 Persons, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00433c6e377ddca4 - 1...\n",
      "Processing 00433c6e377ddca4 - 2...\n",
      "Processing 00433c6e377ddca4 - 3...\n",
      "Processing 00433c6e377ddca4 - 4...\n",
      "Processing 00433c6e377ddca4 - 5...\n",
      "Processing ./img/resize\\0043812c7b263341.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0043abf968e5bb23.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle, 1 Bicycle wheel, 1 Wheel, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0043abf968e5bb23 - 1...\n",
      "Processing 0043abf968e5bb23 - 2...\n",
      "Processing 0043abf968e5bb23 - 3...\n",
      "Processing ./img/resize\\0043ad125f8d4a66.jpg...\n",
      "\n",
      "0: 480x640 1 Train, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0043ad125f8d4a66 - 1...\n",
      "Processing ./img/resize\\0043ee667cb084a7.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00447e8a5017f587.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 1 Human face, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00447e8a5017f587 - 1...\n",
      "Processing 00447e8a5017f587 - 2...\n",
      "Processing 00447e8a5017f587 - 3...\n",
      "Processing ./img/resize\\00447feff77fb089.jpg...\n",
      "\n",
      "0: 480x640 1 Footwear, 1 Waste container, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00447feff77fb089 - 1...\n",
      "Processing 00447feff77fb089 - 2...\n",
      "Processing ./img/resize\\0044a0aaee2e8009.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0045232476c41bcc.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0045232476c41bcc - 1...\n",
      "Processing 0045232476c41bcc - 2...\n",
      "Processing 0045232476c41bcc - 3...\n",
      "Processing ./img/resize\\0045305c9c3d4eff.jpg...\n",
      "\n",
      "0: 480x640 2 Trees, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0045305c9c3d4eff - 1...\n",
      "Processing 0045305c9c3d4eff - 2...\n",
      "Processing ./img/resize\\00456cbee2f9c18c.jpg...\n",
      "\n",
      "0: 480x640 2 Skyscrapers, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00456cbee2f9c18c - 1...\n",
      "Processing 00456cbee2f9c18c - 2...\n",
      "Processing ./img/resize\\0045b2dc66af6095.jpg...\n",
      "\n",
      "0: 480x640 2 Clothings, 1 Man, 1 Woman, 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0045b2dc66af6095 - 1...\n",
      "Processing 0045b2dc66af6095 - 2...\n",
      "Processing 0045b2dc66af6095 - 3...\n",
      "Processing 0045b2dc66af6095 - 4...\n",
      "Processing ./img/resize\\0045d88407bab692.jpg...\n",
      "\n",
      "0: 480x640 1 Bus, 1 Car, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0045d88407bab692 - 1...\n",
      "Processing 0045d88407bab692 - 2...\n",
      "Processing ./img/resize\\004708976637747e.jpg...\n",
      "\n",
      "0: 480x640 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 004708976637747e - 1...\n",
      "Processing ./img/resize\\0047238a365660a2.jpg...\n",
      "\n",
      "0: 480x640 1 Picture frame, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0047238a365660a2 - 1...\n",
      "Processing ./img/resize\\004731d03f8d6764.jpg...\n",
      "\n",
      "0: 480x640 3 Cars, 1 Wheel, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 004731d03f8d6764 - 1...\n",
      "Processing 004731d03f8d6764 - 2...\n",
      "Processing 004731d03f8d6764 - 3...\n",
      "Processing 004731d03f8d6764 - 4...\n",
      "Processing ./img/resize\\004793df03b93a02.jpg...\n",
      "\n",
      "0: 480x640 2 Goggless, 3 Lemons, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 004793df03b93a02 - 1...\n",
      "Processing 004793df03b93a02 - 2...\n",
      "Processing 004793df03b93a02 - 3...\n",
      "Processing 004793df03b93a02 - 4...\n",
      "Processing 004793df03b93a02 - 5...\n",
      "Processing ./img/resize\\0047fb2e2908c12d.jpg...\n",
      "\n",
      "0: 480x640 1 Bottle, 1 Bowl, 7 Boys, 1 Coffee cup, 6 Coffee tables, 1 Computer monitor, 1 Desk, 3 Egg (Food)s, 1 Goggles, 4 Grapefruits, 2 Human heads, 2 Laptops, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "30\n",
      "Processing 0047fb2e2908c12d - 1...\n",
      "Processing 0047fb2e2908c12d - 2...\n",
      "Processing 0047fb2e2908c12d - 3...\n",
      "Processing 0047fb2e2908c12d - 4...\n",
      "Processing 0047fb2e2908c12d - 5...\n",
      "Processing 0047fb2e2908c12d - 6...\n",
      "Processing 0047fb2e2908c12d - 7...\n",
      "Processing 0047fb2e2908c12d - 8...\n",
      "Processing 0047fb2e2908c12d - 9...\n",
      "Processing 0047fb2e2908c12d - 10...\n",
      "Processing 0047fb2e2908c12d - 11...\n",
      "Processing 0047fb2e2908c12d - 12...\n",
      "Processing 0047fb2e2908c12d - 13...\n",
      "Processing 0047fb2e2908c12d - 14...\n",
      "Processing 0047fb2e2908c12d - 15...\n",
      "Processing 0047fb2e2908c12d - 16...\n",
      "Processing 0047fb2e2908c12d - 17...\n",
      "Processing 0047fb2e2908c12d - 18...\n",
      "Processing 0047fb2e2908c12d - 19...\n",
      "Processing 0047fb2e2908c12d - 20...\n",
      "Processing 0047fb2e2908c12d - 21...\n",
      "Processing 0047fb2e2908c12d - 22...\n",
      "Processing 0047fb2e2908c12d - 23...\n",
      "Processing 0047fb2e2908c12d - 24...\n",
      "Processing 0047fb2e2908c12d - 25...\n",
      "Processing 0047fb2e2908c12d - 26...\n",
      "Processing 0047fb2e2908c12d - 27...\n",
      "Processing 0047fb2e2908c12d - 28...\n",
      "Processing 0047fb2e2908c12d - 29...\n",
      "Processing 0047fb2e2908c12d - 30...\n",
      "Processing ./img/resize\\00480c44f2f0816a.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 2 Suits, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00480c44f2f0816a - 1...\n",
      "Processing 00480c44f2f0816a - 2...\n",
      "Processing 00480c44f2f0816a - 3...\n",
      "Processing 00480c44f2f0816a - 4...\n",
      "Processing ./img/resize\\004819c00b00ab6b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0048235182f8dd64.jpg...\n",
      "\n",
      "0: 480x640 1 Helmet, 2 Persons, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0048235182f8dd64 - 1...\n",
      "Processing 0048235182f8dd64 - 2...\n",
      "Processing 0048235182f8dd64 - 3...\n",
      "Processing ./img/resize\\00482b01579b3cc4.jpg...\n",
      "\n",
      "0: 480x640 1 Dress, 1 Fashion accessory, 1 Girl, 1 Human face, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00482b01579b3cc4 - 1...\n",
      "Processing 00482b01579b3cc4 - 2...\n",
      "Processing 00482b01579b3cc4 - 3...\n",
      "Processing 00482b01579b3cc4 - 4...\n",
      "Processing ./img/resize\\004859f5eb4318f9.jpg...\n",
      "\n",
      "0: 480x640 1 Egg (Food), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 004859f5eb4318f9 - 1...\n",
      "Processing ./img/resize\\00488350fe3522bb.jpg...\n",
      "\n",
      "0: 480x640 1 Swimming pool, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00488350fe3522bb - 1...\n",
      "Processing ./img/resize\\004889d86625d7a5.jpg...\n",
      "\n",
      "0: 480x640 1 Ball, 3 Boys, 1 Chair, 2 Coffee tables, 1 Computer monitor, 1 Egg (Food), 1 Goggles, 2 Lighthouses, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "12\n",
      "Processing 004889d86625d7a5 - 1...\n",
      "Processing 004889d86625d7a5 - 2...\n",
      "Processing 004889d86625d7a5 - 3...\n",
      "Processing 004889d86625d7a5 - 4...\n",
      "Processing 004889d86625d7a5 - 5...\n",
      "Processing 004889d86625d7a5 - 6...\n",
      "Processing 004889d86625d7a5 - 7...\n",
      "Processing 004889d86625d7a5 - 8...\n",
      "Processing 004889d86625d7a5 - 9...\n",
      "Processing 004889d86625d7a5 - 10...\n",
      "Processing 004889d86625d7a5 - 11...\n",
      "Processing 004889d86625d7a5 - 12...\n",
      "Processing ./img/resize\\0048aff8e997b7bb.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0048cd69bce72312.jpg...\n",
      "\n",
      "0: 480x640 2 Flowers, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0048cd69bce72312 - 1...\n",
      "Processing 0048cd69bce72312 - 2...\n",
      "Processing ./img/resize\\00499e70eefed751.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00499e70eefed751 - 1...\n",
      "Processing ./img/resize\\0049bd1814cbfc3c.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0049bd1814cbfc3c - 1...\n",
      "Processing 0049bd1814cbfc3c - 2...\n",
      "Processing ./img/resize\\004a41a2e92e241f.jpg...\n",
      "\n",
      "0: 480x640 1 Coffee table, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 004a41a2e92e241f - 1...\n",
      "Processing ./img/resize\\004a6099ed6f3062.jpg...\n",
      "\n",
      "0: 480x640 2 Flowerpots, 2 Houseplants, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 004a6099ed6f3062 - 1...\n",
      "Processing 004a6099ed6f3062 - 2...\n",
      "Processing 004a6099ed6f3062 - 3...\n",
      "Processing 004a6099ed6f3062 - 4...\n",
      "Processing ./img/resize\\004aaa5c62159f7c.jpg...\n",
      "\n",
      "0: 480x640 2 Clothings, 1 Man, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 004aaa5c62159f7c - 1...\n",
      "Processing 004aaa5c62159f7c - 2...\n",
      "Processing 004aaa5c62159f7c - 3...\n",
      "Processing ./img/resize\\004ac88c02edd9e4.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\004b2e45806fe90b.jpg...\n",
      "\n",
      "0: 480x640 2 Boys, 2 Egg (Food)s, 1 Goggles, 2 Human heads, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 004b2e45806fe90b - 1...\n",
      "Processing 004b2e45806fe90b - 2...\n",
      "Processing 004b2e45806fe90b - 3...\n",
      "Processing 004b2e45806fe90b - 4...\n",
      "Processing 004b2e45806fe90b - 5...\n",
      "Processing 004b2e45806fe90b - 6...\n",
      "Processing 004b2e45806fe90b - 7...\n",
      "Processing ./img/resize\\004b3b4cce83475d.jpg...\n",
      "\n",
      "0: 480x640 3 Clothings, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 004b3b4cce83475d - 1...\n",
      "Processing 004b3b4cce83475d - 2...\n",
      "Processing 004b3b4cce83475d - 3...\n",
      "Processing 004b3b4cce83475d - 4...\n",
      "Processing ./img/resize\\004b4401a0017541.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 1 Stairs, 2 Windows, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 004b4401a0017541 - 1...\n",
      "Processing 004b4401a0017541 - 2...\n",
      "Processing 004b4401a0017541 - 3...\n",
      "Processing 004b4401a0017541 - 4...\n",
      "Processing ./img/resize\\004b56d9a86bd87d.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 004b56d9a86bd87d - 1...\n",
      "Processing ./img/resize\\004bba7df7258f7c.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\004bbd1d98d9eaae.jpg...\n",
      "\n",
      "0: 480x640 1 Egg (Food), 1 Human face, 1 Swimwear, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 004bbd1d98d9eaae - 1...\n",
      "Processing 004bbd1d98d9eaae - 2...\n",
      "Processing 004bbd1d98d9eaae - 3...\n",
      "Processing ./img/resize\\004bd64410736c69.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\004be5bac3360204.jpg...\n",
      "\n",
      "0: 480x640 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 004be5bac3360204 - 1...\n",
      "Processing ./img/resize\\004bfb9ff6b61f82.jpg...\n",
      "\n",
      "0: 480x640 4 Aircrafts, 1 Animal, 1 Coffee cup, 1 Human hair, 1 Human head, 1 Rose, 1 Saucer, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "10\n",
      "Processing 004bfb9ff6b61f82 - 1...\n",
      "Processing 004bfb9ff6b61f82 - 2...\n",
      "Processing 004bfb9ff6b61f82 - 3...\n",
      "Processing 004bfb9ff6b61f82 - 4...\n",
      "Processing 004bfb9ff6b61f82 - 5...\n",
      "Processing 004bfb9ff6b61f82 - 6...\n",
      "Processing 004bfb9ff6b61f82 - 7...\n",
      "Processing 004bfb9ff6b61f82 - 8...\n",
      "Processing 004bfb9ff6b61f82 - 9...\n",
      "Processing 004bfb9ff6b61f82 - 10...\n",
      "Processing ./img/resize\\004c196c18277e76.jpg...\n",
      "\n",
      "0: 480x640 3 Human faces, 2 Mans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 004c196c18277e76 - 1...\n",
      "Processing 004c196c18277e76 - 2...\n",
      "Processing 004c196c18277e76 - 3...\n",
      "Processing 004c196c18277e76 - 4...\n",
      "Processing 004c196c18277e76 - 5...\n",
      "Processing ./img/resize\\004c1c2b94414d04.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 004c1c2b94414d04 - 1...\n",
      "Processing 004c1c2b94414d04 - 2...\n",
      "Processing ./img/resize\\004c4ae05a363ccf.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\004c9e87184e8f58.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 004c9e87184e8f58 - 1...\n",
      "Processing 004c9e87184e8f58 - 2...\n",
      "Processing 004c9e87184e8f58 - 3...\n",
      "Processing ./img/resize\\004ca1ea0760e7ef.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 6 Coffee tables, 1 Egg (Food), 4 Grapefruits, 2 Human heads, 2 Shirts, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "16\n",
      "Processing 004ca1ea0760e7ef - 1...\n",
      "Processing 004ca1ea0760e7ef - 2...\n",
      "Processing 004ca1ea0760e7ef - 3...\n",
      "Processing 004ca1ea0760e7ef - 4...\n",
      "Processing 004ca1ea0760e7ef - 5...\n",
      "Processing 004ca1ea0760e7ef - 6...\n",
      "Processing 004ca1ea0760e7ef - 7...\n",
      "Processing 004ca1ea0760e7ef - 8...\n",
      "Processing 004ca1ea0760e7ef - 9...\n",
      "Processing 004ca1ea0760e7ef - 10...\n",
      "Processing 004ca1ea0760e7ef - 11...\n",
      "Processing 004ca1ea0760e7ef - 12...\n",
      "Processing 004ca1ea0760e7ef - 13...\n",
      "Processing 004ca1ea0760e7ef - 14...\n",
      "Processing 004ca1ea0760e7ef - 15...\n",
      "Processing 004ca1ea0760e7ef - 16...\n",
      "Processing ./img/resize\\004cb569de00934c.jpg...\n",
      "\n",
      "0: 480x640 2 Bicycles, 4 Bicycle wheels, 2 Persons, 5 Wheels, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "13\n",
      "Processing 004cb569de00934c - 1...\n",
      "Processing 004cb569de00934c - 2...\n",
      "Processing 004cb569de00934c - 3...\n",
      "Processing 004cb569de00934c - 4...\n",
      "Processing 004cb569de00934c - 5...\n",
      "Processing 004cb569de00934c - 6...\n",
      "Processing 004cb569de00934c - 7...\n",
      "Processing 004cb569de00934c - 8...\n",
      "Processing 004cb569de00934c - 9...\n",
      "Processing 004cb569de00934c - 10...\n",
      "Processing 004cb569de00934c - 11...\n",
      "Processing 004cb569de00934c - 12...\n",
      "Processing 004cb569de00934c - 13...\n",
      "Processing ./img/resize\\004cfffa4b67bb5e.jpg...\n",
      "\n",
      "0: 480x640 1 Coffee table, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 004cfffa4b67bb5e - 1...\n",
      "Processing ./img/resize\\004d534a2552a90d.jpg...\n",
      "\n",
      "0: 480x640 3 Footwears, 1 Girl, 5 Human faces, 1 Man, 1 Pumpkin, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 004d534a2552a90d - 1...\n",
      "Processing 004d534a2552a90d - 2...\n",
      "Processing 004d534a2552a90d - 3...\n",
      "Processing 004d534a2552a90d - 4...\n",
      "Processing 004d534a2552a90d - 5...\n",
      "Processing 004d534a2552a90d - 6...\n",
      "Processing 004d534a2552a90d - 7...\n",
      "Processing 004d534a2552a90d - 8...\n",
      "Processing 004d534a2552a90d - 9...\n",
      "Processing 004d534a2552a90d - 10...\n",
      "Processing 004d534a2552a90d - 11...\n",
      "Processing ./img/resize\\004d5d0c09f93c3a.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 004d5d0c09f93c3a - 1...\n",
      "Processing ./img/resize\\004d6584538801e7.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Person, 1 Rose, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 004d6584538801e7 - 1...\n",
      "Processing 004d6584538801e7 - 2...\n",
      "Processing 004d6584538801e7 - 3...\n",
      "Processing ./img/resize\\004d7158d17f2343.jpg...\n",
      "\n",
      "0: 480x640 1 Bowl, 6 Boys, 1 Clothing, 1 Coffee cup, 5 Coffee tables, 1 Egg (Food), 3 Grapefruits, 1 Human head, 3 Porchs, 6 Sun hats, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "28\n",
      "Processing 004d7158d17f2343 - 1...\n",
      "Processing 004d7158d17f2343 - 2...\n",
      "Processing 004d7158d17f2343 - 3...\n",
      "Processing 004d7158d17f2343 - 4...\n",
      "Processing 004d7158d17f2343 - 5...\n",
      "Processing 004d7158d17f2343 - 6...\n",
      "Processing 004d7158d17f2343 - 7...\n",
      "Processing 004d7158d17f2343 - 8...\n",
      "Processing 004d7158d17f2343 - 9...\n",
      "Processing 004d7158d17f2343 - 10...\n",
      "Processing 004d7158d17f2343 - 11...\n",
      "Processing 004d7158d17f2343 - 12...\n",
      "Processing 004d7158d17f2343 - 13...\n",
      "Processing 004d7158d17f2343 - 14...\n",
      "Processing 004d7158d17f2343 - 15...\n",
      "Processing 004d7158d17f2343 - 16...\n",
      "Processing 004d7158d17f2343 - 17...\n",
      "Processing 004d7158d17f2343 - 18...\n",
      "Processing 004d7158d17f2343 - 19...\n",
      "Processing 004d7158d17f2343 - 20...\n",
      "Processing 004d7158d17f2343 - 21...\n",
      "Processing 004d7158d17f2343 - 22...\n",
      "Processing 004d7158d17f2343 - 23...\n",
      "Processing 004d7158d17f2343 - 24...\n",
      "Processing 004d7158d17f2343 - 25...\n",
      "Processing 004d7158d17f2343 - 26...\n",
      "Processing 004d7158d17f2343 - 27...\n",
      "Processing 004d7158d17f2343 - 28...\n",
      "Processing ./img/resize\\004d7305c3733bf1.jpg...\n",
      "\n",
      "0: 480x640 1 Train, 2 Trees, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 004d7305c3733bf1 - 1...\n",
      "Processing 004d7305c3733bf1 - 2...\n",
      "Processing 004d7305c3733bf1 - 3...\n",
      "Processing ./img/resize\\004da9e46e11f5ed.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 004da9e46e11f5ed - 1...\n",
      "Processing ./img/resize\\004dbb8b67544b24.jpg...\n",
      "\n",
      "0: 480x640 1 Tower, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 004dbb8b67544b24 - 1...\n",
      "Processing ./img/resize\\004e26b41de45ed0.jpg...\n",
      "\n",
      "0: 480x640 1 Bus, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 004e26b41de45ed0 - 1...\n",
      "Processing ./img/resize\\004e556570882f12.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 1 Human face, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 004e556570882f12 - 1...\n",
      "Processing 004e556570882f12 - 2...\n",
      "Processing 004e556570882f12 - 3...\n",
      "Processing ./img/resize\\004e6ac14ea2e218.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\004e831e8776c027.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Dress, 1 Egg (Food), 1 Human head, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 004e831e8776c027 - 1...\n",
      "Processing 004e831e8776c027 - 2...\n",
      "Processing 004e831e8776c027 - 3...\n",
      "Processing 004e831e8776c027 - 4...\n",
      "Processing ./img/resize\\004ebde228ffe228.jpg...\n",
      "\n",
      "0: 480x640 1 Seafood, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 004ebde228ffe228 - 1...\n",
      "Processing ./img/resize\\004efdfdf97633a9.jpg...\n",
      "\n",
      "0: 480x640 1 Aircraft, 6 Animals, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 004efdfdf97633a9 - 1...\n",
      "Processing 004efdfdf97633a9 - 2...\n",
      "Processing 004efdfdf97633a9 - 3...\n",
      "Processing 004efdfdf97633a9 - 4...\n",
      "Processing 004efdfdf97633a9 - 5...\n",
      "Processing 004efdfdf97633a9 - 6...\n",
      "Processing 004efdfdf97633a9 - 7...\n",
      "Processing ./img/resize\\004f69ca166485d4.jpg...\n",
      "\n",
      "0: 480x640 2 Balls, 1 Bicycle helmet, 2 Coffee tables, 1 Dice, 1 Mushroom, 1 Rose, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 004f69ca166485d4 - 1...\n",
      "Processing 004f69ca166485d4 - 2...\n",
      "Processing 004f69ca166485d4 - 3...\n",
      "Processing 004f69ca166485d4 - 4...\n",
      "Processing 004f69ca166485d4 - 5...\n",
      "Processing 004f69ca166485d4 - 6...\n",
      "Processing 004f69ca166485d4 - 7...\n",
      "Processing 004f69ca166485d4 - 8...\n",
      "Processing ./img/resize\\004f7e15dbe2b286.jpg...\n",
      "\n",
      "0: 480x640 3 Human faces, 1 Man, 2 Suits, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 004f7e15dbe2b286 - 1...\n",
      "Processing 004f7e15dbe2b286 - 2...\n",
      "Processing 004f7e15dbe2b286 - 3...\n",
      "Processing 004f7e15dbe2b286 - 4...\n",
      "Processing 004f7e15dbe2b286 - 5...\n",
      "Processing 004f7e15dbe2b286 - 6...\n",
      "Processing ./img/resize\\0050b475a0ae0992.jpg...\n",
      "\n",
      "0: 480x640 3 Clothings, 5 Mans, 3 Womans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 0050b475a0ae0992 - 1...\n",
      "Processing 0050b475a0ae0992 - 2...\n",
      "Processing 0050b475a0ae0992 - 3...\n",
      "Processing 0050b475a0ae0992 - 4...\n",
      "Processing 0050b475a0ae0992 - 5...\n",
      "Processing 0050b475a0ae0992 - 6...\n",
      "Processing 0050b475a0ae0992 - 7...\n",
      "Processing 0050b475a0ae0992 - 8...\n",
      "Processing 0050b475a0ae0992 - 9...\n",
      "Processing 0050b475a0ae0992 - 10...\n",
      "Processing 0050b475a0ae0992 - 11...\n",
      "Processing ./img/resize\\0050e8dc77246dff.jpg...\n",
      "\n",
      "0: 480x640 2 Dresss, 1 Man, 2 Palm trees, 2 Womans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 0050e8dc77246dff - 1...\n",
      "Processing 0050e8dc77246dff - 2...\n",
      "Processing 0050e8dc77246dff - 3...\n",
      "Processing 0050e8dc77246dff - 4...\n",
      "Processing 0050e8dc77246dff - 5...\n",
      "Processing 0050e8dc77246dff - 6...\n",
      "Processing 0050e8dc77246dff - 7...\n",
      "Processing ./img/resize\\0050f2924c71a807.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0051805f87a055f0.jpg...\n",
      "\n",
      "0: 480x640 1 Cocktail, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0051805f87a055f0 - 1...\n",
      "Processing ./img/resize\\005186431682c2bb.jpg...\n",
      "\n",
      "0: 480x640 1 Office building, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005186431682c2bb - 1...\n",
      "Processing ./img/resize\\0051c85dfc6724eb.jpg...\n",
      "\n",
      "0: 480x640 1 Baked goods, 11 Bananas, 1 Box, 1 Common sunflower, 2 Fast foods, 3 French friess, 3 Goggless, 3 Lilys, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "25\n",
      "Processing 0051c85dfc6724eb - 1...\n",
      "Processing 0051c85dfc6724eb - 2...\n",
      "Processing 0051c85dfc6724eb - 3...\n",
      "Processing 0051c85dfc6724eb - 4...\n",
      "Processing 0051c85dfc6724eb - 5...\n",
      "Processing 0051c85dfc6724eb - 6...\n",
      "Processing 0051c85dfc6724eb - 7...\n",
      "Processing 0051c85dfc6724eb - 8...\n",
      "Processing 0051c85dfc6724eb - 9...\n",
      "Processing 0051c85dfc6724eb - 10...\n",
      "Processing 0051c85dfc6724eb - 11...\n",
      "Processing 0051c85dfc6724eb - 12...\n",
      "Processing 0051c85dfc6724eb - 13...\n",
      "Processing 0051c85dfc6724eb - 14...\n",
      "Processing 0051c85dfc6724eb - 15...\n",
      "Processing 0051c85dfc6724eb - 16...\n",
      "Processing 0051c85dfc6724eb - 17...\n",
      "Processing 0051c85dfc6724eb - 18...\n",
      "Processing 0051c85dfc6724eb - 19...\n",
      "Processing 0051c85dfc6724eb - 20...\n",
      "Processing 0051c85dfc6724eb - 21...\n",
      "Processing 0051c85dfc6724eb - 22...\n",
      "Processing 0051c85dfc6724eb - 23...\n",
      "Processing 0051c85dfc6724eb - 24...\n",
      "Processing 0051c85dfc6724eb - 25...\n",
      "Processing ./img/resize\\0051d8810200683c.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0051d8810200683c - 1...\n",
      "Processing ./img/resize\\00528bee18c84e0f.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00528bee18c84e0f - 1...\n",
      "Processing ./img/resize\\005320fec36fd4d0.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Jacket, 1 Man, 1 Sunglasses, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 005320fec36fd4d0 - 1...\n",
      "Processing 005320fec36fd4d0 - 2...\n",
      "Processing 005320fec36fd4d0 - 3...\n",
      "Processing 005320fec36fd4d0 - 4...\n",
      "Processing ./img/resize\\00534750623a7661.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\005363e3025af8cb.jpg...\n",
      "\n",
      "0: 480x640 1 Jeans, 3 Mans, 4 Womans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 005363e3025af8cb - 1...\n",
      "Processing 005363e3025af8cb - 2...\n",
      "Processing 005363e3025af8cb - 3...\n",
      "Processing 005363e3025af8cb - 4...\n",
      "Processing 005363e3025af8cb - 5...\n",
      "Processing 005363e3025af8cb - 6...\n",
      "Processing 005363e3025af8cb - 7...\n",
      "Processing 005363e3025af8cb - 8...\n",
      "Processing ./img/resize\\0053706e944e9990.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0053706e944e9990 - 1...\n",
      "Processing ./img/resize\\00539217a881ae90.jpg...\n",
      "\n",
      "0: 480x640 1 Bird, 1 Sparrow, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00539217a881ae90 - 1...\n",
      "Processing 00539217a881ae90 - 2...\n",
      "Processing ./img/resize\\005411366689cf10.jpg...\n",
      "\n",
      "0: 480x640 1 Candy, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005411366689cf10 - 1...\n",
      "Processing ./img/resize\\00541b3fca88462c.jpg...\n",
      "\n",
      "0: 480x640 2 Balls, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00541b3fca88462c - 1...\n",
      "Processing 00541b3fca88462c - 2...\n",
      "Processing ./img/resize\\005456d1c6ae07cc.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005456d1c6ae07cc - 1...\n",
      "Processing ./img/resize\\005457d1ec6f884d.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00546ff848106b78.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00546ff848106b78 - 1...\n",
      "Processing ./img/resize\\005482dc62a0615b.jpg...\n",
      "\n",
      "0: 480x640 1 Airplane, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005482dc62a0615b - 1...\n",
      "Processing ./img/resize\\0054b0e43d405877.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0054d95b1cf1ecad.jpg...\n",
      "\n",
      "0: 480x640 1 Ant, 9 Balls, 3 Castles, 13 Goggless, 1 Helmet, 1 Human face, 1 Human hair, 1 Human head, 2 Human noses, 1 Jacket, 1 Lighthouse, 1 Man, 1 Microphone, 1 Suit, 1 Swim cap, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "38\n",
      "Processing 0054d95b1cf1ecad - 1...\n",
      "Processing 0054d95b1cf1ecad - 2...\n",
      "Processing 0054d95b1cf1ecad - 3...\n",
      "Processing 0054d95b1cf1ecad - 4...\n",
      "Processing 0054d95b1cf1ecad - 5...\n",
      "Processing 0054d95b1cf1ecad - 6...\n",
      "Processing 0054d95b1cf1ecad - 7...\n",
      "Processing 0054d95b1cf1ecad - 8...\n",
      "Processing 0054d95b1cf1ecad - 9...\n",
      "Processing 0054d95b1cf1ecad - 10...\n",
      "Processing 0054d95b1cf1ecad - 11...\n",
      "Processing 0054d95b1cf1ecad - 12...\n",
      "Processing 0054d95b1cf1ecad - 13...\n",
      "Processing 0054d95b1cf1ecad - 14...\n",
      "Processing 0054d95b1cf1ecad - 15...\n",
      "Processing 0054d95b1cf1ecad - 16...\n",
      "Processing 0054d95b1cf1ecad - 17...\n",
      "Processing 0054d95b1cf1ecad - 18...\n",
      "Processing 0054d95b1cf1ecad - 19...\n",
      "Processing 0054d95b1cf1ecad - 20...\n",
      "Processing 0054d95b1cf1ecad - 21...\n",
      "Processing 0054d95b1cf1ecad - 22...\n",
      "Processing 0054d95b1cf1ecad - 23...\n",
      "Processing 0054d95b1cf1ecad - 24...\n",
      "Processing 0054d95b1cf1ecad - 25...\n",
      "Processing 0054d95b1cf1ecad - 26...\n",
      "Processing 0054d95b1cf1ecad - 27...\n",
      "Processing 0054d95b1cf1ecad - 28...\n",
      "Processing 0054d95b1cf1ecad - 29...\n",
      "Processing 0054d95b1cf1ecad - 30...\n",
      "Processing 0054d95b1cf1ecad - 31...\n",
      "Processing 0054d95b1cf1ecad - 32...\n",
      "Processing 0054d95b1cf1ecad - 33...\n",
      "Processing 0054d95b1cf1ecad - 34...\n",
      "Processing 0054d95b1cf1ecad - 35...\n",
      "Processing 0054d95b1cf1ecad - 36...\n",
      "Processing 0054d95b1cf1ecad - 37...\n",
      "Processing 0054d95b1cf1ecad - 38...\n",
      "Processing ./img/resize\\0054f5a2079ea937.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00550d41f68db31b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0055444dd2ab3489.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0055bdcd0c2965ca.jpg...\n",
      "\n",
      "0: 480x640 2 Buss, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0055bdcd0c2965ca - 1...\n",
      "Processing 0055bdcd0c2965ca - 2...\n",
      "Processing ./img/resize\\0055d83f58279e61.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 2 Cars, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0055d83f58279e61 - 1...\n",
      "Processing 0055d83f58279e61 - 2...\n",
      "Processing 0055d83f58279e61 - 3...\n",
      "Processing ./img/resize\\0055f7e5bac0c8e1.jpg...\n",
      "\n",
      "0: 480x640 1 Orange, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0055f7e5bac0c8e1 - 1...\n",
      "Processing ./img/resize\\00562ca23aa5b4b9.jpg...\n",
      "\n",
      "0: 480x640 1 Dress, 1 Man, 2 Trees, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00562ca23aa5b4b9 - 1...\n",
      "Processing 00562ca23aa5b4b9 - 2...\n",
      "Processing 00562ca23aa5b4b9 - 3...\n",
      "Processing 00562ca23aa5b4b9 - 4...\n",
      "Processing 00562ca23aa5b4b9 - 5...\n",
      "Processing ./img/resize\\00562f156bb23618.jpg...\n",
      "\n",
      "0: 480x640 4 Boys, 1 Grapefruit, 1 Human face, 4 Human heads, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "10\n",
      "Processing 00562f156bb23618 - 1...\n",
      "Processing 00562f156bb23618 - 2...\n",
      "Processing 00562f156bb23618 - 3...\n",
      "Processing 00562f156bb23618 - 4...\n",
      "Processing 00562f156bb23618 - 5...\n",
      "Processing 00562f156bb23618 - 6...\n",
      "Processing 00562f156bb23618 - 7...\n",
      "Processing 00562f156bb23618 - 8...\n",
      "Processing 00562f156bb23618 - 9...\n",
      "Processing 00562f156bb23618 - 10...\n",
      "Processing ./img/resize\\0056496ee24a4912.jpg...\n",
      "\n",
      "0: 480x640 1 Squirrel, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0056496ee24a4912 - 1...\n",
      "Processing ./img/resize\\0056595e121189ca.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0056931e46ed0539.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle, 2 Bicycle wheels, 1 Person, 1 Tire, 2 Wheels, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 0056931e46ed0539 - 1...\n",
      "Processing 0056931e46ed0539 - 2...\n",
      "Processing 0056931e46ed0539 - 3...\n",
      "Processing 0056931e46ed0539 - 4...\n",
      "Processing 0056931e46ed0539 - 5...\n",
      "Processing 0056931e46ed0539 - 6...\n",
      "Processing 0056931e46ed0539 - 7...\n",
      "Processing ./img/resize\\00569cec03db8b35.jpg...\n",
      "\n",
      "0: 480x640 1 Rose, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00569cec03db8b35 - 1...\n",
      "Processing ./img/resize\\0056afacd8e42b30.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0056afacd8e42b30 - 1...\n",
      "Processing 0056afacd8e42b30 - 2...\n",
      "Processing ./img/resize\\0056bee46d2090cf.jpg...\n",
      "\n",
      "0: 480x640 1 Footwear, 1 Man, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0056bee46d2090cf - 1...\n",
      "Processing 0056bee46d2090cf - 2...\n",
      "Processing 0056bee46d2090cf - 3...\n",
      "Processing ./img/resize\\0056e1ded12e8f07.jpg...\n",
      "\n",
      "0: 480x640 1 Whiteboard, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0056e1ded12e8f07 - 1...\n",
      "Processing ./img/resize\\0056ffa92a35158d.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0056ffa92a35158d - 1...\n",
      "Processing ./img/resize\\005709151ec27bd5.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00577ba8090b4549.jpg...\n",
      "\n",
      "0: 480x640 1 Christmas tree, 3 Clothings, 5 Mans, 2 Womans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 00577ba8090b4549 - 1...\n",
      "Processing 00577ba8090b4549 - 2...\n",
      "Processing 00577ba8090b4549 - 3...\n",
      "Processing 00577ba8090b4549 - 4...\n",
      "Processing 00577ba8090b4549 - 5...\n",
      "Processing 00577ba8090b4549 - 6...\n",
      "Processing 00577ba8090b4549 - 7...\n",
      "Processing 00577ba8090b4549 - 8...\n",
      "Processing 00577ba8090b4549 - 9...\n",
      "Processing 00577ba8090b4549 - 10...\n",
      "Processing 00577ba8090b4549 - 11...\n",
      "Processing ./img/resize\\0057b6b5e07e3241.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Human face, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0057b6b5e07e3241 - 1...\n",
      "Processing 0057b6b5e07e3241 - 2...\n",
      "Processing ./img/resize\\00580fd8545e2efc.jpg...\n",
      "\n",
      "0: 480x640 1 Dress, 1 Girl, 2 Human faces, 1 Human head, 1 Suit, 1 Sun hat, 1 Sunglasses, 1 Wine, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 00580fd8545e2efc - 1...\n",
      "Processing 00580fd8545e2efc - 2...\n",
      "Processing 00580fd8545e2efc - 3...\n",
      "Processing 00580fd8545e2efc - 4...\n",
      "Processing 00580fd8545e2efc - 5...\n",
      "Processing 00580fd8545e2efc - 6...\n",
      "Processing 00580fd8545e2efc - 7...\n",
      "Processing 00580fd8545e2efc - 8...\n",
      "Processing 00580fd8545e2efc - 9...\n",
      "Processing ./img/resize\\00584b3a4e064d09.jpg...\n",
      "\n",
      "0: 480x640 1 Bird, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00584b3a4e064d09 - 1...\n",
      "Processing ./img/resize\\00584f5adbdaddb7.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00584f5adbdaddb7 - 1...\n",
      "Processing 00584f5adbdaddb7 - 2...\n",
      "Processing ./img/resize\\00586fc3ebee6f46.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 3 Mans, 3 Suits, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00586fc3ebee6f46 - 1...\n",
      "Processing 00586fc3ebee6f46 - 2...\n",
      "Processing 00586fc3ebee6f46 - 3...\n",
      "Processing 00586fc3ebee6f46 - 4...\n",
      "Processing 00586fc3ebee6f46 - 5...\n",
      "Processing 00586fc3ebee6f46 - 6...\n",
      "Processing 00586fc3ebee6f46 - 7...\n",
      "Processing 00586fc3ebee6f46 - 8...\n",
      "Processing ./img/resize\\0058928240fe1561.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 1 Suit, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0058928240fe1561 - 1...\n",
      "Processing 0058928240fe1561 - 2...\n",
      "Processing 0058928240fe1561 - 3...\n",
      "Processing ./img/resize\\00589649724cb859.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0058a66b55b16606.jpg...\n",
      "\n",
      "0: 480x640 1 Beetle, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0058a66b55b16606 - 1...\n",
      "Processing ./img/resize\\0058d6bc4bba280d.jpg...\n",
      "\n",
      "0: 480x640 1 Guitar, 1 Microphone, 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0058d6bc4bba280d - 1...\n",
      "Processing 0058d6bc4bba280d - 2...\n",
      "Processing 0058d6bc4bba280d - 3...\n",
      "Processing ./img/resize\\0058fb1af173309f.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle, 1 Boat, 1 Wheel, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0058fb1af173309f - 1...\n",
      "Processing 0058fb1af173309f - 2...\n",
      "Processing 0058fb1af173309f - 3...\n",
      "Processing ./img/resize\\00590a12013cc333.jpg...\n",
      "\n",
      "0: 480x640 3 Windows, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00590a12013cc333 - 1...\n",
      "Processing 00590a12013cc333 - 2...\n",
      "Processing 00590a12013cc333 - 3...\n",
      "Processing ./img/resize\\00591cd6c1012c40.jpg...\n",
      "\n",
      "0: 480x640 7 Footwears, 1 Jeans, 2 Mans, 6 Womans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "16\n",
      "Processing 00591cd6c1012c40 - 1...\n",
      "Processing 00591cd6c1012c40 - 2...\n",
      "Processing 00591cd6c1012c40 - 3...\n",
      "Processing 00591cd6c1012c40 - 4...\n",
      "Processing 00591cd6c1012c40 - 5...\n",
      "Processing 00591cd6c1012c40 - 6...\n",
      "Processing 00591cd6c1012c40 - 7...\n",
      "Processing 00591cd6c1012c40 - 8...\n",
      "Processing 00591cd6c1012c40 - 9...\n",
      "Processing 00591cd6c1012c40 - 10...\n",
      "Processing 00591cd6c1012c40 - 11...\n",
      "Processing 00591cd6c1012c40 - 12...\n",
      "Processing 00591cd6c1012c40 - 13...\n",
      "Processing 00591cd6c1012c40 - 14...\n",
      "Processing 00591cd6c1012c40 - 15...\n",
      "Processing 00591cd6c1012c40 - 16...\n",
      "Processing ./img/resize\\005949b2719c70e2.jpg...\n",
      "\n",
      "0: 480x640 3 Clothings, 3 Human faces, 7 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "13\n",
      "Processing 005949b2719c70e2 - 1...\n",
      "Processing 005949b2719c70e2 - 2...\n",
      "Processing 005949b2719c70e2 - 3...\n",
      "Processing 005949b2719c70e2 - 4...\n",
      "Processing 005949b2719c70e2 - 5...\n",
      "Processing 005949b2719c70e2 - 6...\n",
      "Processing 005949b2719c70e2 - 7...\n",
      "Processing 005949b2719c70e2 - 8...\n",
      "Processing 005949b2719c70e2 - 9...\n",
      "Processing 005949b2719c70e2 - 10...\n",
      "Processing 005949b2719c70e2 - 11...\n",
      "Processing 005949b2719c70e2 - 12...\n",
      "Processing 005949b2719c70e2 - 13...\n",
      "Processing ./img/resize\\005980cfb1748efd.jpg...\n",
      "\n",
      "0: 480x640 1 Laptop, 1 Washing machine, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 005980cfb1748efd - 1...\n",
      "Processing 005980cfb1748efd - 2...\n",
      "Processing ./img/resize\\00599a4e08792ee1.jpg...\n",
      "\n",
      "0: 480x640 1 Squirrel, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00599a4e08792ee1 - 1...\n",
      "Processing ./img/resize\\0059abaf62d8fe22.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 5 Mans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 0059abaf62d8fe22 - 1...\n",
      "Processing 0059abaf62d8fe22 - 2...\n",
      "Processing 0059abaf62d8fe22 - 3...\n",
      "Processing 0059abaf62d8fe22 - 4...\n",
      "Processing 0059abaf62d8fe22 - 5...\n",
      "Processing 0059abaf62d8fe22 - 6...\n",
      "Processing ./img/resize\\0059eb01bba96297.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle wheel, 1 Centipede, 1 Cooking spray, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0059eb01bba96297 - 1...\n",
      "Processing 0059eb01bba96297 - 2...\n",
      "Processing 0059eb01bba96297 - 3...\n",
      "Processing ./img/resize\\0059fbca24021176.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0059fbca24021176 - 1...\n",
      "Processing ./img/resize\\005ac8a7e87fff43.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005ac8a7e87fff43 - 1...\n",
      "Processing ./img/resize\\005b0b20423d0687.jpg...\n",
      "\n",
      "0: 480x640 1 Flowerpot, 1 Houseplant, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 005b0b20423d0687 - 1...\n",
      "Processing 005b0b20423d0687 - 2...\n",
      "Processing ./img/resize\\005b1a18091cc6f8.jpg...\n",
      "\n",
      "0: 480x640 1 Girl, 1 Human face, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 005b1a18091cc6f8 - 1...\n",
      "Processing 005b1a18091cc6f8 - 2...\n",
      "Processing ./img/resize\\005b4ca3a3570432.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 005b4ca3a3570432 - 1...\n",
      "Processing 005b4ca3a3570432 - 2...\n",
      "Processing ./img/resize\\005b64d7a7dd7db0.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\005b6e54bee055d4.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\005b708f05e4e9b9.jpg...\n",
      "\n",
      "0: 480x640 5 Mans, 4 Suits, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 005b708f05e4e9b9 - 1...\n",
      "Processing 005b708f05e4e9b9 - 2...\n",
      "Processing 005b708f05e4e9b9 - 3...\n",
      "Processing 005b708f05e4e9b9 - 4...\n",
      "Processing 005b708f05e4e9b9 - 5...\n",
      "Processing 005b708f05e4e9b9 - 6...\n",
      "Processing 005b708f05e4e9b9 - 7...\n",
      "Processing 005b708f05e4e9b9 - 8...\n",
      "Processing 005b708f05e4e9b9 - 9...\n",
      "Processing ./img/resize\\005b8650920ee8fc.jpg...\n",
      "\n",
      "0: 480x640 2 Clothings, 1 Girl, 29.0ms\n",
      "Speed: 1.9ms preprocess, 29.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 005b8650920ee8fc - 1...\n",
      "Processing 005b8650920ee8fc - 2...\n",
      "Processing 005b8650920ee8fc - 3...\n",
      "Processing ./img/resize\\005baac9bd26fdaf.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 29.0ms\n",
      "Speed: 0.9ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 005baac9bd26fdaf - 1...\n",
      "Processing 005baac9bd26fdaf - 2...\n",
      "Processing ./img/resize\\005c0395c0472073.jpg...\n",
      "\n",
      "0: 480x640 1 Train, 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 005c0395c0472073 - 1...\n",
      "Processing 005c0395c0472073 - 2...\n",
      "Processing ./img/resize\\005c372dffca7998.jpg...\n",
      "\n",
      "0: 480x640 2 Clothings, 2 Womans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 005c372dffca7998 - 1...\n",
      "Processing 005c372dffca7998 - 2...\n",
      "Processing 005c372dffca7998 - 3...\n",
      "Processing 005c372dffca7998 - 4...\n",
      "Processing ./img/resize\\005c613ae4b47d24.jpg...\n",
      "\n",
      "0: 480x640 1 Cake, 2 Candles, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 005c613ae4b47d24 - 1...\n",
      "Processing 005c613ae4b47d24 - 2...\n",
      "Processing 005c613ae4b47d24 - 3...\n",
      "Processing ./img/resize\\005c64f8ba47c65c.jpg...\n",
      "\n",
      "0: 480x640 1 Poster, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005c64f8ba47c65c - 1...\n",
      "Processing ./img/resize\\005c698601bcdcb9.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 2 Cars, 1 Coffee table, 1 Egg (Food), 1 Goggles, 1 Human face, 1 Human head, 1 Sun hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 005c698601bcdcb9 - 1...\n",
      "Processing 005c698601bcdcb9 - 2...\n",
      "Processing 005c698601bcdcb9 - 3...\n",
      "Processing 005c698601bcdcb9 - 4...\n",
      "Processing 005c698601bcdcb9 - 5...\n",
      "Processing 005c698601bcdcb9 - 6...\n",
      "Processing 005c698601bcdcb9 - 7...\n",
      "Processing 005c698601bcdcb9 - 8...\n",
      "Processing 005c698601bcdcb9 - 9...\n",
      "Processing ./img/resize\\005c6f249c37ae16.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005c6f249c37ae16 - 1...\n",
      "Processing ./img/resize\\005caff546f21584.jpg...\n",
      "\n",
      "0: 480x640 1 Office building, 31.0ms\n",
      "Speed: 3.0ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005caff546f21584 - 1...\n",
      "Processing ./img/resize\\005cfe0addc5fc40.jpg...\n",
      "\n",
      "0: 480x640 5 Jackets, 5 Jeanss, 5 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "15\n",
      "Processing 005cfe0addc5fc40 - 1...\n",
      "Processing 005cfe0addc5fc40 - 2...\n",
      "Processing 005cfe0addc5fc40 - 3...\n",
      "Processing 005cfe0addc5fc40 - 4...\n",
      "Processing 005cfe0addc5fc40 - 5...\n",
      "Processing 005cfe0addc5fc40 - 6...\n",
      "Processing 005cfe0addc5fc40 - 7...\n",
      "Processing 005cfe0addc5fc40 - 8...\n",
      "Processing 005cfe0addc5fc40 - 9...\n",
      "Processing 005cfe0addc5fc40 - 10...\n",
      "Processing 005cfe0addc5fc40 - 11...\n",
      "Processing 005cfe0addc5fc40 - 12...\n",
      "Processing 005cfe0addc5fc40 - 13...\n",
      "Processing 005cfe0addc5fc40 - 14...\n",
      "Processing 005cfe0addc5fc40 - 15...\n",
      "Processing ./img/resize\\005d25e7c22cc24d.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005d25e7c22cc24d - 1...\n",
      "Processing ./img/resize\\005d380764c6ce1d.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\005d6523f6f0aa2f.jpg...\n",
      "\n",
      "0: 480x640 1 Mobile phone, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005d6523f6f0aa2f - 1...\n",
      "Processing ./img/resize\\005d805b5b987b41.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005d805b5b987b41 - 1...\n",
      "Processing ./img/resize\\005dc0d468615899.jpg...\n",
      "\n",
      "0: 480x640 1 Candy, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005dc0d468615899 - 1...\n",
      "Processing ./img/resize\\005e363863422dcb.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\005e9a55fc95abbb.jpg...\n",
      "\n",
      "0: 480x640 2 Flowers, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 005e9a55fc95abbb - 1...\n",
      "Processing 005e9a55fc95abbb - 2...\n",
      "Processing ./img/resize\\005f4899fd5be1ef.jpg...\n",
      "\n",
      "0: 480x640 1 Cat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 005f4899fd5be1ef - 1...\n",
      "Processing ./img/resize\\005f5c5572d3f0cc.jpg...\n",
      "\n",
      "0: 480x640 1 Egg (Food), 3 Human heads, 1 Sun hat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 005f5c5572d3f0cc - 1...\n",
      "Processing 005f5c5572d3f0cc - 2...\n",
      "Processing 005f5c5572d3f0cc - 3...\n",
      "Processing 005f5c5572d3f0cc - 4...\n",
      "Processing 005f5c5572d3f0cc - 5...\n",
      "Processing ./img/resize\\005f6bd12442acb3.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 005f6bd12442acb3 - 1...\n",
      "Processing 005f6bd12442acb3 - 2...\n",
      "Processing ./img/resize\\005f9567f94efa14.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00608584620d00f9.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00608584620d00f9 - 1...\n",
      "Processing ./img/resize\\0060a27761b0fd63.jpg...\n",
      "\n",
      "0: 480x640 1 Bowl, 5 Boys, 1 Coat, 4 Coffee tables, 1 Computer monitor, 4 Egg (Food)s, 1 Goggles, 2 Grapefruits, 1 Human arm, 2 Human heads, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "22\n",
      "Processing 0060a27761b0fd63 - 1...\n",
      "Processing 0060a27761b0fd63 - 2...\n",
      "Processing 0060a27761b0fd63 - 3...\n",
      "Processing 0060a27761b0fd63 - 4...\n",
      "Processing 0060a27761b0fd63 - 5...\n",
      "Processing 0060a27761b0fd63 - 6...\n",
      "Processing 0060a27761b0fd63 - 7...\n",
      "Processing 0060a27761b0fd63 - 8...\n",
      "Processing 0060a27761b0fd63 - 9...\n",
      "Processing 0060a27761b0fd63 - 10...\n",
      "Processing 0060a27761b0fd63 - 11...\n",
      "Processing 0060a27761b0fd63 - 12...\n",
      "Processing 0060a27761b0fd63 - 13...\n",
      "Processing 0060a27761b0fd63 - 14...\n",
      "Processing 0060a27761b0fd63 - 15...\n",
      "Processing 0060a27761b0fd63 - 16...\n",
      "Processing 0060a27761b0fd63 - 17...\n",
      "Processing 0060a27761b0fd63 - 18...\n",
      "Processing 0060a27761b0fd63 - 19...\n",
      "Processing 0060a27761b0fd63 - 20...\n",
      "Processing 0060a27761b0fd63 - 21...\n",
      "Processing 0060a27761b0fd63 - 22...\n",
      "Processing ./img/resize\\0060bd3d509fba0f.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00613913be1b88d2.jpg...\n",
      "\n",
      "0: 480x640 1 Hat, 3 Mans, 3 Sports uniforms, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00613913be1b88d2 - 1...\n",
      "Processing 00613913be1b88d2 - 2...\n",
      "Processing 00613913be1b88d2 - 3...\n",
      "Processing 00613913be1b88d2 - 4...\n",
      "Processing 00613913be1b88d2 - 5...\n",
      "Processing 00613913be1b88d2 - 6...\n",
      "Processing 00613913be1b88d2 - 7...\n",
      "Processing ./img/resize\\00617ab8fa01b856.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 1 Street light, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00617ab8fa01b856 - 1...\n",
      "Processing 00617ab8fa01b856 - 2...\n",
      "Processing ./img/resize\\00617e64127fa8b0.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0061b1f41d20a9eb.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0061b1f41d20a9eb - 1...\n",
      "Processing 0061b1f41d20a9eb - 2...\n",
      "Processing ./img/resize\\0061b9662130e711.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0061b9662130e711 - 1...\n",
      "Processing 0061b9662130e711 - 2...\n",
      "Processing ./img/resize\\0061f530ca635675.jpg...\n",
      "\n",
      "0: 480x640 5 Picture frames, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 0061f530ca635675 - 1...\n",
      "Processing 0061f530ca635675 - 2...\n",
      "Processing 0061f530ca635675 - 3...\n",
      "Processing 0061f530ca635675 - 4...\n",
      "Processing 0061f530ca635675 - 5...\n",
      "Processing ./img/resize\\0061feb402198de5.jpg...\n",
      "\n",
      "0: 480x640 1 Jeans, 3 Mans, 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 0061feb402198de5 - 1...\n",
      "Processing 0061feb402198de5 - 2...\n",
      "Processing 0061feb402198de5 - 3...\n",
      "Processing 0061feb402198de5 - 4...\n",
      "Processing 0061feb402198de5 - 5...\n",
      "Processing ./img/resize\\0062b78c310f3d5a.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0062b78c310f3d5a - 1...\n",
      "Processing ./img/resize\\0062d9a5fb4913ce.jpg...\n",
      "\n",
      "0: 480x640 1 Stop sign, 1 Traffic sign, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0062d9a5fb4913ce - 1...\n",
      "Processing 0062d9a5fb4913ce - 2...\n",
      "Processing ./img/resize\\0063067d3165274d.jpg...\n",
      "\n",
      "0: 480x640 2 Trees, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0063067d3165274d - 1...\n",
      "Processing 0063067d3165274d - 2...\n",
      "Processing ./img/resize\\00630c9c23991286.jpg...\n",
      "\n",
      "0: 480x640 2 Dogs, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00630c9c23991286 - 1...\n",
      "Processing 00630c9c23991286 - 2...\n",
      "Processing ./img/resize\\00630e6fd717ec17.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00630e6fd717ec17 - 1...\n",
      "Processing 00630e6fd717ec17 - 2...\n",
      "Processing ./img/resize\\0063128b3f03905a.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 2 Coffee tables, 1 Egg (Food), 2 Fishs, 1 Goggles, 1 Human face, 2 Human heads, 1 Marine invertebrates, 1 Shirt, 2 Sun hats, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "14\n",
      "Processing 0063128b3f03905a - 1...\n",
      "Processing 0063128b3f03905a - 2...\n",
      "Processing 0063128b3f03905a - 3...\n",
      "Processing 0063128b3f03905a - 4...\n",
      "Processing 0063128b3f03905a - 5...\n",
      "Processing 0063128b3f03905a - 6...\n",
      "Processing 0063128b3f03905a - 7...\n",
      "Processing 0063128b3f03905a - 8...\n",
      "Processing 0063128b3f03905a - 9...\n",
      "Processing 0063128b3f03905a - 10...\n",
      "Processing 0063128b3f03905a - 11...\n",
      "Processing 0063128b3f03905a - 12...\n",
      "Processing 0063128b3f03905a - 13...\n",
      "Processing 0063128b3f03905a - 14...\n",
      "Processing ./img/resize\\0063503a047d38ec.jpg...\n",
      "\n",
      "0: 480x640 1 Street light, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0063503a047d38ec - 1...\n",
      "Processing ./img/resize\\0063654162c38fbe.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 2 Human faces, 2 Mans, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 0063654162c38fbe - 1...\n",
      "Processing 0063654162c38fbe - 2...\n",
      "Processing 0063654162c38fbe - 3...\n",
      "Processing 0063654162c38fbe - 4...\n",
      "Processing 0063654162c38fbe - 5...\n",
      "Processing 0063654162c38fbe - 6...\n",
      "Processing ./img/resize\\0063b84cc42b6503.jpg...\n",
      "\n",
      "0: 480x640 4 Mans, 1 Woman, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 0063b84cc42b6503 - 1...\n",
      "Processing 0063b84cc42b6503 - 2...\n",
      "Processing 0063b84cc42b6503 - 3...\n",
      "Processing 0063b84cc42b6503 - 4...\n",
      "Processing 0063b84cc42b6503 - 5...\n",
      "Processing ./img/resize\\006407f9ef30bdd5.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00645c084a9bcef3.jpg...\n",
      "\n",
      "0: 480x640 4 Clothings, 4 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00645c084a9bcef3 - 1...\n",
      "Processing 00645c084a9bcef3 - 2...\n",
      "Processing 00645c084a9bcef3 - 3...\n",
      "Processing 00645c084a9bcef3 - 4...\n",
      "Processing 00645c084a9bcef3 - 5...\n",
      "Processing 00645c084a9bcef3 - 6...\n",
      "Processing 00645c084a9bcef3 - 7...\n",
      "Processing 00645c084a9bcef3 - 8...\n",
      "Processing ./img/resize\\006480da52744b74.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 1 Man, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 006480da52744b74 - 1...\n",
      "Processing 006480da52744b74 - 2...\n",
      "Processing 006480da52744b74 - 3...\n",
      "Processing 006480da52744b74 - 4...\n",
      "Processing ./img/resize\\0064a1e677af01b6.jpg...\n",
      "\n",
      "0: 480x640 2 Helmets, 4 Persons, 1 Personal flotation device, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 0064a1e677af01b6 - 1...\n",
      "Processing 0064a1e677af01b6 - 2...\n",
      "Processing 0064a1e677af01b6 - 3...\n",
      "Processing 0064a1e677af01b6 - 4...\n",
      "Processing 0064a1e677af01b6 - 5...\n",
      "Processing 0064a1e677af01b6 - 6...\n",
      "Processing 0064a1e677af01b6 - 7...\n",
      "Processing ./img/resize\\0064b65dbf0fca89.jpg...\n",
      "\n",
      "0: 480x640 1 Egg (Food), 2 Human faces, 1 Sun hat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0064b65dbf0fca89 - 1...\n",
      "Processing 0064b65dbf0fca89 - 2...\n",
      "Processing 0064b65dbf0fca89 - 3...\n",
      "Processing 0064b65dbf0fca89 - 4...\n",
      "Processing ./img/resize\\006513f0695c256d.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0065339df3b3db6f.jpg...\n",
      "\n",
      "0: 480x640 3 Clothings, 1 Man, 1 Office building, 1 Table, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 0065339df3b3db6f - 1...\n",
      "Processing 0065339df3b3db6f - 2...\n",
      "Processing 0065339df3b3db6f - 3...\n",
      "Processing 0065339df3b3db6f - 4...\n",
      "Processing 0065339df3b3db6f - 5...\n",
      "Processing 0065339df3b3db6f - 6...\n",
      "Processing ./img/resize\\006670be1d10e0b3.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 006670be1d10e0b3 - 1...\n",
      "Processing ./img/resize\\006678a15b078c77.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Clothing, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 006678a15b078c77 - 1...\n",
      "Processing 006678a15b078c77 - 2...\n",
      "Processing ./img/resize\\0066bc9d41d70f39.jpg...\n",
      "\n",
      "0: 480x640 1 Otter, 31.0ms\n",
      "Speed: 6.0ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0066bc9d41d70f39 - 1...\n",
      "Processing ./img/resize\\0066c75ecdddf1ca.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0066c75ecdddf1ca - 1...\n",
      "Processing ./img/resize\\0066f4d8f05df0a4.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00671ffe8a33c6ee.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00675f450c1fd082.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00675f7bc0a27213.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00676e729b127dd3.jpg...\n",
      "\n",
      "0: 480x640 1 Bottle, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00676e729b127dd3 - 1...\n",
      "Processing ./img/resize\\00679e1683881fb0.jpg...\n",
      "\n",
      "0: 480x640 1 Sock, 1 Stop sign, 3 Sun hats, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00679e1683881fb0 - 1...\n",
      "Processing 00679e1683881fb0 - 2...\n",
      "Processing 00679e1683881fb0 - 3...\n",
      "Processing 00679e1683881fb0 - 4...\n",
      "Processing 00679e1683881fb0 - 5...\n",
      "Processing ./img/resize\\0067ff942f76456c.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0067ff942f76456c - 1...\n",
      "Processing ./img/resize\\00682d64322627eb.jpg...\n",
      "\n",
      "0: 480x640 3 Accordions, 3 Aircrafts, 7 Mans, 2 Suits, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "15\n",
      "Processing 00682d64322627eb - 1...\n",
      "Processing 00682d64322627eb - 2...\n",
      "Processing 00682d64322627eb - 3...\n",
      "Processing 00682d64322627eb - 4...\n",
      "Processing 00682d64322627eb - 5...\n",
      "Processing 00682d64322627eb - 6...\n",
      "Processing 00682d64322627eb - 7...\n",
      "Processing 00682d64322627eb - 8...\n",
      "Processing 00682d64322627eb - 9...\n",
      "Processing 00682d64322627eb - 10...\n",
      "Processing 00682d64322627eb - 11...\n",
      "Processing 00682d64322627eb - 12...\n",
      "Processing 00682d64322627eb - 13...\n",
      "Processing 00682d64322627eb - 14...\n",
      "Processing 00682d64322627eb - 15...\n",
      "Processing ./img/resize\\00684212851ad62d.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 1 Suit, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00684212851ad62d - 1...\n",
      "Processing 00684212851ad62d - 2...\n",
      "Processing 00684212851ad62d - 3...\n",
      "Processing ./img/resize\\00686395ce9ad0ca.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00686395ce9ad0ca - 1...\n",
      "Processing ./img/resize\\0068ad9447067750.jpg...\n",
      "\n",
      "0: 480x640 2 Alpacas, 1 Animal, 2 Baked goodss, 1 Human body, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 0068ad9447067750 - 1...\n",
      "Processing 0068ad9447067750 - 2...\n",
      "Processing 0068ad9447067750 - 3...\n",
      "Processing 0068ad9447067750 - 4...\n",
      "Processing 0068ad9447067750 - 5...\n",
      "Processing 0068ad9447067750 - 6...\n",
      "Processing ./img/resize\\0068dde995ddedd5.jpg...\n",
      "\n",
      "0: 480x640 1 Coffee cup, 3 Mushrooms, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0068dde995ddedd5 - 1...\n",
      "Processing 0068dde995ddedd5 - 2...\n",
      "Processing 0068dde995ddedd5 - 3...\n",
      "Processing 0068dde995ddedd5 - 4...\n",
      "Processing ./img/resize\\00691744fdc8c1a8.jpg...\n",
      "\n",
      "0: 480x640 1 Fruit, 1 Tree, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00691744fdc8c1a8 - 1...\n",
      "Processing 00691744fdc8c1a8 - 2...\n",
      "Processing ./img/resize\\0069b38654581d49.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0069b38654581d49 - 1...\n",
      "Processing ./img/resize\\006a2000c44a92f5.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\006a75064ece9cfb.jpg...\n",
      "\n",
      "0: 480x640 1 Tower, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 006a75064ece9cfb - 1...\n",
      "Processing ./img/resize\\006ad9fe5fba6d2e.jpg...\n",
      "\n",
      "0: 480x640 1 Parrot, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 006ad9fe5fba6d2e - 1...\n",
      "Processing ./img/resize\\006b139a38d6ceb3.jpg...\n",
      "\n",
      "0: 480x640 1 Human head, 1 Laptop, 1 Man, 1 Pillow, 2 Shirts, 1 Suit, 2 Sun hats, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 006b139a38d6ceb3 - 1...\n",
      "Processing 006b139a38d6ceb3 - 2...\n",
      "Processing 006b139a38d6ceb3 - 3...\n",
      "Processing 006b139a38d6ceb3 - 4...\n",
      "Processing 006b139a38d6ceb3 - 5...\n",
      "Processing 006b139a38d6ceb3 - 6...\n",
      "Processing 006b139a38d6ceb3 - 7...\n",
      "Processing 006b139a38d6ceb3 - 8...\n",
      "Processing 006b139a38d6ceb3 - 9...\n",
      "Processing ./img/resize\\006bea3cd8abe20d.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\006bf1bd35b330ec.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle wheel, 1 Bookcase, 1 Chest of drawers, 2 Coffee tables, 2 Laptops, 1 Picture frame, 4 Teddy bears, 1 Television, 3 Wheels, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "16\n",
      "Processing 006bf1bd35b330ec - 1...\n",
      "Processing 006bf1bd35b330ec - 2...\n",
      "Processing 006bf1bd35b330ec - 3...\n",
      "Processing 006bf1bd35b330ec - 4...\n",
      "Processing 006bf1bd35b330ec - 5...\n",
      "Processing 006bf1bd35b330ec - 6...\n",
      "Processing 006bf1bd35b330ec - 7...\n",
      "Processing 006bf1bd35b330ec - 8...\n",
      "Processing 006bf1bd35b330ec - 9...\n",
      "Processing 006bf1bd35b330ec - 10...\n",
      "Processing 006bf1bd35b330ec - 11...\n",
      "Processing 006bf1bd35b330ec - 12...\n",
      "Processing 006bf1bd35b330ec - 13...\n",
      "Processing 006bf1bd35b330ec - 14...\n",
      "Processing 006bf1bd35b330ec - 15...\n",
      "Processing 006bf1bd35b330ec - 16...\n",
      "Processing ./img/resize\\006c8f923dbaef08.jpg...\n",
      "\n",
      "0: 480x640 1 Sparrow, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 006c8f923dbaef08 - 1...\n",
      "Processing ./img/resize\\006d36dadc702c3f.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Laptop, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 006d36dadc702c3f - 1...\n",
      "Processing 006d36dadc702c3f - 2...\n",
      "Processing ./img/resize\\006d7a5a2009230f.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\006d88707a13bcab.jpg...\n",
      "\n",
      "0: 480x640 1 Flag, 1 House, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 006d88707a13bcab - 1...\n",
      "Processing 006d88707a13bcab - 2...\n",
      "Processing ./img/resize\\006e609c077769be.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 1 Girl, 1 Human face, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 006e609c077769be - 1...\n",
      "Processing 006e609c077769be - 2...\n",
      "Processing 006e609c077769be - 3...\n",
      "Processing 006e609c077769be - 4...\n",
      "Processing ./img/resize\\006f4c2652b33b37.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 0.9ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\006f761aa7a0430d.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 2 Chairs, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 006f761aa7a0430d - 1...\n",
      "Processing 006f761aa7a0430d - 2...\n",
      "Processing 006f761aa7a0430d - 3...\n",
      "Processing ./img/resize\\006f7e7d6ad9e4ff.jpg...\n",
      "\n",
      "0: 480x640 1 Flag, 1 Human face, 1 Person, 1 Suit, 1 Umbrella, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 006f7e7d6ad9e4ff - 1...\n",
      "Processing 006f7e7d6ad9e4ff - 2...\n",
      "Processing 006f7e7d6ad9e4ff - 3...\n",
      "Processing 006f7e7d6ad9e4ff - 4...\n",
      "Processing 006f7e7d6ad9e4ff - 5...\n",
      "Processing ./img/resize\\006fe989683b32c8.jpg...\n",
      "\n",
      "0: 480x640 1 Ball, 1 Brassiere, 1 Coat, 1 Computer monitor, 1 Dress, 2 Fedoras, 5 Goggless, 5 Human arms, 1 Human beard, 2 Human heads, 2 Jackets, 1 Palm tree, 21 Shirts, 3 Sun hats, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "47\n",
      "Processing 006fe989683b32c8 - 1...\n",
      "Processing 006fe989683b32c8 - 2...\n",
      "Processing 006fe989683b32c8 - 3...\n",
      "Processing 006fe989683b32c8 - 4...\n",
      "Processing 006fe989683b32c8 - 5...\n",
      "Processing 006fe989683b32c8 - 6...\n",
      "Processing 006fe989683b32c8 - 7...\n",
      "Processing 006fe989683b32c8 - 8...\n",
      "Processing 006fe989683b32c8 - 9...\n",
      "Processing 006fe989683b32c8 - 10...\n",
      "Processing 006fe989683b32c8 - 11...\n",
      "Processing 006fe989683b32c8 - 12...\n",
      "Processing 006fe989683b32c8 - 13...\n",
      "Processing 006fe989683b32c8 - 14...\n",
      "Processing 006fe989683b32c8 - 15...\n",
      "Processing 006fe989683b32c8 - 16...\n",
      "Processing 006fe989683b32c8 - 17...\n",
      "Processing 006fe989683b32c8 - 18...\n",
      "Processing 006fe989683b32c8 - 19...\n",
      "Processing 006fe989683b32c8 - 20...\n",
      "Processing 006fe989683b32c8 - 21...\n",
      "Processing 006fe989683b32c8 - 22...\n",
      "Processing 006fe989683b32c8 - 23...\n",
      "Processing 006fe989683b32c8 - 24...\n",
      "Processing 006fe989683b32c8 - 25...\n",
      "Processing 006fe989683b32c8 - 26...\n",
      "Processing 006fe989683b32c8 - 27...\n",
      "Processing 006fe989683b32c8 - 28...\n",
      "Processing 006fe989683b32c8 - 29...\n",
      "Processing 006fe989683b32c8 - 30...\n",
      "Processing 006fe989683b32c8 - 31...\n",
      "Processing 006fe989683b32c8 - 32...\n",
      "Processing 006fe989683b32c8 - 33...\n",
      "Processing 006fe989683b32c8 - 34...\n",
      "Processing 006fe989683b32c8 - 35...\n",
      "Processing 006fe989683b32c8 - 36...\n",
      "Processing 006fe989683b32c8 - 37...\n",
      "Processing 006fe989683b32c8 - 38...\n",
      "Processing 006fe989683b32c8 - 39...\n",
      "Processing 006fe989683b32c8 - 40...\n",
      "Processing 006fe989683b32c8 - 41...\n",
      "Processing 006fe989683b32c8 - 42...\n",
      "Processing 006fe989683b32c8 - 43...\n",
      "Processing 006fe989683b32c8 - 44...\n",
      "Processing 006fe989683b32c8 - 45...\n",
      "Processing 006fe989683b32c8 - 46...\n",
      "Processing 006fe989683b32c8 - 47...\n",
      "Processing ./img/resize\\0070a4c05008e9ac.jpg...\n",
      "\n",
      "0: 480x640 1 Sculpture, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0070a4c05008e9ac - 1...\n",
      "Processing ./img/resize\\0070afbbf466e711.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0070afbbf466e711 - 1...\n",
      "Processing 0070afbbf466e711 - 2...\n",
      "Processing ./img/resize\\00712f861f41e5d5.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00712f861f41e5d5 - 1...\n",
      "Processing ./img/resize\\0071902883696658.jpg...\n",
      "\n",
      "0: 480x640 3 Boats, 2 Boxs, 2 Cabinetrys, 3 Castles, 13 Goggless, 1 Helmet, 1 Human head, 1 Human leg, 1 Human nose, 1 Jacket, 1 Lighthouse, 1 Man, 1 Stool, 1 Suit, 1 Swim cap, 2 Trouserss, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "35\n",
      "Processing 0071902883696658 - 1...\n",
      "Processing 0071902883696658 - 2...\n",
      "Processing 0071902883696658 - 3...\n",
      "Processing 0071902883696658 - 4...\n",
      "Processing 0071902883696658 - 5...\n",
      "Processing 0071902883696658 - 6...\n",
      "Processing 0071902883696658 - 7...\n",
      "Processing 0071902883696658 - 8...\n",
      "Processing 0071902883696658 - 9...\n",
      "Processing 0071902883696658 - 10...\n",
      "Processing 0071902883696658 - 11...\n",
      "Processing 0071902883696658 - 12...\n",
      "Processing 0071902883696658 - 13...\n",
      "Processing 0071902883696658 - 14...\n",
      "Processing 0071902883696658 - 15...\n",
      "Processing 0071902883696658 - 16...\n",
      "Processing 0071902883696658 - 17...\n",
      "Processing 0071902883696658 - 18...\n",
      "Processing 0071902883696658 - 19...\n",
      "Processing 0071902883696658 - 20...\n",
      "Processing 0071902883696658 - 21...\n",
      "Processing 0071902883696658 - 22...\n",
      "Processing 0071902883696658 - 23...\n",
      "Processing 0071902883696658 - 24...\n",
      "Processing 0071902883696658 - 25...\n",
      "Processing 0071902883696658 - 26...\n",
      "Processing 0071902883696658 - 27...\n",
      "Processing 0071902883696658 - 28...\n",
      "Processing 0071902883696658 - 29...\n",
      "Processing 0071902883696658 - 30...\n",
      "Processing 0071902883696658 - 31...\n",
      "Processing 0071902883696658 - 32...\n",
      "Processing 0071902883696658 - 33...\n",
      "Processing 0071902883696658 - 34...\n",
      "Processing 0071902883696658 - 35...\n",
      "Processing ./img/resize\\0071dcd09fb19cfb.jpg...\n",
      "\n",
      "0: 480x640 1 Ant, 3 Castles, 9 Goggless, 1 Harbor seal, 1 Helmet, 2 Human noses, 1 Jacket, 1 Lighthouse, 1 Mobile phone, 1 Suit, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "21\n",
      "Processing 0071dcd09fb19cfb - 1...\n",
      "Processing 0071dcd09fb19cfb - 2...\n",
      "Processing 0071dcd09fb19cfb - 3...\n",
      "Processing 0071dcd09fb19cfb - 4...\n",
      "Processing 0071dcd09fb19cfb - 5...\n",
      "Processing 0071dcd09fb19cfb - 6...\n",
      "Processing 0071dcd09fb19cfb - 7...\n",
      "Processing 0071dcd09fb19cfb - 8...\n",
      "Processing 0071dcd09fb19cfb - 9...\n",
      "Processing 0071dcd09fb19cfb - 10...\n",
      "Processing 0071dcd09fb19cfb - 11...\n",
      "Processing 0071dcd09fb19cfb - 12...\n",
      "Processing 0071dcd09fb19cfb - 13...\n",
      "Processing 0071dcd09fb19cfb - 14...\n",
      "Processing 0071dcd09fb19cfb - 15...\n",
      "Processing 0071dcd09fb19cfb - 16...\n",
      "Processing 0071dcd09fb19cfb - 17...\n",
      "Processing 0071dcd09fb19cfb - 18...\n",
      "Processing 0071dcd09fb19cfb - 19...\n",
      "Processing 0071dcd09fb19cfb - 20...\n",
      "Processing 0071dcd09fb19cfb - 21...\n",
      "Processing ./img/resize\\0071f05af81625bc.jpg...\n",
      "\n",
      "0: 480x640 3 Mans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0071f05af81625bc - 1...\n",
      "Processing 0071f05af81625bc - 2...\n",
      "Processing 0071f05af81625bc - 3...\n",
      "Processing ./img/resize\\007228a8d2383fab.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00722ee2bea71256.jpg...\n",
      "\n",
      "0: 480x640 3 Candles, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00722ee2bea71256 - 1...\n",
      "Processing 00722ee2bea71256 - 2...\n",
      "Processing 00722ee2bea71256 - 3...\n",
      "Processing ./img/resize\\0072382a6d2f2e32.jpg...\n",
      "\n",
      "0: 480x640 1 Motorcycle, 2 Tires, 2 Wheels, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 0072382a6d2f2e32 - 1...\n",
      "Processing 0072382a6d2f2e32 - 2...\n",
      "Processing 0072382a6d2f2e32 - 3...\n",
      "Processing 0072382a6d2f2e32 - 4...\n",
      "Processing 0072382a6d2f2e32 - 5...\n",
      "Processing ./img/resize\\00724d5a94e59979.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\007295b698f31f20.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Human face, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 007295b698f31f20 - 1...\n",
      "Processing 007295b698f31f20 - 2...\n",
      "Processing ./img/resize\\0072e2880b5f54c9.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0072e2880b5f54c9 - 1...\n",
      "Processing ./img/resize\\007341ed6fdd3947.jpg...\n",
      "\n",
      "0: 480x640 1 Girl, 1 Human face, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 007341ed6fdd3947 - 1...\n",
      "Processing 007341ed6fdd3947 - 2...\n",
      "Processing ./img/resize\\00734dca70fe9cca.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00737efc6f6a967e.jpg...\n",
      "\n",
      "0: 480x640 2 Persons, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00737efc6f6a967e - 1...\n",
      "Processing 00737efc6f6a967e - 2...\n",
      "Processing ./img/resize\\0073c88a4fef2be9.jpg...\n",
      "\n",
      "0: 480x640 1 Balloon, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0073c88a4fef2be9 - 1...\n",
      "Processing ./img/resize\\0074d01086a0451d.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0074feb18be45b19.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0074feb18be45b19 - 1...\n",
      "Processing ./img/resize\\007505d868c7c7e5.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00751332f75e12d2.jpg...\n",
      "\n",
      "0: 480x640 3 Buss, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00751332f75e12d2 - 1...\n",
      "Processing 00751332f75e12d2 - 2...\n",
      "Processing 00751332f75e12d2 - 3...\n",
      "Processing ./img/resize\\0075391cbf4d78b5.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00753a206a1138fe.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 1 Suit, 5 Womans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00753a206a1138fe - 1...\n",
      "Processing 00753a206a1138fe - 2...\n",
      "Processing 00753a206a1138fe - 3...\n",
      "Processing 00753a206a1138fe - 4...\n",
      "Processing 00753a206a1138fe - 5...\n",
      "Processing 00753a206a1138fe - 6...\n",
      "Processing 00753a206a1138fe - 7...\n",
      "Processing 00753a206a1138fe - 8...\n",
      "Processing ./img/resize\\00755d0ce98f3659.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00757bfa18756532.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.9ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\007582e7afd57acb.jpg...\n",
      "\n",
      "0: 480x640 2 Accordions, 1 Baseball glove, 1 Bench, 1 Butterfly, 1 Candy, 2 Christmas trees, 3 Coffee tables, 2 Human heads, 1 Person, 1 Rose, 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "16\n",
      "Processing 007582e7afd57acb - 1...\n",
      "Processing 007582e7afd57acb - 2...\n",
      "Processing 007582e7afd57acb - 3...\n",
      "Processing 007582e7afd57acb - 4...\n",
      "Processing 007582e7afd57acb - 5...\n",
      "Processing 007582e7afd57acb - 6...\n",
      "Processing 007582e7afd57acb - 7...\n",
      "Processing 007582e7afd57acb - 8...\n",
      "Processing 007582e7afd57acb - 9...\n",
      "Processing 007582e7afd57acb - 10...\n",
      "Processing 007582e7afd57acb - 11...\n",
      "Processing 007582e7afd57acb - 12...\n",
      "Processing 007582e7afd57acb - 13...\n",
      "Processing 007582e7afd57acb - 14...\n",
      "Processing 007582e7afd57acb - 15...\n",
      "Processing 007582e7afd57acb - 16...\n",
      "Processing ./img/resize\\0075d5f5c44f74cb.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle wheel, 2 Houses, 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0075d5f5c44f74cb - 1...\n",
      "Processing 0075d5f5c44f74cb - 2...\n",
      "Processing 0075d5f5c44f74cb - 3...\n",
      "Processing 0075d5f5c44f74cb - 4...\n",
      "Processing ./img/resize\\0075dbddf4ec1bae.jpg...\n",
      "\n",
      "0: 480x640 1 Dog, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0075dbddf4ec1bae - 1...\n",
      "Processing ./img/resize\\0075dbf2903d9a06.jpg...\n",
      "\n",
      "0: 480x640 2 Motorcycles, 1 Person, 1 Tent, 1 Tree, 4 Wheels, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 0075dbf2903d9a06 - 1...\n",
      "Processing 0075dbf2903d9a06 - 2...\n",
      "Processing 0075dbf2903d9a06 - 3...\n",
      "Processing 0075dbf2903d9a06 - 4...\n",
      "Processing 0075dbf2903d9a06 - 5...\n",
      "Processing 0075dbf2903d9a06 - 6...\n",
      "Processing 0075dbf2903d9a06 - 7...\n",
      "Processing 0075dbf2903d9a06 - 8...\n",
      "Processing 0075dbf2903d9a06 - 9...\n",
      "Processing ./img/resize\\0075f62d76a87cc0.jpg...\n",
      "\n",
      "0: 480x640 1 Maple, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0075f62d76a87cc0 - 1...\n",
      "Processing ./img/resize\\00764d72c58674c5.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Human face, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00764d72c58674c5 - 1...\n",
      "Processing 00764d72c58674c5 - 2...\n",
      "Processing ./img/resize\\007659d9886bda16.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00766ef4ca0d1c32.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.1ms\n",
      "Speed: 1.0ms preprocess, 30.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00766ef4ca0d1c32 - 1...\n",
      "Processing ./img/resize\\00767a2f89796e62.jpg...\n",
      "\n",
      "0: 480x640 2 Guitars, 2 Persons, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00767a2f89796e62 - 1...\n",
      "Processing 00767a2f89796e62 - 2...\n",
      "Processing 00767a2f89796e62 - 3...\n",
      "Processing 00767a2f89796e62 - 4...\n",
      "Processing ./img/resize\\0076b04cbf381be6.jpg...\n",
      "\n",
      "0: 480x640 1 Animal, 2 Armadillos, 2 Bicycle wheels, 1 Bird, 3 Isopods, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 0076b04cbf381be6 - 1...\n",
      "Processing 0076b04cbf381be6 - 2...\n",
      "Processing 0076b04cbf381be6 - 3...\n",
      "Processing 0076b04cbf381be6 - 4...\n",
      "Processing 0076b04cbf381be6 - 5...\n",
      "Processing 0076b04cbf381be6 - 6...\n",
      "Processing 0076b04cbf381be6 - 7...\n",
      "Processing 0076b04cbf381be6 - 8...\n",
      "Processing 0076b04cbf381be6 - 9...\n",
      "Processing ./img/resize\\0076e16733b8a5ec.jpg...\n",
      "\n",
      "0: 480x640 5 Boys, 1 Cabinetry, 4 Coffee tables, 2 Computer monitors, 2 Egg (Food)s, 2 Goggless, 3 Human faces, 1 Human head, 2 Sun hats, 1 Tire, 1 Wine, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "24\n",
      "Processing 0076e16733b8a5ec - 1...\n",
      "Processing 0076e16733b8a5ec - 2...\n",
      "Processing 0076e16733b8a5ec - 3...\n",
      "Processing 0076e16733b8a5ec - 4...\n",
      "Processing 0076e16733b8a5ec - 5...\n",
      "Processing 0076e16733b8a5ec - 6...\n",
      "Processing 0076e16733b8a5ec - 7...\n",
      "Processing 0076e16733b8a5ec - 8...\n",
      "Processing 0076e16733b8a5ec - 9...\n",
      "Processing 0076e16733b8a5ec - 10...\n",
      "Processing 0076e16733b8a5ec - 11...\n",
      "Processing 0076e16733b8a5ec - 12...\n",
      "Processing 0076e16733b8a5ec - 13...\n",
      "Processing 0076e16733b8a5ec - 14...\n",
      "Processing 0076e16733b8a5ec - 15...\n",
      "Processing 0076e16733b8a5ec - 16...\n",
      "Processing 0076e16733b8a5ec - 17...\n",
      "Processing 0076e16733b8a5ec - 18...\n",
      "Processing 0076e16733b8a5ec - 19...\n",
      "Processing 0076e16733b8a5ec - 20...\n",
      "Processing 0076e16733b8a5ec - 21...\n",
      "Processing 0076e16733b8a5ec - 22...\n",
      "Processing 0076e16733b8a5ec - 23...\n",
      "Processing 0076e16733b8a5ec - 24...\n",
      "Processing ./img/resize\\0077354fa7f36b3a.jpg...\n",
      "\n",
      "0: 480x640 4 Boots, 1 Boy, 3 Egg (Food)s, 2 Goggless, 1 Grapefruit, 2 Sun hats, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "13\n",
      "Processing 0077354fa7f36b3a - 1...\n",
      "Processing 0077354fa7f36b3a - 2...\n",
      "Processing 0077354fa7f36b3a - 3...\n",
      "Processing 0077354fa7f36b3a - 4...\n",
      "Processing 0077354fa7f36b3a - 5...\n",
      "Processing 0077354fa7f36b3a - 6...\n",
      "Processing 0077354fa7f36b3a - 7...\n",
      "Processing 0077354fa7f36b3a - 8...\n",
      "Processing 0077354fa7f36b3a - 9...\n",
      "Processing 0077354fa7f36b3a - 10...\n",
      "Processing 0077354fa7f36b3a - 11...\n",
      "Processing 0077354fa7f36b3a - 12...\n",
      "Processing 0077354fa7f36b3a - 13...\n",
      "Processing ./img/resize\\00777823afff31f7.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 House, 1 Waste container, 2 Windows, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00777823afff31f7 - 1...\n",
      "Processing 00777823afff31f7 - 2...\n",
      "Processing 00777823afff31f7 - 3...\n",
      "Processing 00777823afff31f7 - 4...\n",
      "Processing 00777823afff31f7 - 5...\n",
      "Processing ./img/resize\\007790c627007042.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 007790c627007042 - 1...\n",
      "Processing 007790c627007042 - 2...\n",
      "Processing 007790c627007042 - 3...\n",
      "Processing ./img/resize\\0077b4e81d147a1c.jpg...\n",
      "\n",
      "0: 480x640 7 Footwears, 3 Girls, 6 Human faces, 1 Jeans, 5 Mans, 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "23\n",
      "Processing 0077b4e81d147a1c - 1...\n",
      "Processing 0077b4e81d147a1c - 2...\n",
      "Processing 0077b4e81d147a1c - 3...\n",
      "Processing 0077b4e81d147a1c - 4...\n",
      "Processing 0077b4e81d147a1c - 5...\n",
      "Processing 0077b4e81d147a1c - 6...\n",
      "Processing 0077b4e81d147a1c - 7...\n",
      "Processing 0077b4e81d147a1c - 8...\n",
      "Processing 0077b4e81d147a1c - 9...\n",
      "Processing 0077b4e81d147a1c - 10...\n",
      "Processing 0077b4e81d147a1c - 11...\n",
      "Processing 0077b4e81d147a1c - 12...\n",
      "Processing 0077b4e81d147a1c - 13...\n",
      "Processing 0077b4e81d147a1c - 14...\n",
      "Processing 0077b4e81d147a1c - 15...\n",
      "Processing 0077b4e81d147a1c - 16...\n",
      "Processing 0077b4e81d147a1c - 17...\n",
      "Processing 0077b4e81d147a1c - 18...\n",
      "Processing 0077b4e81d147a1c - 19...\n",
      "Processing 0077b4e81d147a1c - 20...\n",
      "Processing 0077b4e81d147a1c - 21...\n",
      "Processing 0077b4e81d147a1c - 22...\n",
      "Processing 0077b4e81d147a1c - 23...\n",
      "Processing ./img/resize\\0077c7a766f221d4.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0077c7a766f221d4 - 1...\n",
      "Processing ./img/resize\\0077c8ad75cdb9b0.jpg...\n",
      "\n",
      "0: 480x640 1 Dress, 1 Man, 1 Suit, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0077c8ad75cdb9b0 - 1...\n",
      "Processing 0077c8ad75cdb9b0 - 2...\n",
      "Processing 0077c8ad75cdb9b0 - 3...\n",
      "Processing 0077c8ad75cdb9b0 - 4...\n",
      "Processing ./img/resize\\0078009637adf3bd.jpg...\n",
      "\n",
      "0: 480x640 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0078009637adf3bd - 1...\n",
      "Processing ./img/resize\\00785bf6288684df.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00785bf6288684df - 1...\n",
      "Processing 00785bf6288684df - 2...\n",
      "Processing ./img/resize\\007873e5087056a4.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle helmet, 4 Boys, 1 Coffee cup, 3 Persons, 1 Rose, 1 Sun hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 007873e5087056a4 - 1...\n",
      "Processing 007873e5087056a4 - 2...\n",
      "Processing 007873e5087056a4 - 3...\n",
      "Processing 007873e5087056a4 - 4...\n",
      "Processing 007873e5087056a4 - 5...\n",
      "Processing 007873e5087056a4 - 6...\n",
      "Processing 007873e5087056a4 - 7...\n",
      "Processing 007873e5087056a4 - 8...\n",
      "Processing 007873e5087056a4 - 9...\n",
      "Processing 007873e5087056a4 - 10...\n",
      "Processing 007873e5087056a4 - 11...\n",
      "Processing ./img/resize\\00789ace048d6508.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00789ace048d6508 - 1...\n",
      "Processing ./img/resize\\0078bf6d54a54e9b.jpg...\n",
      "\n",
      "0: 480x640 1 Computer keyboard, 1 Laptop, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0078bf6d54a54e9b - 1...\n",
      "Processing 0078bf6d54a54e9b - 2...\n",
      "Processing ./img/resize\\0078f96834715a06.jpg...\n",
      "\n",
      "0: 480x640 2 Boots, 1 Boy, 1 Flowerpot, 1 Goggles, 1 Human face, 2 Human heads, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 0078f96834715a06 - 1...\n",
      "Processing 0078f96834715a06 - 2...\n",
      "Processing 0078f96834715a06 - 3...\n",
      "Processing 0078f96834715a06 - 4...\n",
      "Processing 0078f96834715a06 - 5...\n",
      "Processing 0078f96834715a06 - 6...\n",
      "Processing 0078f96834715a06 - 7...\n",
      "Processing 0078f96834715a06 - 8...\n",
      "Processing 0078f96834715a06 - 9...\n",
      "Processing ./img/resize\\007913e79f64039c.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Laptop, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 007913e79f64039c - 1...\n",
      "Processing 007913e79f64039c - 2...\n",
      "Processing ./img/resize\\0079708a58487475.jpg...\n",
      "\n",
      "0: 480x640 1 Office building, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0079708a58487475 - 1...\n",
      "Processing ./img/resize\\0079a5454f2e31fc.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0079c70fc115d8db.jpg...\n",
      "\n",
      "0: 480x640 3 Adhesive tapes, 1 Auto part, 1 Baked goods, 1 Bed, 1 Boat, 1 Human face, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 0079c70fc115d8db - 1...\n",
      "Processing 0079c70fc115d8db - 2...\n",
      "Processing 0079c70fc115d8db - 3...\n",
      "Processing 0079c70fc115d8db - 4...\n",
      "Processing 0079c70fc115d8db - 5...\n",
      "Processing 0079c70fc115d8db - 6...\n",
      "Processing 0079c70fc115d8db - 7...\n",
      "Processing 0079c70fc115d8db - 8...\n",
      "Processing ./img/resize\\0079d59fe583d268.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0079f8d9a1180543.jpg...\n",
      "\n",
      "0: 480x640 1 Motorcycle, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0079f8d9a1180543 - 1...\n",
      "Processing 0079f8d9a1180543 - 2...\n",
      "Processing ./img/resize\\007a08c7ee691d0b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\007a204dd9162c4e.jpg...\n",
      "\n",
      "0: 480x640 1 House, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 007a204dd9162c4e - 1...\n",
      "Processing ./img/resize\\007a73ae3d567b19.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 007a73ae3d567b19 - 1...\n",
      "Processing 007a73ae3d567b19 - 2...\n",
      "Processing ./img/resize\\007a7cb668455fc3.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\007adedc7e7e35c0.jpg...\n",
      "\n",
      "0: 480x640 1 Dog, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 007adedc7e7e35c0 - 1...\n",
      "Processing ./img/resize\\007af1656313d9ec.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 007af1656313d9ec - 1...\n",
      "Processing ./img/resize\\007b42b566c8950a.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Flower, 1 House, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 007b42b566c8950a - 1...\n",
      "Processing 007b42b566c8950a - 2...\n",
      "Processing 007b42b566c8950a - 3...\n",
      "Processing ./img/resize\\007b614719fbc4aa.jpg...\n",
      "\n",
      "0: 480x640 1 Picture frame, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 007b614719fbc4aa - 1...\n",
      "Processing ./img/resize\\007b8153fb7aba73.jpg...\n",
      "\n",
      "0: 480x640 1 Horse, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 007b8153fb7aba73 - 1...\n",
      "Processing ./img/resize\\007c0a2e2e9c7647.jpg...\n",
      "\n",
      "0: 480x640 2 Boats, 1 Person, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 007c0a2e2e9c7647 - 1...\n",
      "Processing 007c0a2e2e9c7647 - 2...\n",
      "Processing 007c0a2e2e9c7647 - 3...\n",
      "Processing ./img/resize\\007c4ca0efeaac92.jpg...\n",
      "\n",
      "0: 480x640 1 Street light, 1 Umbrella, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 007c4ca0efeaac92 - 1...\n",
      "Processing 007c4ca0efeaac92 - 2...\n",
      "Processing ./img/resize\\007c60b5da49292c.jpg...\n",
      "\n",
      "0: 480x640 9 Balls, 3 Goggless, 1 Human head, 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "14\n",
      "Processing 007c60b5da49292c - 1...\n",
      "Processing 007c60b5da49292c - 2...\n",
      "Processing 007c60b5da49292c - 3...\n",
      "Processing 007c60b5da49292c - 4...\n",
      "Processing 007c60b5da49292c - 5...\n",
      "Processing 007c60b5da49292c - 6...\n",
      "Processing 007c60b5da49292c - 7...\n",
      "Processing 007c60b5da49292c - 8...\n",
      "Processing 007c60b5da49292c - 9...\n",
      "Processing 007c60b5da49292c - 10...\n",
      "Processing 007c60b5da49292c - 11...\n",
      "Processing 007c60b5da49292c - 12...\n",
      "Processing 007c60b5da49292c - 13...\n",
      "Processing 007c60b5da49292c - 14...\n",
      "Processing ./img/resize\\007c87a8a87f6ca7.jpg...\n",
      "\n",
      "0: 480x640 3 Clothings, 3 Mans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 007c87a8a87f6ca7 - 1...\n",
      "Processing 007c87a8a87f6ca7 - 2...\n",
      "Processing 007c87a8a87f6ca7 - 3...\n",
      "Processing 007c87a8a87f6ca7 - 4...\n",
      "Processing 007c87a8a87f6ca7 - 5...\n",
      "Processing 007c87a8a87f6ca7 - 6...\n",
      "Processing ./img/resize\\007cd9d9b02c6d99.jpg...\n",
      "\n",
      "0: 480x640 1 Aircraft, 4 Animals, 4 Benchs, 2 Boxs, 3 Cabinetrys, 3 Cars, 5 Goggless, 1 Human head, 1 Human leg, 1 Human nose, 3 Trouserss, 3 Wheels, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "31\n",
      "Processing 007cd9d9b02c6d99 - 1...\n",
      "Processing 007cd9d9b02c6d99 - 2...\n",
      "Processing 007cd9d9b02c6d99 - 3...\n",
      "Processing 007cd9d9b02c6d99 - 4...\n",
      "Processing 007cd9d9b02c6d99 - 5...\n",
      "Processing 007cd9d9b02c6d99 - 6...\n",
      "Processing 007cd9d9b02c6d99 - 7...\n",
      "Processing 007cd9d9b02c6d99 - 8...\n",
      "Processing 007cd9d9b02c6d99 - 9...\n",
      "Processing 007cd9d9b02c6d99 - 10...\n",
      "Processing 007cd9d9b02c6d99 - 11...\n",
      "Processing 007cd9d9b02c6d99 - 12...\n",
      "Processing 007cd9d9b02c6d99 - 13...\n",
      "Processing 007cd9d9b02c6d99 - 14...\n",
      "Processing 007cd9d9b02c6d99 - 15...\n",
      "Processing 007cd9d9b02c6d99 - 16...\n",
      "Processing 007cd9d9b02c6d99 - 17...\n",
      "Processing 007cd9d9b02c6d99 - 18...\n",
      "Processing 007cd9d9b02c6d99 - 19...\n",
      "Processing 007cd9d9b02c6d99 - 20...\n",
      "Processing 007cd9d9b02c6d99 - 21...\n",
      "Processing 007cd9d9b02c6d99 - 22...\n",
      "Processing 007cd9d9b02c6d99 - 23...\n",
      "Processing 007cd9d9b02c6d99 - 24...\n",
      "Processing 007cd9d9b02c6d99 - 25...\n",
      "Processing 007cd9d9b02c6d99 - 26...\n",
      "Processing 007cd9d9b02c6d99 - 27...\n",
      "Processing 007cd9d9b02c6d99 - 28...\n",
      "Processing 007cd9d9b02c6d99 - 29...\n",
      "Processing 007cd9d9b02c6d99 - 30...\n",
      "Processing 007cd9d9b02c6d99 - 31...\n",
      "Processing ./img/resize\\007cdfad5b85d3e7.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Football, 1 Human face, 1 Man, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 007cdfad5b85d3e7 - 1...\n",
      "Processing 007cdfad5b85d3e7 - 2...\n",
      "Processing 007cdfad5b85d3e7 - 3...\n",
      "Processing 007cdfad5b85d3e7 - 4...\n",
      "Processing 007cdfad5b85d3e7 - 5...\n",
      "Processing ./img/resize\\007cebcc0a798185.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Tire, 2 Wheels, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 007cebcc0a798185 - 1...\n",
      "Processing 007cebcc0a798185 - 2...\n",
      "Processing 007cebcc0a798185 - 3...\n",
      "Processing 007cebcc0a798185 - 4...\n",
      "Processing ./img/resize\\007df0727e181488.jpg...\n",
      "\n",
      "0: 480x640 1 Hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 007df0727e181488 - 1...\n",
      "Processing ./img/resize\\007df76788107622.jpg...\n",
      "\n",
      "0: 480x640 1 House, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 007df76788107622 - 1...\n",
      "Processing ./img/resize\\007e853e28efee81.jpg...\n",
      "\n",
      "0: 480x640 1 Plant, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 007e853e28efee81 - 1...\n",
      "Processing ./img/resize\\007f8f8213bb784a.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 007f8f8213bb784a - 1...\n",
      "Processing ./img/resize\\007ff4e15bccb964.jpg...\n",
      "\n",
      "0: 480x640 1 Book, 35.0ms\n",
      "Speed: 1.0ms preprocess, 35.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 007ff4e15bccb964 - 1...\n",
      "Processing ./img/resize\\00807080a52566f4.jpg...\n",
      "\n",
      "0: 480x640 3 Trees, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00807080a52566f4 - 1...\n",
      "Processing 00807080a52566f4 - 2...\n",
      "Processing 00807080a52566f4 - 3...\n",
      "Processing ./img/resize\\0081c3513ebcb830.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Man, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0081c3513ebcb830 - 1...\n",
      "Processing 0081c3513ebcb830 - 2...\n",
      "Processing 0081c3513ebcb830 - 3...\n",
      "Processing ./img/resize\\00821a9c40673e01.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 1 Sunglasses, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00821a9c40673e01 - 1...\n",
      "Processing 00821a9c40673e01 - 2...\n",
      "Processing 00821a9c40673e01 - 3...\n",
      "Processing ./img/resize\\00821d241dcdde27.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00821d241dcdde27 - 1...\n",
      "Processing ./img/resize\\00823e4afb5a0c68.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00823e4afb5a0c68 - 1...\n",
      "Processing ./img/resize\\008258ec756ce09f.jpg...\n",
      "\n",
      "0: 480x640 7 Roller skatess, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 008258ec756ce09f - 1...\n",
      "Processing 008258ec756ce09f - 2...\n",
      "Processing 008258ec756ce09f - 3...\n",
      "Processing 008258ec756ce09f - 4...\n",
      "Processing 008258ec756ce09f - 5...\n",
      "Processing 008258ec756ce09f - 6...\n",
      "Processing 008258ec756ce09f - 7...\n",
      "Processing ./img/resize\\00832ab89abf9907.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00832ab89abf9907 - 1...\n",
      "Processing ./img/resize\\00833390b020023e.jpg...\n",
      "\n",
      "0: 480x640 1 Dress, 2 Girls, 2 Human faces, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00833390b020023e - 1...\n",
      "Processing 00833390b020023e - 2...\n",
      "Processing 00833390b020023e - 3...\n",
      "Processing 00833390b020023e - 4...\n",
      "Processing 00833390b020023e - 5...\n",
      "Processing ./img/resize\\0083347ff5016fc2.jpg...\n",
      "\n",
      "0: 480x640 1 Coffee cup, 1 Tea, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0083347ff5016fc2 - 1...\n",
      "Processing 0083347ff5016fc2 - 2...\n",
      "Processing ./img/resize\\008353e8e91cd62d.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0083956d45ddf0b0.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Jeans, 2 Womans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0083956d45ddf0b0 - 1...\n",
      "Processing 0083956d45ddf0b0 - 2...\n",
      "Processing 0083956d45ddf0b0 - 3...\n",
      "Processing 0083956d45ddf0b0 - 4...\n",
      "Processing ./img/resize\\0083d7c51bd6ae1e.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0083d7c51bd6ae1e - 1...\n",
      "Processing ./img/resize\\008434b7b997f104.jpg...\n",
      "\n",
      "0: 480x640 2 Drums, 1 Footwear, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 008434b7b997f104 - 1...\n",
      "Processing 008434b7b997f104 - 2...\n",
      "Processing 008434b7b997f104 - 3...\n",
      "Processing ./img/resize\\00843be967aab6eb.jpg...\n",
      "\n",
      "0: 480x640 2 Platters, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00843be967aab6eb - 1...\n",
      "Processing 00843be967aab6eb - 2...\n",
      "Processing ./img/resize\\00843cfd0580fc81.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 2 Mans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00843cfd0580fc81 - 1...\n",
      "Processing 00843cfd0580fc81 - 2...\n",
      "Processing 00843cfd0580fc81 - 3...\n",
      "Processing ./img/resize\\008469f0df521c28.jpg...\n",
      "\n",
      "0: 480x640 3 Adhesive tapes, 1 Animal, 1 Apple, 1 Armadillo, 5 Balls, 7 Barges, 1 Bowl, 4 Hippopotamuss, 1 Human head, 1 Sea lion, 30.0ms\n",
      "Speed: 0.9ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "25\n",
      "Processing 008469f0df521c28 - 1...\n",
      "Processing 008469f0df521c28 - 2...\n",
      "Processing 008469f0df521c28 - 3...\n",
      "Processing 008469f0df521c28 - 4...\n",
      "Processing 008469f0df521c28 - 5...\n",
      "Processing 008469f0df521c28 - 6...\n",
      "Processing 008469f0df521c28 - 7...\n",
      "Processing 008469f0df521c28 - 8...\n",
      "Processing 008469f0df521c28 - 9...\n",
      "Processing 008469f0df521c28 - 10...\n",
      "Processing 008469f0df521c28 - 11...\n",
      "Processing 008469f0df521c28 - 12...\n",
      "Processing 008469f0df521c28 - 13...\n",
      "Processing 008469f0df521c28 - 14...\n",
      "Processing 008469f0df521c28 - 15...\n",
      "Processing 008469f0df521c28 - 16...\n",
      "Processing 008469f0df521c28 - 17...\n",
      "Processing 008469f0df521c28 - 18...\n",
      "Processing 008469f0df521c28 - 19...\n",
      "Processing 008469f0df521c28 - 20...\n",
      "Processing 008469f0df521c28 - 21...\n",
      "Processing 008469f0df521c28 - 22...\n",
      "Processing 008469f0df521c28 - 23...\n",
      "Processing 008469f0df521c28 - 24...\n",
      "Processing 008469f0df521c28 - 25...\n",
      "Processing ./img/resize\\00847d2be1d869f1.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00847d2be1d869f1 - 1...\n",
      "Processing 00847d2be1d869f1 - 2...\n",
      "Processing ./img/resize\\0084b263c77b57e6.jpg...\n",
      "\n",
      "0: 480x640 1 Plant, 5 Tomatos, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 0084b263c77b57e6 - 1...\n",
      "Processing 0084b263c77b57e6 - 2...\n",
      "Processing 0084b263c77b57e6 - 3...\n",
      "Processing 0084b263c77b57e6 - 4...\n",
      "Processing 0084b263c77b57e6 - 5...\n",
      "Processing 0084b263c77b57e6 - 6...\n",
      "Processing ./img/resize\\0084e0e94575ce6d.jpg...\n",
      "\n",
      "0: 480x640 2 Clothings, 3 Human faces, 3 Mans, 1 Woman, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 0084e0e94575ce6d - 1...\n",
      "Processing 0084e0e94575ce6d - 2...\n",
      "Processing 0084e0e94575ce6d - 3...\n",
      "Processing 0084e0e94575ce6d - 4...\n",
      "Processing 0084e0e94575ce6d - 5...\n",
      "Processing 0084e0e94575ce6d - 6...\n",
      "Processing 0084e0e94575ce6d - 7...\n",
      "Processing 0084e0e94575ce6d - 8...\n",
      "Processing 0084e0e94575ce6d - 9...\n",
      "Processing ./img/resize\\00850fbbfc9c7809.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00863a4185139518.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Horse, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00863a4185139518 - 1...\n",
      "Processing 00863a4185139518 - 2...\n",
      "Processing ./img/resize\\00865e982fc83046.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00867cddfbed08be.jpg...\n",
      "\n",
      "0: 480x640 1 Umbrella, 6 Womans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00867cddfbed08be - 1...\n",
      "Processing 00867cddfbed08be - 2...\n",
      "Processing 00867cddfbed08be - 3...\n",
      "Processing 00867cddfbed08be - 4...\n",
      "Processing 00867cddfbed08be - 5...\n",
      "Processing 00867cddfbed08be - 6...\n",
      "Processing 00867cddfbed08be - 7...\n",
      "Processing ./img/resize\\0086822acb005244.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle wheel, 2 Human faces, 3 Jackets, 3 Mans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 0086822acb005244 - 1...\n",
      "Processing 0086822acb005244 - 2...\n",
      "Processing 0086822acb005244 - 3...\n",
      "Processing 0086822acb005244 - 4...\n",
      "Processing 0086822acb005244 - 5...\n",
      "Processing 0086822acb005244 - 6...\n",
      "Processing 0086822acb005244 - 7...\n",
      "Processing 0086822acb005244 - 8...\n",
      "Processing 0086822acb005244 - 9...\n",
      "Processing ./img/resize\\00869f0facebd0eb.jpg...\n",
      "\n",
      "0: 480x640 2 Ants, 2 Boxs, 2 Cabinetrys, 6 Castles, 1 Fedora, 22 Goggless, 2 Harbor seals, 3 Helmets, 1 Human hair, 1 Human head, 1 Human leg, 3 Human noses, 2 Ipods, 2 Jackets, 1 Lighthouse, 4 Mans, 1 Microphone, 3 Mobile phones, 1 Stool, 2 Suits, 1 Swim cap, 2 Trouserss, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "66\n",
      "Processing 00869f0facebd0eb - 1...\n",
      "Processing 00869f0facebd0eb - 2...\n",
      "Processing 00869f0facebd0eb - 3...\n",
      "Processing 00869f0facebd0eb - 4...\n",
      "Processing 00869f0facebd0eb - 5...\n",
      "Processing 00869f0facebd0eb - 6...\n",
      "Processing 00869f0facebd0eb - 7...\n",
      "Processing 00869f0facebd0eb - 8...\n",
      "Processing 00869f0facebd0eb - 9...\n",
      "Processing 00869f0facebd0eb - 10...\n",
      "Processing 00869f0facebd0eb - 11...\n",
      "Processing 00869f0facebd0eb - 12...\n",
      "Processing 00869f0facebd0eb - 13...\n",
      "Processing 00869f0facebd0eb - 14...\n",
      "Processing 00869f0facebd0eb - 15...\n",
      "Processing 00869f0facebd0eb - 16...\n",
      "Processing 00869f0facebd0eb - 17...\n",
      "Processing 00869f0facebd0eb - 18...\n",
      "Processing 00869f0facebd0eb - 19...\n",
      "Processing 00869f0facebd0eb - 20...\n",
      "Processing 00869f0facebd0eb - 21...\n",
      "Processing 00869f0facebd0eb - 22...\n",
      "Processing 00869f0facebd0eb - 23...\n",
      "Processing 00869f0facebd0eb - 24...\n",
      "Processing 00869f0facebd0eb - 25...\n",
      "Processing 00869f0facebd0eb - 26...\n",
      "Processing 00869f0facebd0eb - 27...\n",
      "Processing 00869f0facebd0eb - 28...\n",
      "Processing 00869f0facebd0eb - 29...\n",
      "Processing 00869f0facebd0eb - 30...\n",
      "Processing 00869f0facebd0eb - 31...\n",
      "Processing 00869f0facebd0eb - 32...\n",
      "Processing 00869f0facebd0eb - 33...\n",
      "Processing 00869f0facebd0eb - 34...\n",
      "Processing 00869f0facebd0eb - 35...\n",
      "Processing 00869f0facebd0eb - 36...\n",
      "Processing 00869f0facebd0eb - 37...\n",
      "Processing 00869f0facebd0eb - 38...\n",
      "Processing 00869f0facebd0eb - 39...\n",
      "Processing 00869f0facebd0eb - 40...\n",
      "Processing 00869f0facebd0eb - 41...\n",
      "Processing 00869f0facebd0eb - 42...\n",
      "Processing 00869f0facebd0eb - 43...\n",
      "Processing 00869f0facebd0eb - 44...\n",
      "Processing 00869f0facebd0eb - 45...\n",
      "Processing 00869f0facebd0eb - 46...\n",
      "Processing 00869f0facebd0eb - 47...\n",
      "Processing 00869f0facebd0eb - 48...\n",
      "Processing 00869f0facebd0eb - 49...\n",
      "Processing 00869f0facebd0eb - 50...\n",
      "Processing 00869f0facebd0eb - 51...\n",
      "Processing 00869f0facebd0eb - 52...\n",
      "Processing 00869f0facebd0eb - 53...\n",
      "Processing 00869f0facebd0eb - 54...\n",
      "Processing 00869f0facebd0eb - 55...\n",
      "Processing 00869f0facebd0eb - 56...\n",
      "Processing 00869f0facebd0eb - 57...\n",
      "Processing 00869f0facebd0eb - 58...\n",
      "Processing 00869f0facebd0eb - 59...\n",
      "Processing 00869f0facebd0eb - 60...\n",
      "Processing 00869f0facebd0eb - 61...\n",
      "Processing 00869f0facebd0eb - 62...\n",
      "Processing 00869f0facebd0eb - 63...\n",
      "Processing 00869f0facebd0eb - 64...\n",
      "Processing 00869f0facebd0eb - 65...\n",
      "Processing 00869f0facebd0eb - 66...\n",
      "Processing ./img/resize\\0086b27db95aed77.jpg...\n",
      "\n",
      "0: 480x640 1 Sculpture, 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0086b27db95aed77 - 1...\n",
      "Processing 0086b27db95aed77 - 2...\n",
      "Processing ./img/resize\\0086cb300f74c7a3.jpg...\n",
      "\n",
      "0: 480x640 1 Tower, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0086cb300f74c7a3 - 1...\n",
      "Processing ./img/resize\\0086d486af5b83f2.jpg...\n",
      "\n",
      "0: 480x640 1 Bowl, 6 Boys, 3 Coffee tables, 2 Computer monitors, 4 Egg (Food)s, 1 Glasses, 7 Goggless, 1 Human face, 3 Human heads, 5 Sun hats, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "33\n",
      "Processing 0086d486af5b83f2 - 1...\n",
      "Processing 0086d486af5b83f2 - 2...\n",
      "Processing 0086d486af5b83f2 - 3...\n",
      "Processing 0086d486af5b83f2 - 4...\n",
      "Processing 0086d486af5b83f2 - 5...\n",
      "Processing 0086d486af5b83f2 - 6...\n",
      "Processing 0086d486af5b83f2 - 7...\n",
      "Processing 0086d486af5b83f2 - 8...\n",
      "Processing 0086d486af5b83f2 - 9...\n",
      "Processing 0086d486af5b83f2 - 10...\n",
      "Processing 0086d486af5b83f2 - 11...\n",
      "Processing 0086d486af5b83f2 - 12...\n",
      "Processing 0086d486af5b83f2 - 13...\n",
      "Processing 0086d486af5b83f2 - 14...\n",
      "Processing 0086d486af5b83f2 - 15...\n",
      "Processing 0086d486af5b83f2 - 16...\n",
      "Processing 0086d486af5b83f2 - 17...\n",
      "Processing 0086d486af5b83f2 - 18...\n",
      "Processing 0086d486af5b83f2 - 19...\n",
      "Processing 0086d486af5b83f2 - 20...\n",
      "Processing 0086d486af5b83f2 - 21...\n",
      "Processing 0086d486af5b83f2 - 22...\n",
      "Processing 0086d486af5b83f2 - 23...\n",
      "Processing 0086d486af5b83f2 - 24...\n",
      "Processing 0086d486af5b83f2 - 25...\n",
      "Processing 0086d486af5b83f2 - 26...\n",
      "Processing 0086d486af5b83f2 - 27...\n",
      "Processing 0086d486af5b83f2 - 28...\n",
      "Processing 0086d486af5b83f2 - 29...\n",
      "Processing 0086d486af5b83f2 - 30...\n",
      "Processing 0086d486af5b83f2 - 31...\n",
      "Processing 0086d486af5b83f2 - 32...\n",
      "Processing 0086d486af5b83f2 - 33...\n",
      "Processing ./img/resize\\0086db034e0ec2a8.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 3 Laptops, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0086db034e0ec2a8 - 1...\n",
      "Processing 0086db034e0ec2a8 - 2...\n",
      "Processing 0086db034e0ec2a8 - 3...\n",
      "Processing 0086db034e0ec2a8 - 4...\n",
      "Processing ./img/resize\\0086dd2cdf4248cf.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0086e66ce10fb5ba.jpg...\n",
      "\n",
      "0: 480x640 1 Owl, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0086e66ce10fb5ba - 1...\n",
      "Processing ./img/resize\\0087025a394a1aaf.jpg...\n",
      "\n",
      "0: 480x640 1 Adhesive tape, 3 Apples, 1 Auto part, 1 Bathroom accessory, 1 Beer, 1 Brassiere, 2 Cars, 1 Coffee cup, 1 Cosmetics, 6 Goggless, 1 Tea, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "19\n",
      "Processing 0087025a394a1aaf - 1...\n",
      "Processing 0087025a394a1aaf - 2...\n",
      "Processing 0087025a394a1aaf - 3...\n",
      "Processing 0087025a394a1aaf - 4...\n",
      "Processing 0087025a394a1aaf - 5...\n",
      "Processing 0087025a394a1aaf - 6...\n",
      "Processing 0087025a394a1aaf - 7...\n",
      "Processing 0087025a394a1aaf - 8...\n",
      "Processing 0087025a394a1aaf - 9...\n",
      "Processing 0087025a394a1aaf - 10...\n",
      "Processing 0087025a394a1aaf - 11...\n",
      "Processing 0087025a394a1aaf - 12...\n",
      "Processing 0087025a394a1aaf - 13...\n",
      "Processing 0087025a394a1aaf - 14...\n",
      "Processing 0087025a394a1aaf - 15...\n",
      "Processing 0087025a394a1aaf - 16...\n",
      "Processing 0087025a394a1aaf - 17...\n",
      "Processing 0087025a394a1aaf - 18...\n",
      "Processing 0087025a394a1aaf - 19...\n",
      "Processing ./img/resize\\00870dad830acabc.jpg...\n",
      "\n",
      "0: 480x640 1 Skyscraper, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00870dad830acabc - 1...\n",
      "Processing ./img/resize\\00876da7b281d83d.jpg...\n",
      "\n",
      "0: 480x640 1 Goggles, 1 Human face, 1 Sunglasses, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00876da7b281d83d - 1...\n",
      "Processing 00876da7b281d83d - 2...\n",
      "Processing 00876da7b281d83d - 3...\n",
      "Processing ./img/resize\\008794b8a099e4b3.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 1 Human face, 2 Womans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 008794b8a099e4b3 - 1...\n",
      "Processing 008794b8a099e4b3 - 2...\n",
      "Processing 008794b8a099e4b3 - 3...\n",
      "Processing 008794b8a099e4b3 - 4...\n",
      "Processing ./img/resize\\0087c0431a04be16.jpg...\n",
      "\n",
      "0: 480x640 3 Mans, 1 Suit, 1 Window, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 0087c0431a04be16 - 1...\n",
      "Processing 0087c0431a04be16 - 2...\n",
      "Processing 0087c0431a04be16 - 3...\n",
      "Processing 0087c0431a04be16 - 4...\n",
      "Processing 0087c0431a04be16 - 5...\n",
      "Processing ./img/resize\\0087f6676cde8bb3.jpg...\n",
      "\n",
      "0: 480x640 3 Mans, 3 Suits, 2 Tables, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 0087f6676cde8bb3 - 1...\n",
      "Processing 0087f6676cde8bb3 - 2...\n",
      "Processing 0087f6676cde8bb3 - 3...\n",
      "Processing 0087f6676cde8bb3 - 4...\n",
      "Processing 0087f6676cde8bb3 - 5...\n",
      "Processing 0087f6676cde8bb3 - 6...\n",
      "Processing 0087f6676cde8bb3 - 7...\n",
      "Processing 0087f6676cde8bb3 - 8...\n",
      "Processing ./img/resize\\00890863a605d387.jpg...\n",
      "\n",
      "0: 480x640 2 Trees, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00890863a605d387 - 1...\n",
      "Processing 00890863a605d387 - 2...\n",
      "Processing ./img/resize\\008a0cdf8280bb01.jpg...\n",
      "\n",
      "0: 480x640 3 Clothings, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 008a0cdf8280bb01 - 1...\n",
      "Processing 008a0cdf8280bb01 - 2...\n",
      "Processing 008a0cdf8280bb01 - 3...\n",
      "Processing 008a0cdf8280bb01 - 4...\n",
      "Processing ./img/resize\\008a861d9f6d94f4.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\008ad515db8b4508.jpg...\n",
      "\n",
      "0: 480x640 1 Skyscraper, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 008ad515db8b4508 - 1...\n",
      "Processing ./img/resize\\008b09bfdad84b43.jpg...\n",
      "\n",
      "0: 480x640 4 Clothings, 4 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 008b09bfdad84b43 - 1...\n",
      "Processing 008b09bfdad84b43 - 2...\n",
      "Processing 008b09bfdad84b43 - 3...\n",
      "Processing 008b09bfdad84b43 - 4...\n",
      "Processing 008b09bfdad84b43 - 5...\n",
      "Processing 008b09bfdad84b43 - 6...\n",
      "Processing 008b09bfdad84b43 - 7...\n",
      "Processing 008b09bfdad84b43 - 8...\n",
      "Processing ./img/resize\\008c0116989c3edd.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\008c199c5169f593.jpg...\n",
      "\n",
      "0: 480x640 1 Airplane, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 008c199c5169f593 - 1...\n",
      "Processing ./img/resize\\008c1dc7ff628196.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 008c1dc7ff628196 - 1...\n",
      "Processing 008c1dc7ff628196 - 2...\n",
      "Processing ./img/resize\\008c34315d9775ee.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Van, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 008c34315d9775ee - 1...\n",
      "Processing 008c34315d9775ee - 2...\n",
      "Processing ./img/resize\\008c7c56b2f378b9.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Rabbit, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 008c7c56b2f378b9 - 1...\n",
      "Processing 008c7c56b2f378b9 - 2...\n",
      "Processing ./img/resize\\008d2a5dd8dbbf03.jpg...\n",
      "\n",
      "0: 480x640 29 Tin cans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "29\n",
      "Processing 008d2a5dd8dbbf03 - 1...\n",
      "Processing 008d2a5dd8dbbf03 - 2...\n",
      "Processing 008d2a5dd8dbbf03 - 3...\n",
      "Processing 008d2a5dd8dbbf03 - 4...\n",
      "Processing 008d2a5dd8dbbf03 - 5...\n",
      "Processing 008d2a5dd8dbbf03 - 6...\n",
      "Processing 008d2a5dd8dbbf03 - 7...\n",
      "Processing 008d2a5dd8dbbf03 - 8...\n",
      "Processing 008d2a5dd8dbbf03 - 9...\n",
      "Processing 008d2a5dd8dbbf03 - 10...\n",
      "Processing 008d2a5dd8dbbf03 - 11...\n",
      "Processing 008d2a5dd8dbbf03 - 12...\n",
      "Processing 008d2a5dd8dbbf03 - 13...\n",
      "Processing 008d2a5dd8dbbf03 - 14...\n",
      "Processing 008d2a5dd8dbbf03 - 15...\n",
      "Processing 008d2a5dd8dbbf03 - 16...\n",
      "Processing 008d2a5dd8dbbf03 - 17...\n",
      "Processing 008d2a5dd8dbbf03 - 18...\n",
      "Processing 008d2a5dd8dbbf03 - 19...\n",
      "Processing 008d2a5dd8dbbf03 - 20...\n",
      "Processing 008d2a5dd8dbbf03 - 21...\n",
      "Processing 008d2a5dd8dbbf03 - 22...\n",
      "Processing 008d2a5dd8dbbf03 - 23...\n",
      "Processing 008d2a5dd8dbbf03 - 24...\n",
      "Processing 008d2a5dd8dbbf03 - 25...\n",
      "Processing 008d2a5dd8dbbf03 - 26...\n",
      "Processing 008d2a5dd8dbbf03 - 27...\n",
      "Processing 008d2a5dd8dbbf03 - 28...\n",
      "Processing 008d2a5dd8dbbf03 - 29...\n",
      "Processing ./img/resize\\008da2d2b149c7c4.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Clothing, 2 Human faces, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 008da2d2b149c7c4 - 1...\n",
      "Processing 008da2d2b149c7c4 - 2...\n",
      "Processing 008da2d2b149c7c4 - 3...\n",
      "Processing 008da2d2b149c7c4 - 4...\n",
      "Processing 008da2d2b149c7c4 - 5...\n",
      "Processing ./img/resize\\008e90ccbc58f920.jpg...\n",
      "\n",
      "0: 480x640 6 Clothings, 5 Mans, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "12\n",
      "Processing 008e90ccbc58f920 - 1...\n",
      "Processing 008e90ccbc58f920 - 2...\n",
      "Processing 008e90ccbc58f920 - 3...\n",
      "Processing 008e90ccbc58f920 - 4...\n",
      "Processing 008e90ccbc58f920 - 5...\n",
      "Processing 008e90ccbc58f920 - 6...\n",
      "Processing 008e90ccbc58f920 - 7...\n",
      "Processing 008e90ccbc58f920 - 8...\n",
      "Processing 008e90ccbc58f920 - 9...\n",
      "Processing 008e90ccbc58f920 - 10...\n",
      "Processing 008e90ccbc58f920 - 11...\n",
      "Processing 008e90ccbc58f920 - 12...\n",
      "Processing ./img/resize\\008eabe86ea369a7.jpg...\n",
      "\n",
      "0: 480x640 1 Footwear, 1 Girl, 1 Sun hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 008eabe86ea369a7 - 1...\n",
      "Processing 008eabe86ea369a7 - 2...\n",
      "Processing 008eabe86ea369a7 - 3...\n",
      "Processing ./img/resize\\008f291ce79ffe24.jpg...\n",
      "\n",
      "0: 480x640 2 Womans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 008f291ce79ffe24 - 1...\n",
      "Processing 008f291ce79ffe24 - 2...\n",
      "Processing ./img/resize\\008f2cfaf8d8b1c5.jpg...\n",
      "\n",
      "0: 480x640 1 Airplane, 30.0ms\n",
      "Speed: 1.9ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 008f2cfaf8d8b1c5 - 1...\n",
      "Processing ./img/resize\\008fb317eb17858b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\008fd91cf67f26ca.jpg...\n",
      "\n",
      "0: 480x640 6 Boats, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 008fd91cf67f26ca - 1...\n",
      "Processing 008fd91cf67f26ca - 2...\n",
      "Processing 008fd91cf67f26ca - 3...\n",
      "Processing 008fd91cf67f26ca - 4...\n",
      "Processing 008fd91cf67f26ca - 5...\n",
      "Processing 008fd91cf67f26ca - 6...\n",
      "Processing ./img/resize\\008fe43bf697a0c0.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 008fe43bf697a0c0 - 1...\n",
      "Processing ./img/resize\\009016711ee997fc.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 009016711ee997fc - 1...\n",
      "Processing ./img/resize\\00902df449c3460e.jpg...\n",
      "\n",
      "0: 480x640 4 Hamburgers, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00902df449c3460e - 1...\n",
      "Processing 00902df449c3460e - 2...\n",
      "Processing 00902df449c3460e - 3...\n",
      "Processing 00902df449c3460e - 4...\n",
      "Processing ./img/resize\\00907da87b13210f.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 2 Sports uniforms, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00907da87b13210f - 1...\n",
      "Processing 00907da87b13210f - 2...\n",
      "Processing 00907da87b13210f - 3...\n",
      "Processing 00907da87b13210f - 4...\n",
      "Processing ./img/resize\\00908c00168974fd.jpg...\n",
      "\n",
      "0: 480x640 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00908c00168974fd - 1...\n",
      "Processing ./img/resize\\0090cee01c17eda4.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0090f9e87c6fd513.jpg...\n",
      "\n",
      "0: 480x640 1 Drawer, 3 Goggless, 1 Human face, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 0090f9e87c6fd513 - 1...\n",
      "Processing 0090f9e87c6fd513 - 2...\n",
      "Processing 0090f9e87c6fd513 - 3...\n",
      "Processing 0090f9e87c6fd513 - 4...\n",
      "Processing 0090f9e87c6fd513 - 5...\n",
      "Processing ./img/resize\\00910414f88187fd.jpg...\n",
      "\n",
      "0: 480x640 1 Horse, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00910414f88187fd - 1...\n",
      "Processing ./img/resize\\00911bd3213d0353.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00911bd3213d0353 - 1...\n",
      "Processing 00911bd3213d0353 - 2...\n",
      "Processing ./img/resize\\00912e5a453b13bd.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle, 2 Bicycle wheels, 1 Person, 1 Rose, 2 Tires, 2 Wheels, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 00912e5a453b13bd - 1...\n",
      "Processing 00912e5a453b13bd - 2...\n",
      "Processing 00912e5a453b13bd - 3...\n",
      "Processing 00912e5a453b13bd - 4...\n",
      "Processing 00912e5a453b13bd - 5...\n",
      "Processing 00912e5a453b13bd - 6...\n",
      "Processing 00912e5a453b13bd - 7...\n",
      "Processing 00912e5a453b13bd - 8...\n",
      "Processing 00912e5a453b13bd - 9...\n",
      "Processing ./img/resize\\0091bd79dea1280b.jpg...\n",
      "\n",
      "0: 480x640 1 Coffee table, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0091bd79dea1280b - 1...\n",
      "Processing ./img/resize\\00934bf07abd8653.jpg...\n",
      "\n",
      "0: 480x640 6 Bicycle wheels, 1 Egg (Food), 2 Human bodys, 3 Human faces, 1 Loveseat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "13\n",
      "Processing 00934bf07abd8653 - 1...\n",
      "Processing 00934bf07abd8653 - 2...\n",
      "Processing 00934bf07abd8653 - 3...\n",
      "Processing 00934bf07abd8653 - 4...\n",
      "Processing 00934bf07abd8653 - 5...\n",
      "Processing 00934bf07abd8653 - 6...\n",
      "Processing 00934bf07abd8653 - 7...\n",
      "Processing 00934bf07abd8653 - 8...\n",
      "Processing 00934bf07abd8653 - 9...\n",
      "Processing 00934bf07abd8653 - 10...\n",
      "Processing 00934bf07abd8653 - 11...\n",
      "Processing 00934bf07abd8653 - 12...\n",
      "Processing 00934bf07abd8653 - 13...\n",
      "Processing ./img/resize\\00937e0f575d47ab.jpg...\n",
      "\n",
      "0: 480x640 4 Boys, 1 Coat, 1 Coffee table, 1 Dress, 1 Fedora, 1 Goggles, 1 Human face, 1 Human hair, 1 Human head, 1 Man, 2 Muffins, 2 Shirts, 1 Suit, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "18\n",
      "Processing 00937e0f575d47ab - 1...\n",
      "Processing 00937e0f575d47ab - 2...\n",
      "Processing 00937e0f575d47ab - 3...\n",
      "Processing 00937e0f575d47ab - 4...\n",
      "Processing 00937e0f575d47ab - 5...\n",
      "Processing 00937e0f575d47ab - 6...\n",
      "Processing 00937e0f575d47ab - 7...\n",
      "Processing 00937e0f575d47ab - 8...\n",
      "Processing 00937e0f575d47ab - 9...\n",
      "Processing 00937e0f575d47ab - 10...\n",
      "Processing 00937e0f575d47ab - 11...\n",
      "Processing 00937e0f575d47ab - 12...\n",
      "Processing 00937e0f575d47ab - 13...\n",
      "Processing 00937e0f575d47ab - 14...\n",
      "Processing 00937e0f575d47ab - 15...\n",
      "Processing 00937e0f575d47ab - 16...\n",
      "Processing 00937e0f575d47ab - 17...\n",
      "Processing 00937e0f575d47ab - 18...\n",
      "Processing ./img/resize\\00939878ac8e2bd1.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Car, 1 Human face, 1 Human head, 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00939878ac8e2bd1 - 1...\n",
      "Processing 00939878ac8e2bd1 - 2...\n",
      "Processing 00939878ac8e2bd1 - 3...\n",
      "Processing 00939878ac8e2bd1 - 4...\n",
      "Processing 00939878ac8e2bd1 - 5...\n",
      "Processing ./img/resize\\0094063cc9a16f0e.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0094063cc9a16f0e - 1...\n",
      "Processing ./img/resize\\00940d9a2fe72fd8.jpg...\n",
      "\n",
      "0: 480x640 1 Helicopter, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00940d9a2fe72fd8 - 1...\n",
      "Processing ./img/resize\\0094eb82b9f7c5b3.jpg...\n",
      "\n",
      "0: 480x640 1 Door, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0094eb82b9f7c5b3 - 1...\n",
      "Processing ./img/resize\\009510a0b8966993.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0095b78e3923ec4f.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle helmet, 4 Boys, 1 Coffee table, 7 Goggless, 2 Human hairs, 1 Human head, 4 Mans, 6 Shirts, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "26\n",
      "Processing 0095b78e3923ec4f - 1...\n",
      "Processing 0095b78e3923ec4f - 2...\n",
      "Processing 0095b78e3923ec4f - 3...\n",
      "Processing 0095b78e3923ec4f - 4...\n",
      "Processing 0095b78e3923ec4f - 5...\n",
      "Processing 0095b78e3923ec4f - 6...\n",
      "Processing 0095b78e3923ec4f - 7...\n",
      "Processing 0095b78e3923ec4f - 8...\n",
      "Processing 0095b78e3923ec4f - 9...\n",
      "Processing 0095b78e3923ec4f - 10...\n",
      "Processing 0095b78e3923ec4f - 11...\n",
      "Processing 0095b78e3923ec4f - 12...\n",
      "Processing 0095b78e3923ec4f - 13...\n",
      "Processing 0095b78e3923ec4f - 14...\n",
      "Processing 0095b78e3923ec4f - 15...\n",
      "Processing 0095b78e3923ec4f - 16...\n",
      "Processing 0095b78e3923ec4f - 17...\n",
      "Processing 0095b78e3923ec4f - 18...\n",
      "Processing 0095b78e3923ec4f - 19...\n",
      "Processing 0095b78e3923ec4f - 20...\n",
      "Processing 0095b78e3923ec4f - 21...\n",
      "Processing 0095b78e3923ec4f - 22...\n",
      "Processing 0095b78e3923ec4f - 23...\n",
      "Processing 0095b78e3923ec4f - 24...\n",
      "Processing 0095b78e3923ec4f - 25...\n",
      "Processing 0095b78e3923ec4f - 26...\n",
      "Processing ./img/resize\\0095d554fb774d08.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0095d554fb774d08 - 1...\n",
      "Processing ./img/resize\\00960a300ea54117.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Coffee table, 3 Human heads, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00960a300ea54117 - 1...\n",
      "Processing 00960a300ea54117 - 2...\n",
      "Processing 00960a300ea54117 - 3...\n",
      "Processing 00960a300ea54117 - 4...\n",
      "Processing 00960a300ea54117 - 5...\n",
      "Processing ./img/resize\\00961ec7476d6f03.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 2 Womans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00961ec7476d6f03 - 1...\n",
      "Processing 00961ec7476d6f03 - 2...\n",
      "Processing 00961ec7476d6f03 - 3...\n",
      "Processing ./img/resize\\00963ebe1f3676ac.jpg...\n",
      "\n",
      "0: 480x640 1 Armadillo, 1 Bicycle wheel, 1 Cattle, 1 Light switch, 1 Pig, 1 Soap dispenser, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00963ebe1f3676ac - 1...\n",
      "Processing 00963ebe1f3676ac - 2...\n",
      "Processing 00963ebe1f3676ac - 3...\n",
      "Processing 00963ebe1f3676ac - 4...\n",
      "Processing 00963ebe1f3676ac - 5...\n",
      "Processing 00963ebe1f3676ac - 6...\n",
      "Processing ./img/resize\\00964122044b1b2d.jpg...\n",
      "\n",
      "0: 480x640 2 Persons, 1 Sports equipment, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00964122044b1b2d - 1...\n",
      "Processing 00964122044b1b2d - 2...\n",
      "Processing 00964122044b1b2d - 3...\n",
      "Processing ./img/resize\\00968589ac02a00b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0096a63a7cf76c47.jpg...\n",
      "\n",
      "0: 480x640 1 Canoe, 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0096a63a7cf76c47 - 1...\n",
      "Processing 0096a63a7cf76c47 - 2...\n",
      "Processing ./img/resize\\0096abfb93fc4deb.jpg...\n",
      "\n",
      "0: 480x640 4 Mans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0096abfb93fc4deb - 1...\n",
      "Processing 0096abfb93fc4deb - 2...\n",
      "Processing 0096abfb93fc4deb - 3...\n",
      "Processing 0096abfb93fc4deb - 4...\n",
      "Processing ./img/resize\\00972b8bf2e6ccc5.jpg...\n",
      "\n",
      "0: 480x640 1 Bird, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00972b8bf2e6ccc5 - 1...\n",
      "Processing ./img/resize\\009739315fa550ee.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 3 Coffee tables, 1 Dress, 2 Egg (Food)s, 1 Human arm, 2 Human faces, 1 Human hair, 2 Sun hats, 1 Trousers, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "14\n",
      "Processing 009739315fa550ee - 1...\n",
      "Processing 009739315fa550ee - 2...\n",
      "Processing 009739315fa550ee - 3...\n",
      "Processing 009739315fa550ee - 4...\n",
      "Processing 009739315fa550ee - 5...\n",
      "Processing 009739315fa550ee - 6...\n",
      "Processing 009739315fa550ee - 7...\n",
      "Processing 009739315fa550ee - 8...\n",
      "Processing 009739315fa550ee - 9...\n",
      "Processing 009739315fa550ee - 10...\n",
      "Processing 009739315fa550ee - 11...\n",
      "Processing 009739315fa550ee - 12...\n",
      "Processing 009739315fa550ee - 13...\n",
      "Processing 009739315fa550ee - 14...\n",
      "Processing ./img/resize\\0097683580838f04.jpg...\n",
      "\n",
      "0: 480x640 1 Ant, 1 Bathroom accessory, 2 Bicycle wheels, 1 Car, 1 Fashion accessory, 4 Goggless, 1 Human head, 1 Shower, 1 Wheel, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "13\n",
      "Processing 0097683580838f04 - 1...\n",
      "Processing 0097683580838f04 - 2...\n",
      "Processing 0097683580838f04 - 3...\n",
      "Processing 0097683580838f04 - 4...\n",
      "Processing 0097683580838f04 - 5...\n",
      "Processing 0097683580838f04 - 6...\n",
      "Processing 0097683580838f04 - 7...\n",
      "Processing 0097683580838f04 - 8...\n",
      "Processing 0097683580838f04 - 9...\n",
      "Processing 0097683580838f04 - 10...\n",
      "Processing 0097683580838f04 - 11...\n",
      "Processing 0097683580838f04 - 12...\n",
      "Processing 0097683580838f04 - 13...\n",
      "Processing ./img/resize\\0098207b31dfac6c.jpg...\n",
      "\n",
      "0: 480x640 1 Door, 1 House, 2 Windows, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0098207b31dfac6c - 1...\n",
      "Processing 0098207b31dfac6c - 2...\n",
      "Processing 0098207b31dfac6c - 3...\n",
      "Processing 0098207b31dfac6c - 4...\n",
      "Processing ./img/resize\\009825a039ebf0e0.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\009847496908a1ad.jpg...\n",
      "\n",
      "0: 480x640 1 Ball, 1 Footwear, 3 Mans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 009847496908a1ad - 1...\n",
      "Processing 009847496908a1ad - 2...\n",
      "Processing 009847496908a1ad - 3...\n",
      "Processing 009847496908a1ad - 4...\n",
      "Processing 009847496908a1ad - 5...\n",
      "Processing ./img/resize\\0098e5d39e24e716.jpg...\n",
      "\n",
      "0: 480x640 1 Guitar, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0098e5d39e24e716 - 1...\n",
      "Processing ./img/resize\\0099148853b47562.jpg...\n",
      "\n",
      "0: 480x640 1 Wine glass, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0099148853b47562 - 1...\n",
      "Processing ./img/resize\\009994d5c5cb5a2b.jpg...\n",
      "\n",
      "0: 480x640 2 Buss, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 009994d5c5cb5a2b - 1...\n",
      "Processing 009994d5c5cb5a2b - 2...\n",
      "Processing ./img/resize\\0099ad09513db92c.jpg...\n",
      "\n",
      "0: 480x640 9 Balls, 1 Bicycle wheel, 1 Clothing, 4 Goggless, 1 Human body, 2 Human faces, 1 Human head, 1 Man, 1 Woman, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "21\n",
      "Processing 0099ad09513db92c - 1...\n",
      "Processing 0099ad09513db92c - 2...\n",
      "Processing 0099ad09513db92c - 3...\n",
      "Processing 0099ad09513db92c - 4...\n",
      "Processing 0099ad09513db92c - 5...\n",
      "Processing 0099ad09513db92c - 6...\n",
      "Processing 0099ad09513db92c - 7...\n",
      "Processing 0099ad09513db92c - 8...\n",
      "Processing 0099ad09513db92c - 9...\n",
      "Processing 0099ad09513db92c - 10...\n",
      "Processing 0099ad09513db92c - 11...\n",
      "Processing 0099ad09513db92c - 12...\n",
      "Processing 0099ad09513db92c - 13...\n",
      "Processing 0099ad09513db92c - 14...\n",
      "Processing 0099ad09513db92c - 15...\n",
      "Processing 0099ad09513db92c - 16...\n",
      "Processing 0099ad09513db92c - 17...\n",
      "Processing 0099ad09513db92c - 18...\n",
      "Processing 0099ad09513db92c - 19...\n",
      "Processing 0099ad09513db92c - 20...\n",
      "Processing 0099ad09513db92c - 21...\n",
      "Processing ./img/resize\\0099bb1e8a4f95b8.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0099c30b163f3ae1.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0099c30b163f3ae1 - 1...\n",
      "Processing ./img/resize\\009a2885cab0857b.jpg...\n",
      "\n",
      "0: 480x640 3 Palm trees, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 009a2885cab0857b - 1...\n",
      "Processing 009a2885cab0857b - 2...\n",
      "Processing 009a2885cab0857b - 3...\n",
      "Processing ./img/resize\\009a609f01c68186.jpg...\n",
      "\n",
      "0: 480x640 4 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 009a609f01c68186 - 1...\n",
      "Processing 009a609f01c68186 - 2...\n",
      "Processing 009a609f01c68186 - 3...\n",
      "Processing 009a609f01c68186 - 4...\n",
      "Processing ./img/resize\\009af922c0f166a0.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle, 2 Bicycle wheels, 1 Tree, 2 Wheels, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 009af922c0f166a0 - 1...\n",
      "Processing 009af922c0f166a0 - 2...\n",
      "Processing 009af922c0f166a0 - 3...\n",
      "Processing 009af922c0f166a0 - 4...\n",
      "Processing 009af922c0f166a0 - 5...\n",
      "Processing 009af922c0f166a0 - 6...\n",
      "Processing ./img/resize\\009b067a652d7d79.jpg...\n",
      "\n",
      "0: 480x640 1 Bus, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 009b067a652d7d79 - 1...\n",
      "Processing ./img/resize\\009b230bae16361c.jpg...\n",
      "\n",
      "0: 480x640 1 Dress, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 009b230bae16361c - 1...\n",
      "Processing ./img/resize\\009b5378bedaff01.jpg...\n",
      "\n",
      "0: 480x640 1 Insect, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 009b5378bedaff01 - 1...\n",
      "Processing ./img/resize\\009b71cc4fd38230.jpg...\n",
      "\n",
      "0: 480x640 1 Dog, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 009b71cc4fd38230 - 1...\n",
      "Processing ./img/resize\\009b890887c6572c.jpg...\n",
      "\n",
      "0: 480x640 1 Bee, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 009b890887c6572c - 1...\n",
      "Processing ./img/resize\\009bed86cec77b2a.jpg...\n",
      "\n",
      "0: 480x640 3 Mans, 2 Suits, 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 009bed86cec77b2a - 1...\n",
      "Processing 009bed86cec77b2a - 2...\n",
      "Processing 009bed86cec77b2a - 3...\n",
      "Processing 009bed86cec77b2a - 4...\n",
      "Processing 009bed86cec77b2a - 5...\n",
      "Processing ./img/resize\\009bf5ad19cd8f72.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\009c5979794f4a2f.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Dog, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 009c5979794f4a2f - 1...\n",
      "Processing 009c5979794f4a2f - 2...\n",
      "Processing ./img/resize\\009c8b0a19b954fc.jpg...\n",
      "\n",
      "0: 480x640 7 Boys, 1 Coffee table, 2 Egg (Food)s, 3 Goggless, 2 Grapefruits, 3 Human heads, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "18\n",
      "Processing 009c8b0a19b954fc - 1...\n",
      "Processing 009c8b0a19b954fc - 2...\n",
      "Processing 009c8b0a19b954fc - 3...\n",
      "Processing 009c8b0a19b954fc - 4...\n",
      "Processing 009c8b0a19b954fc - 5...\n",
      "Processing 009c8b0a19b954fc - 6...\n",
      "Processing 009c8b0a19b954fc - 7...\n",
      "Processing 009c8b0a19b954fc - 8...\n",
      "Processing 009c8b0a19b954fc - 9...\n",
      "Processing 009c8b0a19b954fc - 10...\n",
      "Processing 009c8b0a19b954fc - 11...\n",
      "Processing 009c8b0a19b954fc - 12...\n",
      "Processing 009c8b0a19b954fc - 13...\n",
      "Processing 009c8b0a19b954fc - 14...\n",
      "Processing 009c8b0a19b954fc - 15...\n",
      "Processing 009c8b0a19b954fc - 16...\n",
      "Processing 009c8b0a19b954fc - 17...\n",
      "Processing 009c8b0a19b954fc - 18...\n",
      "Processing ./img/resize\\009c9cc9b5fc1ba2.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle helmet, 1 Bicycle wheel, 2 Bowls, 7 Boys, 1 Coffee cup, 7 Coffee tables, 1 Drawer, 7 Egg (Food)s, 3 Goggless, 3 Grapefruits, 1 Human face, 2 Human heads, 1 Skirt, 2 Sun hats, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "39\n",
      "Processing 009c9cc9b5fc1ba2 - 1...\n",
      "Processing 009c9cc9b5fc1ba2 - 2...\n",
      "Processing 009c9cc9b5fc1ba2 - 3...\n",
      "Processing 009c9cc9b5fc1ba2 - 4...\n",
      "Processing 009c9cc9b5fc1ba2 - 5...\n",
      "Processing 009c9cc9b5fc1ba2 - 6...\n",
      "Processing 009c9cc9b5fc1ba2 - 7...\n",
      "Processing 009c9cc9b5fc1ba2 - 8...\n",
      "Processing 009c9cc9b5fc1ba2 - 9...\n",
      "Processing 009c9cc9b5fc1ba2 - 10...\n",
      "Processing 009c9cc9b5fc1ba2 - 11...\n",
      "Processing 009c9cc9b5fc1ba2 - 12...\n",
      "Processing 009c9cc9b5fc1ba2 - 13...\n",
      "Processing 009c9cc9b5fc1ba2 - 14...\n",
      "Processing 009c9cc9b5fc1ba2 - 15...\n",
      "Processing 009c9cc9b5fc1ba2 - 16...\n",
      "Processing 009c9cc9b5fc1ba2 - 17...\n",
      "Processing 009c9cc9b5fc1ba2 - 18...\n",
      "Processing 009c9cc9b5fc1ba2 - 19...\n",
      "Processing 009c9cc9b5fc1ba2 - 20...\n",
      "Processing 009c9cc9b5fc1ba2 - 21...\n",
      "Processing 009c9cc9b5fc1ba2 - 22...\n",
      "Processing 009c9cc9b5fc1ba2 - 23...\n",
      "Processing 009c9cc9b5fc1ba2 - 24...\n",
      "Processing 009c9cc9b5fc1ba2 - 25...\n",
      "Processing 009c9cc9b5fc1ba2 - 26...\n",
      "Processing 009c9cc9b5fc1ba2 - 27...\n",
      "Processing 009c9cc9b5fc1ba2 - 28...\n",
      "Processing 009c9cc9b5fc1ba2 - 29...\n",
      "Processing 009c9cc9b5fc1ba2 - 30...\n",
      "Processing 009c9cc9b5fc1ba2 - 31...\n",
      "Processing 009c9cc9b5fc1ba2 - 32...\n",
      "Processing 009c9cc9b5fc1ba2 - 33...\n",
      "Processing 009c9cc9b5fc1ba2 - 34...\n",
      "Processing 009c9cc9b5fc1ba2 - 35...\n",
      "Processing 009c9cc9b5fc1ba2 - 36...\n",
      "Processing 009c9cc9b5fc1ba2 - 37...\n",
      "Processing 009c9cc9b5fc1ba2 - 38...\n",
      "Processing 009c9cc9b5fc1ba2 - 39...\n",
      "Processing ./img/resize\\009ccd7da735fc21.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 009ccd7da735fc21 - 1...\n",
      "Processing ./img/resize\\009d556a9aa06e1b.jpg...\n",
      "\n",
      "0: 480x640 1 Animal, 1 Auto part, 1 Banana, 2 Beehives, 2 Butterflys, 1 Plant, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 009d556a9aa06e1b - 1...\n",
      "Processing 009d556a9aa06e1b - 2...\n",
      "Processing 009d556a9aa06e1b - 3...\n",
      "Processing 009d556a9aa06e1b - 4...\n",
      "Processing 009d556a9aa06e1b - 5...\n",
      "Processing 009d556a9aa06e1b - 6...\n",
      "Processing 009d556a9aa06e1b - 7...\n",
      "Processing 009d556a9aa06e1b - 8...\n",
      "Processing ./img/resize\\009db8913bdb108b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\009dde42a2f637ad.jpg...\n",
      "\n",
      "0: 480x640 3 Clothings, 7 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "10\n",
      "Processing 009dde42a2f637ad - 1...\n",
      "Processing 009dde42a2f637ad - 2...\n",
      "Processing 009dde42a2f637ad - 3...\n",
      "Processing 009dde42a2f637ad - 4...\n",
      "Processing 009dde42a2f637ad - 5...\n",
      "Processing 009dde42a2f637ad - 6...\n",
      "Processing 009dde42a2f637ad - 7...\n",
      "Processing 009dde42a2f637ad - 8...\n",
      "Processing 009dde42a2f637ad - 9...\n",
      "Processing 009dde42a2f637ad - 10...\n",
      "Processing ./img/resize\\009de56c84685ba5.jpg...\n",
      "\n",
      "0: 480x640 1 Christmas tree, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 009de56c84685ba5 - 1...\n",
      "Processing ./img/resize\\009e71cf131399a0.jpg...\n",
      "\n",
      "0: 480x640 4 Boys, 2 Goggless, 1 Human head, 2 Mans, 2 Roller skatess, 2 Roses, 3 Shirts, 3 Suits, 1 Sun hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "20\n",
      "Processing 009e71cf131399a0 - 1...\n",
      "Processing 009e71cf131399a0 - 2...\n",
      "Processing 009e71cf131399a0 - 3...\n",
      "Processing 009e71cf131399a0 - 4...\n",
      "Processing 009e71cf131399a0 - 5...\n",
      "Processing 009e71cf131399a0 - 6...\n",
      "Processing 009e71cf131399a0 - 7...\n",
      "Processing 009e71cf131399a0 - 8...\n",
      "Processing 009e71cf131399a0 - 9...\n",
      "Processing 009e71cf131399a0 - 10...\n",
      "Processing 009e71cf131399a0 - 11...\n",
      "Processing 009e71cf131399a0 - 12...\n",
      "Processing 009e71cf131399a0 - 13...\n",
      "Processing 009e71cf131399a0 - 14...\n",
      "Processing 009e71cf131399a0 - 15...\n",
      "Processing 009e71cf131399a0 - 16...\n",
      "Processing 009e71cf131399a0 - 17...\n",
      "Processing 009e71cf131399a0 - 18...\n",
      "Processing 009e71cf131399a0 - 19...\n",
      "Processing 009e71cf131399a0 - 20...\n",
      "Processing ./img/resize\\009f259e443a58b8.jpg...\n",
      "\n",
      "0: 480x640 1 Houseplant, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 009f259e443a58b8 - 1...\n",
      "Processing ./img/resize\\009fa7754fece924.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00a0491033b0cb63.jpg...\n",
      "\n",
      "0: 480x640 1 Ball, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00a0491033b0cb63 - 1...\n",
      "Processing ./img/resize\\00a06353e116fb75.jpg...\n",
      "\n",
      "0: 480x640 1 Sculpture, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00a06353e116fb75 - 1...\n",
      "Processing ./img/resize\\00a09bf8a4d943b5.jpg...\n",
      "\n",
      "0: 480x640 3 Dolphins, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00a09bf8a4d943b5 - 1...\n",
      "Processing 00a09bf8a4d943b5 - 2...\n",
      "Processing 00a09bf8a4d943b5 - 3...\n",
      "Processing ./img/resize\\00a0fedc012cce05.jpg...\n",
      "\n",
      "0: 480x640 3 Mans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00a0fedc012cce05 - 1...\n",
      "Processing 00a0fedc012cce05 - 2...\n",
      "Processing 00a0fedc012cce05 - 3...\n",
      "Processing ./img/resize\\00a12db7abb26c9c.jpg...\n",
      "\n",
      "0: 480x640 2 Common sunflowers, 1 Sun hat, 1 Swimwear, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00a12db7abb26c9c - 1...\n",
      "Processing 00a12db7abb26c9c - 2...\n",
      "Processing 00a12db7abb26c9c - 3...\n",
      "Processing 00a12db7abb26c9c - 4...\n",
      "Processing ./img/resize\\00a130980e1747ed.jpg...\n",
      "\n",
      "0: 480x640 1 Plant, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00a130980e1747ed - 1...\n",
      "Processing ./img/resize\\00a1568f9906eaa8.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00a1e4370005ee7b.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00a1e4370005ee7b - 1...\n",
      "Processing ./img/resize\\00a27291b4cf7b40.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00a28793e0d1ac72.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00a28793e0d1ac72 - 1...\n",
      "Processing ./img/resize\\00a2aeacf2469920.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 33.0ms\n",
      "Speed: 1.0ms preprocess, 33.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00a2aeacf2469920 - 1...\n",
      "Processing 00a2aeacf2469920 - 2...\n",
      "Processing ./img/resize\\00a2aefdc67f263f.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00a2d9d79f8e8bf0.jpg...\n",
      "\n",
      "0: 480x640 1 Guitar, 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00a2d9d79f8e8bf0 - 1...\n",
      "Processing 00a2d9d79f8e8bf0 - 2...\n",
      "Processing 00a2d9d79f8e8bf0 - 3...\n",
      "Processing ./img/resize\\00a2e43047dcd44a.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00a2e43047dcd44a - 1...\n",
      "Processing ./img/resize\\00a2fb1fb083da68.jpg...\n",
      "\n",
      "0: 480x640 2 Laptops, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00a2fb1fb083da68 - 1...\n",
      "Processing 00a2fb1fb083da68 - 2...\n",
      "Processing 00a2fb1fb083da68 - 3...\n",
      "Processing ./img/resize\\00a353126980b5d8.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Man, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00a353126980b5d8 - 1...\n",
      "Processing 00a353126980b5d8 - 2...\n",
      "Processing ./img/resize\\00a3bc010db7cbef.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00a3bc010db7cbef - 1...\n",
      "Processing ./img/resize\\00a3e18b5904f497.jpg...\n",
      "\n",
      "0: 480x640 5 Footwears, 6 Mans, 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "12\n",
      "Processing 00a3e18b5904f497 - 1...\n",
      "Processing 00a3e18b5904f497 - 2...\n",
      "Processing 00a3e18b5904f497 - 3...\n",
      "Processing 00a3e18b5904f497 - 4...\n",
      "Processing 00a3e18b5904f497 - 5...\n",
      "Processing 00a3e18b5904f497 - 6...\n",
      "Processing 00a3e18b5904f497 - 7...\n",
      "Processing 00a3e18b5904f497 - 8...\n",
      "Processing 00a3e18b5904f497 - 9...\n",
      "Processing 00a3e18b5904f497 - 10...\n",
      "Processing 00a3e18b5904f497 - 11...\n",
      "Processing 00a3e18b5904f497 - 12...\n",
      "Processing ./img/resize\\00a42fc158bbdc03.jpg...\n",
      "\n",
      "0: 480x640 2 Buss, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00a42fc158bbdc03 - 1...\n",
      "Processing 00a42fc158bbdc03 - 2...\n",
      "Processing ./img/resize\\00a45c1499af9c25.jpg...\n",
      "\n",
      "0: 480x640 1 Bench, 1 Boat, 1 Goggles, 1 Porch, 1 Sunglasses, 1 Table, 1 Tableware, 1 Tire, 1 Wheel, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 00a45c1499af9c25 - 1...\n",
      "Processing 00a45c1499af9c25 - 2...\n",
      "Processing 00a45c1499af9c25 - 3...\n",
      "Processing 00a45c1499af9c25 - 4...\n",
      "Processing 00a45c1499af9c25 - 5...\n",
      "Processing 00a45c1499af9c25 - 6...\n",
      "Processing 00a45c1499af9c25 - 7...\n",
      "Processing 00a45c1499af9c25 - 8...\n",
      "Processing 00a45c1499af9c25 - 9...\n",
      "Processing ./img/resize\\00a4c67f19c078b5.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00a4dda5785848bb.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00a4dda5785848bb - 1...\n",
      "Processing 00a4dda5785848bb - 2...\n",
      "Processing ./img/resize\\00a4e010d37dadcd.jpg...\n",
      "\n",
      "0: 480x640 1 Belt, 1 Bowl, 1 Cowboy hat, 1 Dog, 1 Fashion accessory, 1 Flying disc, 3 Goggless, 4 Hats, 1 Person, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "14\n",
      "Processing 00a4e010d37dadcd - 1...\n",
      "Processing 00a4e010d37dadcd - 2...\n",
      "Processing 00a4e010d37dadcd - 3...\n",
      "Processing 00a4e010d37dadcd - 4...\n",
      "Processing 00a4e010d37dadcd - 5...\n",
      "Processing 00a4e010d37dadcd - 6...\n",
      "Processing 00a4e010d37dadcd - 7...\n",
      "Processing 00a4e010d37dadcd - 8...\n",
      "Processing 00a4e010d37dadcd - 9...\n",
      "Processing 00a4e010d37dadcd - 10...\n",
      "Processing 00a4e010d37dadcd - 11...\n",
      "Processing 00a4e010d37dadcd - 12...\n",
      "Processing 00a4e010d37dadcd - 13...\n",
      "Processing 00a4e010d37dadcd - 14...\n",
      "Processing ./img/resize\\00a4e8944cc8ad7b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00a51efbb8372459.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 1 Boy, 2 Mans, 1 Person, 1 Shirt, 1 Suit, 1 Sun hat, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00a51efbb8372459 - 1...\n",
      "Processing 00a51efbb8372459 - 2...\n",
      "Processing 00a51efbb8372459 - 3...\n",
      "Processing 00a51efbb8372459 - 4...\n",
      "Processing 00a51efbb8372459 - 5...\n",
      "Processing 00a51efbb8372459 - 6...\n",
      "Processing 00a51efbb8372459 - 7...\n",
      "Processing 00a51efbb8372459 - 8...\n",
      "Processing ./img/resize\\00a56327032571c8.jpg...\n",
      "\n",
      "0: 480x640 1 Bus, 1 Dress, 1 Swim cap, 1 Wheel, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00a56327032571c8 - 1...\n",
      "Processing 00a56327032571c8 - 2...\n",
      "Processing 00a56327032571c8 - 3...\n",
      "Processing 00a56327032571c8 - 4...\n",
      "Processing ./img/resize\\00a67e1bf0dfab98.jpg...\n",
      "\n",
      "0: 480x640 1 Bird, 1 Fashion accessory, 1 Plant, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00a67e1bf0dfab98 - 1...\n",
      "Processing 00a67e1bf0dfab98 - 2...\n",
      "Processing 00a67e1bf0dfab98 - 3...\n",
      "Processing ./img/resize\\00a6adac40bdde86.jpg...\n",
      "\n",
      "0: 480x640 2 Flags, 3 Persons, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00a6adac40bdde86 - 1...\n",
      "Processing 00a6adac40bdde86 - 2...\n",
      "Processing 00a6adac40bdde86 - 3...\n",
      "Processing 00a6adac40bdde86 - 4...\n",
      "Processing 00a6adac40bdde86 - 5...\n",
      "Processing ./img/resize\\00a6d94243311ea6.jpg...\n",
      "\n",
      "0: 480x640 1 Computer mouse, 1 Picture frame, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00a6d94243311ea6 - 1...\n",
      "Processing 00a6d94243311ea6 - 2...\n",
      "Processing ./img/resize\\00a6e5e32dc5727d.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00a76d31926655c3.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00a76d31926655c3 - 1...\n",
      "Processing ./img/resize\\00a7bac3448128bc.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00a7df3e8b095d83.jpg...\n",
      "\n",
      "0: 480x640 4 Airplanes, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00a7df3e8b095d83 - 1...\n",
      "Processing 00a7df3e8b095d83 - 2...\n",
      "Processing 00a7df3e8b095d83 - 3...\n",
      "Processing 00a7df3e8b095d83 - 4...\n",
      "Processing ./img/resize\\00a7e2a62beb50e3.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00a866e732901fc7.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00a866e732901fc7 - 1...\n",
      "Processing 00a866e732901fc7 - 2...\n",
      "Processing ./img/resize\\00a8b82f9944ae6c.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00a921a5c2810640.jpg...\n",
      "\n",
      "0: 480x640 1 Flag, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00a921a5c2810640 - 1...\n",
      "Processing ./img/resize\\00a97dfa6d5998ca.jpg...\n",
      "\n",
      "0: 480x640 1 Tower, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00a97dfa6d5998ca - 1...\n",
      "Processing ./img/resize\\00a9b7f6ed5fb2e5.jpg...\n",
      "\n",
      "0: 480x640 1 Flag, 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00a9b7f6ed5fb2e5 - 1...\n",
      "Processing 00a9b7f6ed5fb2e5 - 2...\n",
      "Processing 00a9b7f6ed5fb2e5 - 3...\n",
      "Processing ./img/resize\\00a9e93b14c796e7.jpg...\n",
      "\n",
      "0: 480x640 2 Coffee tables, 3 Egg (Food)s, 1 Goggles, 1 Sun hat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00a9e93b14c796e7 - 1...\n",
      "Processing 00a9e93b14c796e7 - 2...\n",
      "Processing 00a9e93b14c796e7 - 3...\n",
      "Processing 00a9e93b14c796e7 - 4...\n",
      "Processing 00a9e93b14c796e7 - 5...\n",
      "Processing 00a9e93b14c796e7 - 6...\n",
      "Processing 00a9e93b14c796e7 - 7...\n",
      "Processing ./img/resize\\00aa5aad38a4d5b8.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle, 3 Mans, 1 Woman, 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00aa5aad38a4d5b8 - 1...\n",
      "Processing 00aa5aad38a4d5b8 - 2...\n",
      "Processing 00aa5aad38a4d5b8 - 3...\n",
      "Processing 00aa5aad38a4d5b8 - 4...\n",
      "Processing 00aa5aad38a4d5b8 - 5...\n",
      "Processing ./img/resize\\00aa85aa816f3acb.jpg...\n",
      "\n",
      "0: 480x640 3 Birds, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00aa85aa816f3acb - 1...\n",
      "Processing 00aa85aa816f3acb - 2...\n",
      "Processing 00aa85aa816f3acb - 3...\n",
      "Processing ./img/resize\\00ab13a1d5af511f.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00ab54fd19bfc646.jpg...\n",
      "\n",
      "0: 480x640 1 Mobile phone, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00ab54fd19bfc646 - 1...\n",
      "Processing ./img/resize\\00ac34597051c09f.jpg...\n",
      "\n",
      "0: 480x640 4 Motorcycles, 1 Rose, 4 Tires, 4 Wheels, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "13\n",
      "Processing 00ac34597051c09f - 1...\n",
      "Processing 00ac34597051c09f - 2...\n",
      "Processing 00ac34597051c09f - 3...\n",
      "Processing 00ac34597051c09f - 4...\n",
      "Processing 00ac34597051c09f - 5...\n",
      "Processing 00ac34597051c09f - 6...\n",
      "Processing 00ac34597051c09f - 7...\n",
      "Processing 00ac34597051c09f - 8...\n",
      "Processing 00ac34597051c09f - 9...\n",
      "Processing 00ac34597051c09f - 10...\n",
      "Processing 00ac34597051c09f - 11...\n",
      "Processing 00ac34597051c09f - 12...\n",
      "Processing 00ac34597051c09f - 13...\n",
      "Processing ./img/resize\\00ac549c3ab01bc1.jpg...\n",
      "\n",
      "0: 480x640 2 Egg (Food)s, 1 Footwear, 1 Lamp, 1 Shirt, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00ac549c3ab01bc1 - 1...\n",
      "Processing 00ac549c3ab01bc1 - 2...\n",
      "Processing 00ac549c3ab01bc1 - 3...\n",
      "Processing 00ac549c3ab01bc1 - 4...\n",
      "Processing 00ac549c3ab01bc1 - 5...\n",
      "Processing ./img/resize\\00acb7cd141284d4.jpg...\n",
      "\n",
      "0: 480x640 1 Bowl, 6 Boys, 1 Coat, 2 Coffee tables, 2 Egg (Food)s, 4 Goggless, 1 Grapefruit, 2 Human faces, 1 Human hair, 4 Sun hats, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "24\n",
      "Processing 00acb7cd141284d4 - 1...\n",
      "Processing 00acb7cd141284d4 - 2...\n",
      "Processing 00acb7cd141284d4 - 3...\n",
      "Processing 00acb7cd141284d4 - 4...\n",
      "Processing 00acb7cd141284d4 - 5...\n",
      "Processing 00acb7cd141284d4 - 6...\n",
      "Processing 00acb7cd141284d4 - 7...\n",
      "Processing 00acb7cd141284d4 - 8...\n",
      "Processing 00acb7cd141284d4 - 9...\n",
      "Processing 00acb7cd141284d4 - 10...\n",
      "Processing 00acb7cd141284d4 - 11...\n",
      "Processing 00acb7cd141284d4 - 12...\n",
      "Processing 00acb7cd141284d4 - 13...\n",
      "Processing 00acb7cd141284d4 - 14...\n",
      "Processing 00acb7cd141284d4 - 15...\n",
      "Processing 00acb7cd141284d4 - 16...\n",
      "Processing 00acb7cd141284d4 - 17...\n",
      "Processing 00acb7cd141284d4 - 18...\n",
      "Processing 00acb7cd141284d4 - 19...\n",
      "Processing 00acb7cd141284d4 - 20...\n",
      "Processing 00acb7cd141284d4 - 21...\n",
      "Processing 00acb7cd141284d4 - 22...\n",
      "Processing 00acb7cd141284d4 - 23...\n",
      "Processing 00acb7cd141284d4 - 24...\n",
      "Processing ./img/resize\\00acd4d12ebf4a17.jpg...\n",
      "\n",
      "0: 480x640 1 Fish, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00acd4d12ebf4a17 - 1...\n",
      "Processing ./img/resize\\00ad212b692ad8e3.jpg...\n",
      "\n",
      "0: 480x640 1 Butterfly, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00ad212b692ad8e3 - 1...\n",
      "Processing ./img/resize\\00ae0954f429073b.jpg...\n",
      "\n",
      "0: 480x640 2 Beehives, 1 Box, 2 Butterflys, 1 Panda, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00ae0954f429073b - 1...\n",
      "Processing 00ae0954f429073b - 2...\n",
      "Processing 00ae0954f429073b - 3...\n",
      "Processing 00ae0954f429073b - 4...\n",
      "Processing 00ae0954f429073b - 5...\n",
      "Processing 00ae0954f429073b - 6...\n",
      "Processing ./img/resize\\00ae16f9f9da14c0.jpg...\n",
      "\n",
      "0: 480x640 2 Birds, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00ae16f9f9da14c0 - 1...\n",
      "Processing 00ae16f9f9da14c0 - 2...\n",
      "Processing ./img/resize\\00ae233b3c41000a.jpg...\n",
      "\n",
      "0: 480x640 1 Bird, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00ae233b3c41000a - 1...\n",
      "Processing ./img/resize\\00ae2c4cc2cd45af.jpg...\n",
      "\n",
      "0: 480x640 1 Apple, 3 Boys, 1 Chest of drawers, 2 Coffee cups, 6 Coffee tables, 1 Desk, 4 Goggless, 1 Human body, 1 Human face, 1 Human foot, 3 Mans, 1 Muffin, 2 Persons, 6 Shirts, 4 Suits, 1 Sun hat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "38\n",
      "Processing 00ae2c4cc2cd45af - 1...\n",
      "Processing 00ae2c4cc2cd45af - 2...\n",
      "Processing 00ae2c4cc2cd45af - 3...\n",
      "Processing 00ae2c4cc2cd45af - 4...\n",
      "Processing 00ae2c4cc2cd45af - 5...\n",
      "Processing 00ae2c4cc2cd45af - 6...\n",
      "Processing 00ae2c4cc2cd45af - 7...\n",
      "Processing 00ae2c4cc2cd45af - 8...\n",
      "Processing 00ae2c4cc2cd45af - 9...\n",
      "Processing 00ae2c4cc2cd45af - 10...\n",
      "Processing 00ae2c4cc2cd45af - 11...\n",
      "Processing 00ae2c4cc2cd45af - 12...\n",
      "Processing 00ae2c4cc2cd45af - 13...\n",
      "Processing 00ae2c4cc2cd45af - 14...\n",
      "Processing 00ae2c4cc2cd45af - 15...\n",
      "Processing 00ae2c4cc2cd45af - 16...\n",
      "Processing 00ae2c4cc2cd45af - 17...\n",
      "Processing 00ae2c4cc2cd45af - 18...\n",
      "Processing 00ae2c4cc2cd45af - 19...\n",
      "Processing 00ae2c4cc2cd45af - 20...\n",
      "Processing 00ae2c4cc2cd45af - 21...\n",
      "Processing 00ae2c4cc2cd45af - 22...\n",
      "Processing 00ae2c4cc2cd45af - 23...\n",
      "Processing 00ae2c4cc2cd45af - 24...\n",
      "Processing 00ae2c4cc2cd45af - 25...\n",
      "Processing 00ae2c4cc2cd45af - 26...\n",
      "Processing 00ae2c4cc2cd45af - 27...\n",
      "Processing 00ae2c4cc2cd45af - 28...\n",
      "Processing 00ae2c4cc2cd45af - 29...\n",
      "Processing 00ae2c4cc2cd45af - 30...\n",
      "Processing 00ae2c4cc2cd45af - 31...\n",
      "Processing 00ae2c4cc2cd45af - 32...\n",
      "Processing 00ae2c4cc2cd45af - 33...\n",
      "Processing 00ae2c4cc2cd45af - 34...\n",
      "Processing 00ae2c4cc2cd45af - 35...\n",
      "Processing 00ae2c4cc2cd45af - 36...\n",
      "Processing 00ae2c4cc2cd45af - 37...\n",
      "Processing 00ae2c4cc2cd45af - 38...\n",
      "Processing ./img/resize\\00ae6284ecdf24f7.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle, 4 Bicycle wheels, 1 Human body, 1 Man, 2 Wheels, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 00ae6284ecdf24f7 - 1...\n",
      "Processing 00ae6284ecdf24f7 - 2...\n",
      "Processing 00ae6284ecdf24f7 - 3...\n",
      "Processing 00ae6284ecdf24f7 - 4...\n",
      "Processing 00ae6284ecdf24f7 - 5...\n",
      "Processing 00ae6284ecdf24f7 - 6...\n",
      "Processing 00ae6284ecdf24f7 - 7...\n",
      "Processing 00ae6284ecdf24f7 - 8...\n",
      "Processing 00ae6284ecdf24f7 - 9...\n",
      "Processing ./img/resize\\00aeaa933017a871.jpg...\n",
      "\n",
      "0: 480x640 1 Camera, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00aeaa933017a871 - 1...\n",
      "Processing ./img/resize\\00aeb2446c9ff884.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Human face, 1 Man, 1 Table, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00aeb2446c9ff884 - 1...\n",
      "Processing 00aeb2446c9ff884 - 2...\n",
      "Processing 00aeb2446c9ff884 - 3...\n",
      "Processing 00aeb2446c9ff884 - 4...\n",
      "Processing ./img/resize\\00aed4b4d03198da.jpg...\n",
      "\n",
      "0: 480x640 1 Skyscraper, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00aed4b4d03198da - 1...\n",
      "Processing ./img/resize\\00af1b599518dd24.jpg...\n",
      "\n",
      "0: 480x640 1 Accordion, 2 Ants, 1 Armadillo, 5 Bees, 1 Bench, 1 Cabinetry, 3 Common sunflowers, 2 Cupboards, 1 Deer, 2 Girls, 2 Goggless, 1 Gondola, 1 High heels, 1 Human body, 2 Human faces, 1 Human foot, 1 Jacket, 1 Studio couch, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "30\n",
      "Processing 00af1b599518dd24 - 1...\n",
      "Processing 00af1b599518dd24 - 2...\n",
      "Processing 00af1b599518dd24 - 3...\n",
      "Processing 00af1b599518dd24 - 4...\n",
      "Processing 00af1b599518dd24 - 5...\n",
      "Processing 00af1b599518dd24 - 6...\n",
      "Processing 00af1b599518dd24 - 7...\n",
      "Processing 00af1b599518dd24 - 8...\n",
      "Processing 00af1b599518dd24 - 9...\n",
      "Processing 00af1b599518dd24 - 10...\n",
      "Processing 00af1b599518dd24 - 11...\n",
      "Processing 00af1b599518dd24 - 12...\n",
      "Processing 00af1b599518dd24 - 13...\n",
      "Processing 00af1b599518dd24 - 14...\n",
      "Processing 00af1b599518dd24 - 15...\n",
      "Processing 00af1b599518dd24 - 16...\n",
      "Processing 00af1b599518dd24 - 17...\n",
      "Processing 00af1b599518dd24 - 18...\n",
      "Processing 00af1b599518dd24 - 19...\n",
      "Processing 00af1b599518dd24 - 20...\n",
      "Processing 00af1b599518dd24 - 21...\n",
      "Processing 00af1b599518dd24 - 22...\n",
      "Processing 00af1b599518dd24 - 23...\n",
      "Processing 00af1b599518dd24 - 24...\n",
      "Processing 00af1b599518dd24 - 25...\n",
      "Processing 00af1b599518dd24 - 26...\n",
      "Processing 00af1b599518dd24 - 27...\n",
      "Processing 00af1b599518dd24 - 28...\n",
      "Processing 00af1b599518dd24 - 29...\n",
      "Processing 00af1b599518dd24 - 30...\n",
      "Processing ./img/resize\\00afe7db4069f05d.jpg...\n",
      "\n",
      "0: 480x640 1 House, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00afe7db4069f05d - 1...\n",
      "Processing ./img/resize\\00b0367dc1d8facb.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00b0652631eecf59.jpg...\n",
      "\n",
      "0: 480x640 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00b0652631eecf59 - 1...\n",
      "Processing ./img/resize\\00b08dc0f33f9744.jpg...\n",
      "\n",
      "0: 480x640 1 Bowl, 4 Boys, 1 Chest of drawers, 3 Coffee tables, 4 Common sunflowers, 2 Computer monitors, 3 Egg (Food)s, 7 Goggless, 5 Human heads, 3 Sun hats, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "33\n",
      "Processing 00b08dc0f33f9744 - 1...\n",
      "Processing 00b08dc0f33f9744 - 2...\n",
      "Processing 00b08dc0f33f9744 - 3...\n",
      "Processing 00b08dc0f33f9744 - 4...\n",
      "Processing 00b08dc0f33f9744 - 5...\n",
      "Processing 00b08dc0f33f9744 - 6...\n",
      "Processing 00b08dc0f33f9744 - 7...\n",
      "Processing 00b08dc0f33f9744 - 8...\n",
      "Processing 00b08dc0f33f9744 - 9...\n",
      "Processing 00b08dc0f33f9744 - 10...\n",
      "Processing 00b08dc0f33f9744 - 11...\n",
      "Processing 00b08dc0f33f9744 - 12...\n",
      "Processing 00b08dc0f33f9744 - 13...\n",
      "Processing 00b08dc0f33f9744 - 14...\n",
      "Processing 00b08dc0f33f9744 - 15...\n",
      "Processing 00b08dc0f33f9744 - 16...\n",
      "Processing 00b08dc0f33f9744 - 17...\n",
      "Processing 00b08dc0f33f9744 - 18...\n",
      "Processing 00b08dc0f33f9744 - 19...\n",
      "Processing 00b08dc0f33f9744 - 20...\n",
      "Processing 00b08dc0f33f9744 - 21...\n",
      "Processing 00b08dc0f33f9744 - 22...\n",
      "Processing 00b08dc0f33f9744 - 23...\n",
      "Processing 00b08dc0f33f9744 - 24...\n",
      "Processing 00b08dc0f33f9744 - 25...\n",
      "Processing 00b08dc0f33f9744 - 26...\n",
      "Processing 00b08dc0f33f9744 - 27...\n",
      "Processing 00b08dc0f33f9744 - 28...\n",
      "Processing 00b08dc0f33f9744 - 29...\n",
      "Processing 00b08dc0f33f9744 - 30...\n",
      "Processing 00b08dc0f33f9744 - 31...\n",
      "Processing 00b08dc0f33f9744 - 32...\n",
      "Processing 00b08dc0f33f9744 - 33...\n",
      "Processing ./img/resize\\00b0b3d8c34f028b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00b0d38974082ef8.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00b0d38974082ef8 - 1...\n",
      "Processing 00b0d38974082ef8 - 2...\n",
      "Processing ./img/resize\\00b12b3ae64eac18.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00b160ef31b17c4d.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00b160ef31b17c4d - 1...\n",
      "Processing 00b160ef31b17c4d - 2...\n",
      "Processing ./img/resize\\00b1612c02849203.jpg...\n",
      "\n",
      "0: 480x640 3 Bicycle wheels, 1 Butterfly, 1 Clothing, 1 Human body, 1 Mammal, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00b1612c02849203 - 1...\n",
      "Processing 00b1612c02849203 - 2...\n",
      "Processing 00b1612c02849203 - 3...\n",
      "Processing 00b1612c02849203 - 4...\n",
      "Processing 00b1612c02849203 - 5...\n",
      "Processing 00b1612c02849203 - 6...\n",
      "Processing 00b1612c02849203 - 7...\n",
      "Processing 00b1612c02849203 - 8...\n",
      "Processing ./img/resize\\00b18f8e129814cd.jpg...\n",
      "\n",
      "0: 480x640 1 Egg (Food), 3 Goggless, 1 Human face, 1 Human leg, 1 Laptop, 5 Sun hats, 1 Umbrella, 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "13\n",
      "Processing 00b18f8e129814cd - 1...\n",
      "Processing 00b18f8e129814cd - 2...\n",
      "Processing 00b18f8e129814cd - 3...\n",
      "Processing 00b18f8e129814cd - 4...\n",
      "Processing 00b18f8e129814cd - 5...\n",
      "Processing 00b18f8e129814cd - 6...\n",
      "Processing 00b18f8e129814cd - 7...\n",
      "Processing 00b18f8e129814cd - 8...\n",
      "Processing 00b18f8e129814cd - 9...\n",
      "Processing 00b18f8e129814cd - 10...\n",
      "Processing 00b18f8e129814cd - 11...\n",
      "Processing 00b18f8e129814cd - 12...\n",
      "Processing 00b18f8e129814cd - 13...\n",
      "Processing ./img/resize\\00b1f4cb7f0d5b39.jpg...\n",
      "\n",
      "0: 480x640 1 Human arm, 1 Human head, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00b1f4cb7f0d5b39 - 1...\n",
      "Processing 00b1f4cb7f0d5b39 - 2...\n",
      "Processing ./img/resize\\00b268860e5d6ae6.jpg...\n",
      "\n",
      "0: 480x640 3 Coffee tables, 3 Egg (Food)s, 2 Footwears, 1 Girl, 1 Goggles, 1 Human head, 1 Lighthouse, 1 Shorts, 4 Sun hats, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "17\n",
      "Processing 00b268860e5d6ae6 - 1...\n",
      "Processing 00b268860e5d6ae6 - 2...\n",
      "Processing 00b268860e5d6ae6 - 3...\n",
      "Processing 00b268860e5d6ae6 - 4...\n",
      "Processing 00b268860e5d6ae6 - 5...\n",
      "Processing 00b268860e5d6ae6 - 6...\n",
      "Processing 00b268860e5d6ae6 - 7...\n",
      "Processing 00b268860e5d6ae6 - 8...\n",
      "Processing 00b268860e5d6ae6 - 9...\n",
      "Processing 00b268860e5d6ae6 - 10...\n",
      "Processing 00b268860e5d6ae6 - 11...\n",
      "Processing 00b268860e5d6ae6 - 12...\n",
      "Processing 00b268860e5d6ae6 - 13...\n",
      "Processing 00b268860e5d6ae6 - 14...\n",
      "Processing 00b268860e5d6ae6 - 15...\n",
      "Processing 00b268860e5d6ae6 - 16...\n",
      "Processing 00b268860e5d6ae6 - 17...\n",
      "Processing ./img/resize\\00b28be1f086ec8d.jpg...\n",
      "\n",
      "0: 480x640 1 Christmas tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00b28be1f086ec8d - 1...\n",
      "Processing ./img/resize\\00b2b51a2afd9196.jpg...\n",
      "\n",
      "0: 480x640 1 Poster, 2 Wine glasss, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00b2b51a2afd9196 - 1...\n",
      "Processing 00b2b51a2afd9196 - 2...\n",
      "Processing 00b2b51a2afd9196 - 3...\n",
      "Processing ./img/resize\\00b2c6274c78aba4.jpg...\n",
      "\n",
      "0: 480x640 1 Coin, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00b2c6274c78aba4 - 1...\n",
      "Processing ./img/resize\\00b3ac6d8f6f5a2c.jpg...\n",
      "\n",
      "0: 480x640 5 Jeanss, 3 Mans, 4 Womans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "12\n",
      "Processing 00b3ac6d8f6f5a2c - 1...\n",
      "Processing 00b3ac6d8f6f5a2c - 2...\n",
      "Processing 00b3ac6d8f6f5a2c - 3...\n",
      "Processing 00b3ac6d8f6f5a2c - 4...\n",
      "Processing 00b3ac6d8f6f5a2c - 5...\n",
      "Processing 00b3ac6d8f6f5a2c - 6...\n",
      "Processing 00b3ac6d8f6f5a2c - 7...\n",
      "Processing 00b3ac6d8f6f5a2c - 8...\n",
      "Processing 00b3ac6d8f6f5a2c - 9...\n",
      "Processing 00b3ac6d8f6f5a2c - 10...\n",
      "Processing 00b3ac6d8f6f5a2c - 11...\n",
      "Processing 00b3ac6d8f6f5a2c - 12...\n",
      "Processing ./img/resize\\00b3ff14a0437422.jpg...\n",
      "\n",
      "0: 480x640 2 Boys, 2 Egg (Food)s, 4 Goggless, 1 Human head, 2 Sun hats, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 00b3ff14a0437422 - 1...\n",
      "Processing 00b3ff14a0437422 - 2...\n",
      "Processing 00b3ff14a0437422 - 3...\n",
      "Processing 00b3ff14a0437422 - 4...\n",
      "Processing 00b3ff14a0437422 - 5...\n",
      "Processing 00b3ff14a0437422 - 6...\n",
      "Processing 00b3ff14a0437422 - 7...\n",
      "Processing 00b3ff14a0437422 - 8...\n",
      "Processing 00b3ff14a0437422 - 9...\n",
      "Processing 00b3ff14a0437422 - 10...\n",
      "Processing 00b3ff14a0437422 - 11...\n",
      "Processing ./img/resize\\00b40029c9e849c8.jpg...\n",
      "\n",
      "0: 480x640 1 Footwear, 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00b40029c9e849c8 - 1...\n",
      "Processing 00b40029c9e849c8 - 2...\n",
      "Processing ./img/resize\\00b4092092d8102c.jpg...\n",
      "\n",
      "0: 480x640 1 Coffee table, 1 Human body, 2 Human faces, 2 Mans, 1 Person, 1 Suit, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00b4092092d8102c - 1...\n",
      "Processing 00b4092092d8102c - 2...\n",
      "Processing 00b4092092d8102c - 3...\n",
      "Processing 00b4092092d8102c - 4...\n",
      "Processing 00b4092092d8102c - 5...\n",
      "Processing 00b4092092d8102c - 6...\n",
      "Processing 00b4092092d8102c - 7...\n",
      "Processing 00b4092092d8102c - 8...\n",
      "Processing ./img/resize\\00b4292129e922d9.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00b44cac03c7ff35.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Man, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00b44cac03c7ff35 - 1...\n",
      "Processing 00b44cac03c7ff35 - 2...\n",
      "Processing ./img/resize\\00b48e4d07cc0ac5.jpg...\n",
      "\n",
      "0: 480x640 1 House, 3 Windows, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00b48e4d07cc0ac5 - 1...\n",
      "Processing 00b48e4d07cc0ac5 - 2...\n",
      "Processing 00b48e4d07cc0ac5 - 3...\n",
      "Processing 00b48e4d07cc0ac5 - 4...\n",
      "Processing ./img/resize\\00b4ac624689b33a.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00b4d07f7be89f98.jpg...\n",
      "\n",
      "0: 480x640 1 Auto part, 4 Cars, 1 Goggles, 1 Shrimp, 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00b4d07f7be89f98 - 1...\n",
      "Processing 00b4d07f7be89f98 - 2...\n",
      "Processing 00b4d07f7be89f98 - 3...\n",
      "Processing 00b4d07f7be89f98 - 4...\n",
      "Processing 00b4d07f7be89f98 - 5...\n",
      "Processing 00b4d07f7be89f98 - 6...\n",
      "Processing 00b4d07f7be89f98 - 7...\n",
      "Processing 00b4d07f7be89f98 - 8...\n",
      "Processing ./img/resize\\00b4ed87e6bed513.jpg...\n",
      "\n",
      "0: 480x640 2 Cats, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00b4ed87e6bed513 - 1...\n",
      "Processing 00b4ed87e6bed513 - 2...\n",
      "Processing ./img/resize\\00b5194962c6cc10.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00b522cbc320cc85.jpg...\n",
      "\n",
      "0: 480x640 2 Persons, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00b522cbc320cc85 - 1...\n",
      "Processing 00b522cbc320cc85 - 2...\n",
      "Processing ./img/resize\\00b5d41148a57d85.jpg...\n",
      "\n",
      "0: 480x640 1 Butterfly, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00b5d41148a57d85 - 1...\n",
      "Processing ./img/resize\\00b637d7c76b4e4a.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00b665b8942db075.jpg...\n",
      "\n",
      "0: 480x640 2 Houseplants, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00b665b8942db075 - 1...\n",
      "Processing 00b665b8942db075 - 2...\n",
      "Processing ./img/resize\\00b6782d3137dfb0.jpg...\n",
      "\n",
      "0: 480x640 1 Insect, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00b6782d3137dfb0 - 1...\n",
      "Processing ./img/resize\\00b67d020fdf2391.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00b67d020fdf2391 - 1...\n",
      "Processing 00b67d020fdf2391 - 2...\n",
      "Processing ./img/resize\\00b691b302a0a8c4.jpg...\n",
      "\n",
      "0: 480x640 3 Houses, 4 Trees, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00b691b302a0a8c4 - 1...\n",
      "Processing 00b691b302a0a8c4 - 2...\n",
      "Processing 00b691b302a0a8c4 - 3...\n",
      "Processing 00b691b302a0a8c4 - 4...\n",
      "Processing 00b691b302a0a8c4 - 5...\n",
      "Processing 00b691b302a0a8c4 - 6...\n",
      "Processing 00b691b302a0a8c4 - 7...\n",
      "Processing ./img/resize\\00b696cd4ee81807.jpg...\n",
      "\n",
      "0: 480x640 2 Suits, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00b696cd4ee81807 - 1...\n",
      "Processing 00b696cd4ee81807 - 2...\n",
      "Processing ./img/resize\\00b6c4eb7aae9ace.jpg...\n",
      "\n",
      "0: 480x640 1 Ice cream, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00b6c4eb7aae9ace - 1...\n",
      "Processing ./img/resize\\00b6e195e04ba79f.jpg...\n",
      "\n",
      "0: 480x640 1 Insect, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00b6e195e04ba79f - 1...\n",
      "Processing ./img/resize\\00b77b267c23807a.jpg...\n",
      "\n",
      "0: 480x640 2 Fishs, 1 Seafood, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00b77b267c23807a - 1...\n",
      "Processing 00b77b267c23807a - 2...\n",
      "Processing 00b77b267c23807a - 3...\n",
      "Processing ./img/resize\\00b8c7642d98fedf.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Human ear, 2 Sun hats, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00b8c7642d98fedf - 1...\n",
      "Processing 00b8c7642d98fedf - 2...\n",
      "Processing 00b8c7642d98fedf - 3...\n",
      "Processing 00b8c7642d98fedf - 4...\n",
      "Processing ./img/resize\\00b8e380ff7301b5.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00b92fe674de375d.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 4 Human faces, 2 Mans, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00b92fe674de375d - 1...\n",
      "Processing 00b92fe674de375d - 2...\n",
      "Processing 00b92fe674de375d - 3...\n",
      "Processing 00b92fe674de375d - 4...\n",
      "Processing 00b92fe674de375d - 5...\n",
      "Processing 00b92fe674de375d - 6...\n",
      "Processing 00b92fe674de375d - 7...\n",
      "Processing 00b92fe674de375d - 8...\n",
      "Processing ./img/resize\\00b93492b4e71619.jpg...\n",
      "\n",
      "0: 480x640 3 Castles, 1 Food, 3 Goggless, 1 Helmet, 1 Human nose, 1 Lighthouse, 1 Suit, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 00b93492b4e71619 - 1...\n",
      "Processing 00b93492b4e71619 - 2...\n",
      "Processing 00b93492b4e71619 - 3...\n",
      "Processing 00b93492b4e71619 - 4...\n",
      "Processing 00b93492b4e71619 - 5...\n",
      "Processing 00b93492b4e71619 - 6...\n",
      "Processing 00b93492b4e71619 - 7...\n",
      "Processing 00b93492b4e71619 - 8...\n",
      "Processing 00b93492b4e71619 - 9...\n",
      "Processing 00b93492b4e71619 - 10...\n",
      "Processing 00b93492b4e71619 - 11...\n",
      "Processing ./img/resize\\00b957ae0fdef50e.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00b957ae0fdef50e - 1...\n",
      "Processing ./img/resize\\00b96f1b8caa3e6d.jpg...\n",
      "\n",
      "0: 480x640 2 Footwears, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00b96f1b8caa3e6d - 1...\n",
      "Processing 00b96f1b8caa3e6d - 2...\n",
      "Processing ./img/resize\\00b9ace2e1b06adf.jpg...\n",
      "\n",
      "0: 480x640 1 Coffee table, 1 French fries, 1 Shirt, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00b9ace2e1b06adf - 1...\n",
      "Processing 00b9ace2e1b06adf - 2...\n",
      "Processing 00b9ace2e1b06adf - 3...\n",
      "Processing ./img/resize\\00b9d2d3796638c5.jpg...\n",
      "\n",
      "0: 480x640 1 Bird, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00b9d2d3796638c5 - 1...\n",
      "Processing ./img/resize\\00b9e528eb0c9b21.jpg...\n",
      "\n",
      "0: 480x640 1 Chair, 1 Television, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00b9e528eb0c9b21 - 1...\n",
      "Processing 00b9e528eb0c9b21 - 2...\n",
      "Processing ./img/resize\\00ba37bc770a7929.jpg...\n",
      "\n",
      "0: 480x640 2 Airplanes, 1 Ant, 1 Apple, 2 Bicycle helmets, 1 Boy, 3 Cars, 3 Castles, 1 Coat, 1 Common sunflower, 1 Computer monitor, 2 Egg (Food)s, 12 Goggless, 1 Helmet, 1 Human body, 1 Human hair, 1 Human hand, 1 Human head, 2 Human noses, 1 Jacket, 1 Lamp, 2 Lighthouses, 1 Mammal, 2 Snacks, 2 Suits, 2 Sun hats, 1 Toy, 1 Truck, 1 Wheel, 1 Woman, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "52\n",
      "Processing 00ba37bc770a7929 - 1...\n",
      "Processing 00ba37bc770a7929 - 2...\n",
      "Processing 00ba37bc770a7929 - 3...\n",
      "Processing 00ba37bc770a7929 - 4...\n",
      "Processing 00ba37bc770a7929 - 5...\n",
      "Processing 00ba37bc770a7929 - 6...\n",
      "Processing 00ba37bc770a7929 - 7...\n",
      "Processing 00ba37bc770a7929 - 8...\n",
      "Processing 00ba37bc770a7929 - 9...\n",
      "Processing 00ba37bc770a7929 - 10...\n",
      "Processing 00ba37bc770a7929 - 11...\n",
      "Processing 00ba37bc770a7929 - 12...\n",
      "Processing 00ba37bc770a7929 - 13...\n",
      "Processing 00ba37bc770a7929 - 14...\n",
      "Processing 00ba37bc770a7929 - 15...\n",
      "Processing 00ba37bc770a7929 - 16...\n",
      "Processing 00ba37bc770a7929 - 17...\n",
      "Processing 00ba37bc770a7929 - 18...\n",
      "Processing 00ba37bc770a7929 - 19...\n",
      "Processing 00ba37bc770a7929 - 20...\n",
      "Processing 00ba37bc770a7929 - 21...\n",
      "Processing 00ba37bc770a7929 - 22...\n",
      "Processing 00ba37bc770a7929 - 23...\n",
      "Processing 00ba37bc770a7929 - 24...\n",
      "Processing 00ba37bc770a7929 - 25...\n",
      "Processing 00ba37bc770a7929 - 26...\n",
      "Processing 00ba37bc770a7929 - 27...\n",
      "Processing 00ba37bc770a7929 - 28...\n",
      "Processing 00ba37bc770a7929 - 29...\n",
      "Processing 00ba37bc770a7929 - 30...\n",
      "Processing 00ba37bc770a7929 - 31...\n",
      "Processing 00ba37bc770a7929 - 32...\n",
      "Processing 00ba37bc770a7929 - 33...\n",
      "Processing 00ba37bc770a7929 - 34...\n",
      "Processing 00ba37bc770a7929 - 35...\n",
      "Processing 00ba37bc770a7929 - 36...\n",
      "Processing 00ba37bc770a7929 - 37...\n",
      "Processing 00ba37bc770a7929 - 38...\n",
      "Processing 00ba37bc770a7929 - 39...\n",
      "Processing 00ba37bc770a7929 - 40...\n",
      "Processing 00ba37bc770a7929 - 41...\n",
      "Processing 00ba37bc770a7929 - 42...\n",
      "Processing 00ba37bc770a7929 - 43...\n",
      "Processing 00ba37bc770a7929 - 44...\n",
      "Processing 00ba37bc770a7929 - 45...\n",
      "Processing 00ba37bc770a7929 - 46...\n",
      "Processing 00ba37bc770a7929 - 47...\n",
      "Processing 00ba37bc770a7929 - 48...\n",
      "Processing 00ba37bc770a7929 - 49...\n",
      "Processing 00ba37bc770a7929 - 50...\n",
      "Processing 00ba37bc770a7929 - 51...\n",
      "Processing 00ba37bc770a7929 - 52...\n",
      "Processing ./img/resize\\00ba3c9c8a062e4b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00ba4c2dbb00d580.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00ba4c2dbb00d580 - 1...\n",
      "Processing 00ba4c2dbb00d580 - 2...\n",
      "Processing 00ba4c2dbb00d580 - 3...\n",
      "Processing ./img/resize\\00ba4f8b91d01af2.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Man, 1 Mobile phone, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00ba4f8b91d01af2 - 1...\n",
      "Processing 00ba4f8b91d01af2 - 2...\n",
      "Processing 00ba4f8b91d01af2 - 3...\n",
      "Processing ./img/resize\\00bb0c471b36fe5a.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 1 Suit, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00bb0c471b36fe5a - 1...\n",
      "Processing 00bb0c471b36fe5a - 2...\n",
      "Processing 00bb0c471b36fe5a - 3...\n",
      "Processing ./img/resize\\00bb54d0686bcc72.jpg...\n",
      "\n",
      "0: 480x640 2 Clothings, 1 Human face, 1 Poster, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00bb54d0686bcc72 - 1...\n",
      "Processing 00bb54d0686bcc72 - 2...\n",
      "Processing 00bb54d0686bcc72 - 3...\n",
      "Processing 00bb54d0686bcc72 - 4...\n",
      "Processing ./img/resize\\00bb5df772f8a96c.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00bb5df772f8a96c - 1...\n",
      "Processing ./img/resize\\00bbc92e06d3d740.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00bc2165c842afd0.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00bc2165c842afd0 - 1...\n",
      "Processing ./img/resize\\00bc79d0a1f48390.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00bc79d0a1f48390 - 1...\n",
      "Processing ./img/resize\\00bca2ef1d89097c.jpg...\n",
      "\n",
      "0: 480x640 1 Footwear, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00bca2ef1d89097c - 1...\n",
      "Processing ./img/resize\\00bd1cc86c91093c.jpg...\n",
      "\n",
      "0: 480x640 1 Tent, 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00bd1cc86c91093c - 1...\n",
      "Processing 00bd1cc86c91093c - 2...\n",
      "Processing ./img/resize\\00bd3f67d6e5d850.jpg...\n",
      "\n",
      "0: 480x640 1 Dog, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00bd3f67d6e5d850 - 1...\n",
      "Processing ./img/resize\\00bda305647be8f5.jpg...\n",
      "\n",
      "0: 480x640 3 Balls, 2 Coffee tables, 1 Egg (Food), 1 Human face, 1 Human head, 3 Sun hats, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 00bda305647be8f5 - 1...\n",
      "Processing 00bda305647be8f5 - 2...\n",
      "Processing 00bda305647be8f5 - 3...\n",
      "Processing 00bda305647be8f5 - 4...\n",
      "Processing 00bda305647be8f5 - 5...\n",
      "Processing 00bda305647be8f5 - 6...\n",
      "Processing 00bda305647be8f5 - 7...\n",
      "Processing 00bda305647be8f5 - 8...\n",
      "Processing 00bda305647be8f5 - 9...\n",
      "Processing 00bda305647be8f5 - 10...\n",
      "Processing 00bda305647be8f5 - 11...\n",
      "Processing ./img/resize\\00bda713b019bf0b.jpg...\n",
      "\n",
      "0: 480x640 1 Fashion accessory, 2 Tires, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00bda713b019bf0b - 1...\n",
      "Processing 00bda713b019bf0b - 2...\n",
      "Processing 00bda713b019bf0b - 3...\n",
      "Processing ./img/resize\\00bdb3b075af0fe5.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00bdb3b075af0fe5 - 1...\n",
      "Processing ./img/resize\\00bdc1cd6453b416.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00bdc1cd6453b416 - 1...\n",
      "Processing ./img/resize\\00bde63b398f14a8.jpg...\n",
      "\n",
      "0: 480x640 1 Girl, 2 Human faces, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00bde63b398f14a8 - 1...\n",
      "Processing 00bde63b398f14a8 - 2...\n",
      "Processing 00bde63b398f14a8 - 3...\n",
      "Processing ./img/resize\\00be32b15dc16f18.jpg...\n",
      "\n",
      "0: 480x640 3 Mans, 2 Womans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00be32b15dc16f18 - 1...\n",
      "Processing 00be32b15dc16f18 - 2...\n",
      "Processing 00be32b15dc16f18 - 3...\n",
      "Processing 00be32b15dc16f18 - 4...\n",
      "Processing 00be32b15dc16f18 - 5...\n",
      "Processing ./img/resize\\00be435f1f010bcc.jpg...\n",
      "\n",
      "0: 480x640 1 Bus, 1 Car, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00be435f1f010bcc - 1...\n",
      "Processing 00be435f1f010bcc - 2...\n",
      "Processing ./img/resize\\00be5d837ceac97a.jpg...\n",
      "\n",
      "0: 480x640 1 Cat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00be5d837ceac97a - 1...\n",
      "Processing ./img/resize\\00be7f82bd787bb1.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 2 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00be7f82bd787bb1 - 1...\n",
      "Processing 00be7f82bd787bb1 - 2...\n",
      "Processing 00be7f82bd787bb1 - 3...\n",
      "Processing 00be7f82bd787bb1 - 4...\n",
      "Processing ./img/resize\\00bf163d72db82ff.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00bf55c53dda6815.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00bf88689ae98f54.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 2 Houses, 5 Windows, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 00bf88689ae98f54 - 1...\n",
      "Processing 00bf88689ae98f54 - 2...\n",
      "Processing 00bf88689ae98f54 - 3...\n",
      "Processing 00bf88689ae98f54 - 4...\n",
      "Processing 00bf88689ae98f54 - 5...\n",
      "Processing 00bf88689ae98f54 - 6...\n",
      "Processing 00bf88689ae98f54 - 7...\n",
      "Processing 00bf88689ae98f54 - 8...\n",
      "Processing 00bf88689ae98f54 - 9...\n",
      "Processing ./img/resize\\00bf953bf7ac8085.jpg...\n",
      "\n",
      "0: 480x640 1 Bus, 1 Car, 4 Coffee tables, 3 Egg (Food)s, 3 Sun hats, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "12\n",
      "Processing 00bf953bf7ac8085 - 1...\n",
      "Processing 00bf953bf7ac8085 - 2...\n",
      "Processing 00bf953bf7ac8085 - 3...\n",
      "Processing 00bf953bf7ac8085 - 4...\n",
      "Processing 00bf953bf7ac8085 - 5...\n",
      "Processing 00bf953bf7ac8085 - 6...\n",
      "Processing 00bf953bf7ac8085 - 7...\n",
      "Processing 00bf953bf7ac8085 - 8...\n",
      "Processing 00bf953bf7ac8085 - 9...\n",
      "Processing 00bf953bf7ac8085 - 10...\n",
      "Processing 00bf953bf7ac8085 - 11...\n",
      "Processing 00bf953bf7ac8085 - 12...\n",
      "Processing ./img/resize\\00bfcd25320fd354.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle, 1 Door, 1 Wheel, 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00bfcd25320fd354 - 1...\n",
      "Processing 00bfcd25320fd354 - 2...\n",
      "Processing 00bfcd25320fd354 - 3...\n",
      "Processing ./img/resize\\00bfefa51a93b61f.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00bfefa51a93b61f - 1...\n",
      "Processing ./img/resize\\00c083bb8bfe1f58.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00c0e36d053bc134.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00c166304ba7c42e.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00c1769ea7ef6b27.jpg...\n",
      "\n",
      "0: 480x640 1 Bench, 1 Tree, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00c1769ea7ef6b27 - 1...\n",
      "Processing 00c1769ea7ef6b27 - 2...\n",
      "Processing ./img/resize\\00c1914cc38fbe38.jpg...\n",
      "\n",
      "0: 480x640 3 Bowls, 9 Coffee tables, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "12\n",
      "Processing 00c1914cc38fbe38 - 1...\n",
      "Processing 00c1914cc38fbe38 - 2...\n",
      "Processing 00c1914cc38fbe38 - 3...\n",
      "Processing 00c1914cc38fbe38 - 4...\n",
      "Processing 00c1914cc38fbe38 - 5...\n",
      "Processing 00c1914cc38fbe38 - 6...\n",
      "Processing 00c1914cc38fbe38 - 7...\n",
      "Processing 00c1914cc38fbe38 - 8...\n",
      "Processing 00c1914cc38fbe38 - 9...\n",
      "Processing 00c1914cc38fbe38 - 10...\n",
      "Processing 00c1914cc38fbe38 - 11...\n",
      "Processing 00c1914cc38fbe38 - 12...\n",
      "Processing ./img/resize\\00c1c3d1030f63dc.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00c1c3d1030f63dc - 1...\n",
      "Processing ./img/resize\\00c1fe3576df1b60.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00c264246b5c4df5.jpg...\n",
      "\n",
      "0: 480x640 1 Tin can, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00c264246b5c4df5 - 1...\n",
      "Processing ./img/resize\\00c2e9aa89385b0a.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00c302c0cdd9e23a.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00c3fc7ae2e35a57.jpg...\n",
      "\n",
      "0: 480x640 2 Clothings, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00c3fc7ae2e35a57 - 1...\n",
      "Processing 00c3fc7ae2e35a57 - 2...\n",
      "Processing ./img/resize\\00c470f36a16514e.jpg...\n",
      "\n",
      "0: 480x640 1 Bed, 1 Curtain, 1 Sun hat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00c470f36a16514e - 1...\n",
      "Processing 00c470f36a16514e - 2...\n",
      "Processing 00c470f36a16514e - 3...\n",
      "Processing ./img/resize\\00c4a61ab56fed54.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Cart, 3 Coffee tables, 2 Egg (Food)s, 4 Sun hats, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 00c4a61ab56fed54 - 1...\n",
      "Processing 00c4a61ab56fed54 - 2...\n",
      "Processing 00c4a61ab56fed54 - 3...\n",
      "Processing 00c4a61ab56fed54 - 4...\n",
      "Processing 00c4a61ab56fed54 - 5...\n",
      "Processing 00c4a61ab56fed54 - 6...\n",
      "Processing 00c4a61ab56fed54 - 7...\n",
      "Processing 00c4a61ab56fed54 - 8...\n",
      "Processing 00c4a61ab56fed54 - 9...\n",
      "Processing 00c4a61ab56fed54 - 10...\n",
      "Processing 00c4a61ab56fed54 - 11...\n",
      "Processing ./img/resize\\00c4fcb31c46a90b.jpg...\n",
      "\n",
      "0: 480x640 1 Beetle, 3 Insects, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00c4fcb31c46a90b - 1...\n",
      "Processing 00c4fcb31c46a90b - 2...\n",
      "Processing 00c4fcb31c46a90b - 3...\n",
      "Processing 00c4fcb31c46a90b - 4...\n",
      "Processing ./img/resize\\00c5064463923fb6.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00c51c36cbefc426.jpg...\n",
      "\n",
      "0: 480x640 2 Apples, 2 Balls, 1 Bench, 1 Bicycle helmet, 3 Bicycle wheels, 5 Bowls, 3 Boys, 1 Brassiere, 2 Chairs, 1 Coat, 4 Coffee tables, 1 Coin, 1 Computer monitor, 14 Goggless, 2 Grapefruits, 1 Human arm, 1 Human body, 3 Human faces, 1 Human foot, 1 Human hair, 6 Human heads, 1 Jeans, 2 Mammals, 5 Mans, 1 Saucer, 2 Shirts, 1 Skirt, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "68\n",
      "Processing 00c51c36cbefc426 - 1...\n",
      "Processing 00c51c36cbefc426 - 2...\n",
      "Processing 00c51c36cbefc426 - 3...\n",
      "Processing 00c51c36cbefc426 - 4...\n",
      "Processing 00c51c36cbefc426 - 5...\n",
      "Processing 00c51c36cbefc426 - 6...\n",
      "Processing 00c51c36cbefc426 - 7...\n",
      "Processing 00c51c36cbefc426 - 8...\n",
      "Processing 00c51c36cbefc426 - 9...\n",
      "Processing 00c51c36cbefc426 - 10...\n",
      "Processing 00c51c36cbefc426 - 11...\n",
      "Processing 00c51c36cbefc426 - 12...\n",
      "Processing 00c51c36cbefc426 - 13...\n",
      "Processing 00c51c36cbefc426 - 14...\n",
      "Processing 00c51c36cbefc426 - 15...\n",
      "Processing 00c51c36cbefc426 - 16...\n",
      "Processing 00c51c36cbefc426 - 17...\n",
      "Processing 00c51c36cbefc426 - 18...\n",
      "Processing 00c51c36cbefc426 - 19...\n",
      "Processing 00c51c36cbefc426 - 20...\n",
      "Processing 00c51c36cbefc426 - 21...\n",
      "Processing 00c51c36cbefc426 - 22...\n",
      "Processing 00c51c36cbefc426 - 23...\n",
      "Processing 00c51c36cbefc426 - 24...\n",
      "Processing 00c51c36cbefc426 - 25...\n",
      "Processing 00c51c36cbefc426 - 26...\n",
      "Processing 00c51c36cbefc426 - 27...\n",
      "Processing 00c51c36cbefc426 - 28...\n",
      "Processing 00c51c36cbefc426 - 29...\n",
      "Processing 00c51c36cbefc426 - 30...\n",
      "Processing 00c51c36cbefc426 - 31...\n",
      "Processing 00c51c36cbefc426 - 32...\n",
      "Processing 00c51c36cbefc426 - 33...\n",
      "Processing 00c51c36cbefc426 - 34...\n",
      "Processing 00c51c36cbefc426 - 35...\n",
      "Processing 00c51c36cbefc426 - 36...\n",
      "Processing 00c51c36cbefc426 - 37...\n",
      "Processing 00c51c36cbefc426 - 38...\n",
      "Processing 00c51c36cbefc426 - 39...\n",
      "Processing 00c51c36cbefc426 - 40...\n",
      "Processing 00c51c36cbefc426 - 41...\n",
      "Processing 00c51c36cbefc426 - 42...\n",
      "Processing 00c51c36cbefc426 - 43...\n",
      "Processing 00c51c36cbefc426 - 44...\n",
      "Processing 00c51c36cbefc426 - 45...\n",
      "Processing 00c51c36cbefc426 - 46...\n",
      "Processing 00c51c36cbefc426 - 47...\n",
      "Processing 00c51c36cbefc426 - 48...\n",
      "Processing 00c51c36cbefc426 - 49...\n",
      "Processing 00c51c36cbefc426 - 50...\n",
      "Processing 00c51c36cbefc426 - 51...\n",
      "Processing 00c51c36cbefc426 - 52...\n",
      "Processing 00c51c36cbefc426 - 53...\n",
      "Processing 00c51c36cbefc426 - 54...\n",
      "Processing 00c51c36cbefc426 - 55...\n",
      "Processing 00c51c36cbefc426 - 56...\n",
      "Processing 00c51c36cbefc426 - 57...\n",
      "Processing 00c51c36cbefc426 - 58...\n",
      "Processing 00c51c36cbefc426 - 59...\n",
      "Processing 00c51c36cbefc426 - 60...\n",
      "Processing 00c51c36cbefc426 - 61...\n",
      "Processing 00c51c36cbefc426 - 62...\n",
      "Processing 00c51c36cbefc426 - 63...\n",
      "Processing 00c51c36cbefc426 - 64...\n",
      "Processing 00c51c36cbefc426 - 65...\n",
      "Processing 00c51c36cbefc426 - 66...\n",
      "Processing 00c51c36cbefc426 - 67...\n",
      "Processing 00c51c36cbefc426 - 68...\n",
      "Processing ./img/resize\\00c571ae426b402f.jpg...\n",
      "\n",
      "0: 480x640 1 Computer monitor, 1 Laptop, 1 Office building, 1 Person, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00c571ae426b402f - 1...\n",
      "Processing 00c571ae426b402f - 2...\n",
      "Processing 00c571ae426b402f - 3...\n",
      "Processing 00c571ae426b402f - 4...\n",
      "Processing ./img/resize\\00c58ccb55dd91a1.jpg...\n",
      "\n",
      "0: 480x640 1 Ball, 1 Bicycle wheel, 1 Bottle, 2 Boys, 1 Butterfly, 2 Coats, 2 Dresss, 2 Egg (Food)s, 2 Human bodys, 1 Human head, 2 Miniskirts, 1 Motorcycle, 4 Persons, 1 Sports uniform, 1 Sun hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "24\n",
      "Processing 00c58ccb55dd91a1 - 1...\n",
      "Processing 00c58ccb55dd91a1 - 2...\n",
      "Processing 00c58ccb55dd91a1 - 3...\n",
      "Processing 00c58ccb55dd91a1 - 4...\n",
      "Processing 00c58ccb55dd91a1 - 5...\n",
      "Processing 00c58ccb55dd91a1 - 6...\n",
      "Processing 00c58ccb55dd91a1 - 7...\n",
      "Processing 00c58ccb55dd91a1 - 8...\n",
      "Processing 00c58ccb55dd91a1 - 9...\n",
      "Processing 00c58ccb55dd91a1 - 10...\n",
      "Processing 00c58ccb55dd91a1 - 11...\n",
      "Processing 00c58ccb55dd91a1 - 12...\n",
      "Processing 00c58ccb55dd91a1 - 13...\n",
      "Processing 00c58ccb55dd91a1 - 14...\n",
      "Processing 00c58ccb55dd91a1 - 15...\n",
      "Processing 00c58ccb55dd91a1 - 16...\n",
      "Processing 00c58ccb55dd91a1 - 17...\n",
      "Processing 00c58ccb55dd91a1 - 18...\n",
      "Processing 00c58ccb55dd91a1 - 19...\n",
      "Processing 00c58ccb55dd91a1 - 20...\n",
      "Processing 00c58ccb55dd91a1 - 21...\n",
      "Processing 00c58ccb55dd91a1 - 22...\n",
      "Processing 00c58ccb55dd91a1 - 23...\n",
      "Processing 00c58ccb55dd91a1 - 24...\n",
      "Processing ./img/resize\\00c5d5b00769dc7d.jpg...\n",
      "\n",
      "0: 480x640 4 Apples, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00c5d5b00769dc7d - 1...\n",
      "Processing 00c5d5b00769dc7d - 2...\n",
      "Processing 00c5d5b00769dc7d - 3...\n",
      "Processing 00c5d5b00769dc7d - 4...\n",
      "Processing ./img/resize\\00c5e8339eb88fe8.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 2 Human faces, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00c5e8339eb88fe8 - 1...\n",
      "Processing 00c5e8339eb88fe8 - 2...\n",
      "Processing 00c5e8339eb88fe8 - 3...\n",
      "Processing ./img/resize\\00c5eaa5e060b31e.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 36.0ms\n",
      "Speed: 2.0ms preprocess, 36.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00c5eaa5e060b31e - 1...\n",
      "Processing ./img/resize\\00c66f3c6207f706.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle wheel, 1 Cat, 1 Flowerpot, 1 Houseplant, 1 Human body, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00c66f3c6207f706 - 1...\n",
      "Processing 00c66f3c6207f706 - 2...\n",
      "Processing 00c66f3c6207f706 - 3...\n",
      "Processing 00c66f3c6207f706 - 4...\n",
      "Processing 00c66f3c6207f706 - 5...\n",
      "Processing ./img/resize\\00c6f79c49d2733f.jpg...\n",
      "\n",
      "0: 480x640 1 House, 3 Windows, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00c6f79c49d2733f - 1...\n",
      "Processing 00c6f79c49d2733f - 2...\n",
      "Processing 00c6f79c49d2733f - 3...\n",
      "Processing 00c6f79c49d2733f - 4...\n",
      "Processing ./img/resize\\00c71c14162ff0ff.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00c71c14162ff0ff - 1...\n",
      "Processing 00c71c14162ff0ff - 2...\n",
      "Processing ./img/resize\\00c74e0f11d24f66.jpg...\n",
      "\n",
      "0: 480x640 2 Motorcycles, 5 Tires, 5 Wheels, 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "12\n",
      "Processing 00c74e0f11d24f66 - 1...\n",
      "Processing 00c74e0f11d24f66 - 2...\n",
      "Processing 00c74e0f11d24f66 - 3...\n",
      "Processing 00c74e0f11d24f66 - 4...\n",
      "Processing 00c74e0f11d24f66 - 5...\n",
      "Processing 00c74e0f11d24f66 - 6...\n",
      "Processing 00c74e0f11d24f66 - 7...\n",
      "Processing 00c74e0f11d24f66 - 8...\n",
      "Processing 00c74e0f11d24f66 - 9...\n",
      "Processing 00c74e0f11d24f66 - 10...\n",
      "Processing 00c74e0f11d24f66 - 11...\n",
      "Processing 00c74e0f11d24f66 - 12...\n",
      "Processing ./img/resize\\00c7502bc2a77300.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00c79041873d5156.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00c8082e31e2f0e8.jpg...\n",
      "\n",
      "0: 480x640 1 Dog, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00c8082e31e2f0e8 - 1...\n",
      "Processing ./img/resize\\00c82d509c6203b1.jpg...\n",
      "\n",
      "0: 480x640 2 Football helmets, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00c82d509c6203b1 - 1...\n",
      "Processing 00c82d509c6203b1 - 2...\n",
      "Processing ./img/resize\\00c861b91a81039a.jpg...\n",
      "\n",
      "0: 480x640 1 Backpack, 2 Beetles, 2 Bicycle wheels, 1 Boot, 1 Coat, 4 Human bodys, 2 Mammals, 2 Traffic signs, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "15\n",
      "Processing 00c861b91a81039a - 1...\n",
      "Processing 00c861b91a81039a - 2...\n",
      "Processing 00c861b91a81039a - 3...\n",
      "Processing 00c861b91a81039a - 4...\n",
      "Processing 00c861b91a81039a - 5...\n",
      "Processing 00c861b91a81039a - 6...\n",
      "Processing 00c861b91a81039a - 7...\n",
      "Processing 00c861b91a81039a - 8...\n",
      "Processing 00c861b91a81039a - 9...\n",
      "Processing 00c861b91a81039a - 10...\n",
      "Processing 00c861b91a81039a - 11...\n",
      "Processing 00c861b91a81039a - 12...\n",
      "Processing 00c861b91a81039a - 13...\n",
      "Processing 00c861b91a81039a - 14...\n",
      "Processing 00c861b91a81039a - 15...\n",
      "Processing ./img/resize\\00c895c9413e4576.jpg...\n",
      "\n",
      "0: 480x640 3 Jeanss, 5 Mans, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00c895c9413e4576 - 1...\n",
      "Processing 00c895c9413e4576 - 2...\n",
      "Processing 00c895c9413e4576 - 3...\n",
      "Processing 00c895c9413e4576 - 4...\n",
      "Processing 00c895c9413e4576 - 5...\n",
      "Processing 00c895c9413e4576 - 6...\n",
      "Processing 00c895c9413e4576 - 7...\n",
      "Processing 00c895c9413e4576 - 8...\n",
      "Processing ./img/resize\\00c8d36882dd6d37.jpg...\n",
      "\n",
      "0: 480x640 1 Deer, 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00c8d36882dd6d37 - 1...\n",
      "Processing 00c8d36882dd6d37 - 2...\n",
      "Processing ./img/resize\\00c8ecf06fd78a81.jpg...\n",
      "\n",
      "0: 480x640 3 Footwears, 2 Girls, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00c8ecf06fd78a81 - 1...\n",
      "Processing 00c8ecf06fd78a81 - 2...\n",
      "Processing 00c8ecf06fd78a81 - 3...\n",
      "Processing 00c8ecf06fd78a81 - 4...\n",
      "Processing 00c8ecf06fd78a81 - 5...\n",
      "Processing ./img/resize\\00c96fe5a710db26.jpg...\n",
      "\n",
      "0: 480x640 1 Common sunflower, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00c96fe5a710db26 - 1...\n",
      "Processing ./img/resize\\00c99f06b295849c.jpg...\n",
      "\n",
      "0: 480x640 5 Boys, 1 Coffee table, 6 Egg (Food)s, 3 Goggless, 1 Grapefruit, 1 Human face, 2 Human heads, 2 Sun hats, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "21\n",
      "Processing 00c99f06b295849c - 1...\n",
      "Processing 00c99f06b295849c - 2...\n",
      "Processing 00c99f06b295849c - 3...\n",
      "Processing 00c99f06b295849c - 4...\n",
      "Processing 00c99f06b295849c - 5...\n",
      "Processing 00c99f06b295849c - 6...\n",
      "Processing 00c99f06b295849c - 7...\n",
      "Processing 00c99f06b295849c - 8...\n",
      "Processing 00c99f06b295849c - 9...\n",
      "Processing 00c99f06b295849c - 10...\n",
      "Processing 00c99f06b295849c - 11...\n",
      "Processing 00c99f06b295849c - 12...\n",
      "Processing 00c99f06b295849c - 13...\n",
      "Processing 00c99f06b295849c - 14...\n",
      "Processing 00c99f06b295849c - 15...\n",
      "Processing 00c99f06b295849c - 16...\n",
      "Processing 00c99f06b295849c - 17...\n",
      "Processing 00c99f06b295849c - 18...\n",
      "Processing 00c99f06b295849c - 19...\n",
      "Processing 00c99f06b295849c - 20...\n",
      "Processing 00c99f06b295849c - 21...\n",
      "Processing ./img/resize\\00c9aa59305317be.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Picture frame, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00c9aa59305317be - 1...\n",
      "Processing 00c9aa59305317be - 2...\n",
      "Processing 00c9aa59305317be - 3...\n",
      "Processing ./img/resize\\00c9dbb79339a83e.jpg...\n",
      "\n",
      "0: 480x640 6 Toys, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00c9dbb79339a83e - 1...\n",
      "Processing 00c9dbb79339a83e - 2...\n",
      "Processing 00c9dbb79339a83e - 3...\n",
      "Processing 00c9dbb79339a83e - 4...\n",
      "Processing 00c9dbb79339a83e - 5...\n",
      "Processing 00c9dbb79339a83e - 6...\n",
      "Processing ./img/resize\\00c9ebcfe494e31b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00ca5cf44a3b5a07.jpg...\n",
      "\n",
      "0: 480x640 1 Toy, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00ca5cf44a3b5a07 - 1...\n",
      "Processing ./img/resize\\00cb26a8fd68981d.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Man, 1 Suit, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00cb26a8fd68981d - 1...\n",
      "Processing 00cb26a8fd68981d - 2...\n",
      "Processing 00cb26a8fd68981d - 3...\n",
      "Processing ./img/resize\\00cc018b8dec06bc.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00cc018b8dec06bc - 1...\n",
      "Processing ./img/resize\\00cc0b94078e0282.jpg...\n",
      "\n",
      "0: 480x640 12 Computer mouses, 1 Fashion accessory, 3 Human faces, 2 Mans, 1 Mirror, 1 Suitcase, 2 Televisions, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "22\n",
      "Processing 00cc0b94078e0282 - 1...\n",
      "Processing 00cc0b94078e0282 - 2...\n",
      "Processing 00cc0b94078e0282 - 3...\n",
      "Processing 00cc0b94078e0282 - 4...\n",
      "Processing 00cc0b94078e0282 - 5...\n",
      "Processing 00cc0b94078e0282 - 6...\n",
      "Processing 00cc0b94078e0282 - 7...\n",
      "Processing 00cc0b94078e0282 - 8...\n",
      "Processing 00cc0b94078e0282 - 9...\n",
      "Processing 00cc0b94078e0282 - 10...\n",
      "Processing 00cc0b94078e0282 - 11...\n",
      "Processing 00cc0b94078e0282 - 12...\n",
      "Processing 00cc0b94078e0282 - 13...\n",
      "Processing 00cc0b94078e0282 - 14...\n",
      "Processing 00cc0b94078e0282 - 15...\n",
      "Processing 00cc0b94078e0282 - 16...\n",
      "Processing 00cc0b94078e0282 - 17...\n",
      "Processing 00cc0b94078e0282 - 18...\n",
      "Processing 00cc0b94078e0282 - 19...\n",
      "Processing 00cc0b94078e0282 - 20...\n",
      "Processing 00cc0b94078e0282 - 21...\n",
      "Processing 00cc0b94078e0282 - 22...\n",
      "Processing ./img/resize\\00cc2f51c797adc4.jpg...\n",
      "\n",
      "0: 480x640 1 Fashion accessory, 2 Human hands, 2 Jeanss, 1 Van, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00cc2f51c797adc4 - 1...\n",
      "Processing 00cc2f51c797adc4 - 2...\n",
      "Processing 00cc2f51c797adc4 - 3...\n",
      "Processing 00cc2f51c797adc4 - 4...\n",
      "Processing 00cc2f51c797adc4 - 5...\n",
      "Processing 00cc2f51c797adc4 - 6...\n",
      "Processing ./img/resize\\00cc5a10776a591a.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 0.9ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00ccafc53669b851.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 2 Mans, 2 Womans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00ccafc53669b851 - 1...\n",
      "Processing 00ccafc53669b851 - 2...\n",
      "Processing 00ccafc53669b851 - 3...\n",
      "Processing 00ccafc53669b851 - 4...\n",
      "Processing 00ccafc53669b851 - 5...\n",
      "Processing ./img/resize\\00cd32b9db30c834.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00cd3e2a6425b2b8.jpg...\n",
      "\n",
      "0: 480x640 1 Egg (Food), 2 Human heads, 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00cd3e2a6425b2b8 - 1...\n",
      "Processing 00cd3e2a6425b2b8 - 2...\n",
      "Processing 00cd3e2a6425b2b8 - 3...\n",
      "Processing ./img/resize\\00cd66ab36a4bd25.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00cd66ab36a4bd25 - 1...\n",
      "Processing 00cd66ab36a4bd25 - 2...\n",
      "Processing ./img/resize\\00cd866870478844.jpg...\n",
      "\n",
      "0: 480x640 2 Dresss, 2 Mans, 1 Suit, 2 Womans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00cd866870478844 - 1...\n",
      "Processing 00cd866870478844 - 2...\n",
      "Processing 00cd866870478844 - 3...\n",
      "Processing 00cd866870478844 - 4...\n",
      "Processing 00cd866870478844 - 5...\n",
      "Processing 00cd866870478844 - 6...\n",
      "Processing 00cd866870478844 - 7...\n",
      "Processing ./img/resize\\00cd9c0e8e267180.jpg...\n",
      "\n",
      "0: 480x640 1 Baked goods, 1 Bee, 1 Book, 2 Christmas trees, 1 Coffee table, 1 Cosmetics, 1 Countertop, 1 Fashion accessory, 1 Food, 5 Goggless, 1 Human face, 1 Human foot, 1 Human hair, 1 Human head, 1 Porch, 1 Roller skates, 2 Sun hats, 3 Windows, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "26\n",
      "Processing 00cd9c0e8e267180 - 1...\n",
      "Processing 00cd9c0e8e267180 - 2...\n",
      "Processing 00cd9c0e8e267180 - 3...\n",
      "Processing 00cd9c0e8e267180 - 4...\n",
      "Processing 00cd9c0e8e267180 - 5...\n",
      "Processing 00cd9c0e8e267180 - 6...\n",
      "Processing 00cd9c0e8e267180 - 7...\n",
      "Processing 00cd9c0e8e267180 - 8...\n",
      "Processing 00cd9c0e8e267180 - 9...\n",
      "Processing 00cd9c0e8e267180 - 10...\n",
      "Processing 00cd9c0e8e267180 - 11...\n",
      "Processing 00cd9c0e8e267180 - 12...\n",
      "Processing 00cd9c0e8e267180 - 13...\n",
      "Processing 00cd9c0e8e267180 - 14...\n",
      "Processing 00cd9c0e8e267180 - 15...\n",
      "Processing 00cd9c0e8e267180 - 16...\n",
      "Processing 00cd9c0e8e267180 - 17...\n",
      "Processing 00cd9c0e8e267180 - 18...\n",
      "Processing 00cd9c0e8e267180 - 19...\n",
      "Processing 00cd9c0e8e267180 - 20...\n",
      "Processing 00cd9c0e8e267180 - 21...\n",
      "Processing 00cd9c0e8e267180 - 22...\n",
      "Processing 00cd9c0e8e267180 - 23...\n",
      "Processing 00cd9c0e8e267180 - 24...\n",
      "Processing 00cd9c0e8e267180 - 25...\n",
      "Processing 00cd9c0e8e267180 - 26...\n",
      "Processing ./img/resize\\00ce854ef2483ee5.jpg...\n",
      "\n",
      "0: 480x640 1 Baked goods, 11 Bananas, 3 Boys, 1 Cheese, 4 Coffee tables, 1 Common sunflower, 1 Computer monitor, 2 Egg (Food)s, 2 Fast foods, 4 French friess, 3 Goggless, 3 Grapefruits, 3 Lilys, 1 Sun hat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "40\n",
      "Processing 00ce854ef2483ee5 - 1...\n",
      "Processing 00ce854ef2483ee5 - 2...\n",
      "Processing 00ce854ef2483ee5 - 3...\n",
      "Processing 00ce854ef2483ee5 - 4...\n",
      "Processing 00ce854ef2483ee5 - 5...\n",
      "Processing 00ce854ef2483ee5 - 6...\n",
      "Processing 00ce854ef2483ee5 - 7...\n",
      "Processing 00ce854ef2483ee5 - 8...\n",
      "Processing 00ce854ef2483ee5 - 9...\n",
      "Processing 00ce854ef2483ee5 - 10...\n",
      "Processing 00ce854ef2483ee5 - 11...\n",
      "Processing 00ce854ef2483ee5 - 12...\n",
      "Processing 00ce854ef2483ee5 - 13...\n",
      "Processing 00ce854ef2483ee5 - 14...\n",
      "Processing 00ce854ef2483ee5 - 15...\n",
      "Processing 00ce854ef2483ee5 - 16...\n",
      "Processing 00ce854ef2483ee5 - 17...\n",
      "Processing 00ce854ef2483ee5 - 18...\n",
      "Processing 00ce854ef2483ee5 - 19...\n",
      "Processing 00ce854ef2483ee5 - 20...\n",
      "Processing 00ce854ef2483ee5 - 21...\n",
      "Processing 00ce854ef2483ee5 - 22...\n",
      "Processing 00ce854ef2483ee5 - 23...\n",
      "Processing 00ce854ef2483ee5 - 24...\n",
      "Processing 00ce854ef2483ee5 - 25...\n",
      "Processing 00ce854ef2483ee5 - 26...\n",
      "Processing 00ce854ef2483ee5 - 27...\n",
      "Processing 00ce854ef2483ee5 - 28...\n",
      "Processing 00ce854ef2483ee5 - 29...\n",
      "Processing 00ce854ef2483ee5 - 30...\n",
      "Processing 00ce854ef2483ee5 - 31...\n",
      "Processing 00ce854ef2483ee5 - 32...\n",
      "Processing 00ce854ef2483ee5 - 33...\n",
      "Processing 00ce854ef2483ee5 - 34...\n",
      "Processing 00ce854ef2483ee5 - 35...\n",
      "Processing 00ce854ef2483ee5 - 36...\n",
      "Processing 00ce854ef2483ee5 - 37...\n",
      "Processing 00ce854ef2483ee5 - 38...\n",
      "Processing 00ce854ef2483ee5 - 39...\n",
      "Processing 00ce854ef2483ee5 - 40...\n",
      "Processing ./img/resize\\00cfaf8ab7d08a61.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00cfaf8ab7d08a61 - 1...\n",
      "Processing ./img/resize\\00cfefdb5ca8a0f7.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00d05698b5796b01.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00d0d0e50ec07300.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Human head, 1 Sun hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00d0d0e50ec07300 - 1...\n",
      "Processing 00d0d0e50ec07300 - 2...\n",
      "Processing 00d0d0e50ec07300 - 3...\n",
      "Processing ./img/resize\\00d10b1211b59e90.jpg...\n",
      "\n",
      "0: 480x640 1 Bowl, 1 Boy, 1 Coffee table, 1 Egg (Food), 6 Goggless, 1 Human hair, 2 Human heads, 1 Man, 1 Shirt, 1 Sunglasses, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "16\n",
      "Processing 00d10b1211b59e90 - 1...\n",
      "Processing 00d10b1211b59e90 - 2...\n",
      "Processing 00d10b1211b59e90 - 3...\n",
      "Processing 00d10b1211b59e90 - 4...\n",
      "Processing 00d10b1211b59e90 - 5...\n",
      "Processing 00d10b1211b59e90 - 6...\n",
      "Processing 00d10b1211b59e90 - 7...\n",
      "Processing 00d10b1211b59e90 - 8...\n",
      "Processing 00d10b1211b59e90 - 9...\n",
      "Processing 00d10b1211b59e90 - 10...\n",
      "Processing 00d10b1211b59e90 - 11...\n",
      "Processing 00d10b1211b59e90 - 12...\n",
      "Processing 00d10b1211b59e90 - 13...\n",
      "Processing 00d10b1211b59e90 - 14...\n",
      "Processing 00d10b1211b59e90 - 15...\n",
      "Processing 00d10b1211b59e90 - 16...\n",
      "Processing ./img/resize\\00d1204d0dc20811.jpg...\n",
      "\n",
      "0: 480x640 4 Helicopters, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00d1204d0dc20811 - 1...\n",
      "Processing 00d1204d0dc20811 - 2...\n",
      "Processing 00d1204d0dc20811 - 3...\n",
      "Processing 00d1204d0dc20811 - 4...\n",
      "Processing ./img/resize\\00d131863084d7d7.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00d131863084d7d7 - 1...\n",
      "Processing ./img/resize\\00d1968e36d6ce7b.jpg...\n",
      "\n",
      "0: 480x640 2 Flowerpots, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00d1968e36d6ce7b - 1...\n",
      "Processing 00d1968e36d6ce7b - 2...\n",
      "Processing ./img/resize\\00d1fa85689c90a7.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 1 Woman, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00d1fa85689c90a7 - 1...\n",
      "Processing 00d1fa85689c90a7 - 2...\n",
      "Processing ./img/resize\\00d21d6e456019f9.jpg...\n",
      "\n",
      "0: 480x640 1 Goggles, 1 Human face, 1 Sunglasses, 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00d21d6e456019f9 - 1...\n",
      "Processing 00d21d6e456019f9 - 2...\n",
      "Processing 00d21d6e456019f9 - 3...\n",
      "Processing 00d21d6e456019f9 - 4...\n",
      "Processing ./img/resize\\00d2ccd8f8804528.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00d2ccd8f8804528 - 1...\n",
      "Processing 00d2ccd8f8804528 - 2...\n",
      "Processing 00d2ccd8f8804528 - 3...\n",
      "Processing ./img/resize\\00d366b6a4bf4e15.jpg...\n",
      "\n",
      "0: 480x640 1 Bus, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00d366b6a4bf4e15 - 1...\n",
      "Processing ./img/resize\\00d3b262ed8a4992.jpg...\n",
      "\n",
      "0: 480x640 1 Butterfly, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00d3b262ed8a4992 - 1...\n",
      "Processing ./img/resize\\00d449b98c6c9d53.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Sculpture, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00d449b98c6c9d53 - 1...\n",
      "Processing 00d449b98c6c9d53 - 2...\n",
      "Processing ./img/resize\\00d4a2999742bd29.jpg...\n",
      "\n",
      "0: 480x640 1 Airplane, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00d4a2999742bd29 - 1...\n",
      "Processing ./img/resize\\00d4c2070ab2b0e0.jpg...\n",
      "\n",
      "0: 480x640 2 Boys, 1 Coffee table, 1 Egg (Food), 1 Human face, 1 Sun hat, 1 Train, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00d4c2070ab2b0e0 - 1...\n",
      "Processing 00d4c2070ab2b0e0 - 2...\n",
      "Processing 00d4c2070ab2b0e0 - 3...\n",
      "Processing 00d4c2070ab2b0e0 - 4...\n",
      "Processing 00d4c2070ab2b0e0 - 5...\n",
      "Processing 00d4c2070ab2b0e0 - 6...\n",
      "Processing 00d4c2070ab2b0e0 - 7...\n",
      "Processing ./img/resize\\00d4e9985d5e6294.jpg...\n",
      "\n",
      "0: 480x640 2 Boxs, 3 Boys, 3 Cabinetrys, 1 Coffee table, 6 Goggless, 1 Human face, 2 Human heads, 1 Human leg, 1 Human nose, 1 Sun hat, 1 Tree, 2 Trouserss, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "24\n",
      "Processing 00d4e9985d5e6294 - 1...\n",
      "Processing 00d4e9985d5e6294 - 2...\n",
      "Processing 00d4e9985d5e6294 - 3...\n",
      "Processing 00d4e9985d5e6294 - 4...\n",
      "Processing 00d4e9985d5e6294 - 5...\n",
      "Processing 00d4e9985d5e6294 - 6...\n",
      "Processing 00d4e9985d5e6294 - 7...\n",
      "Processing 00d4e9985d5e6294 - 8...\n",
      "Processing 00d4e9985d5e6294 - 9...\n",
      "Processing 00d4e9985d5e6294 - 10...\n",
      "Processing 00d4e9985d5e6294 - 11...\n",
      "Processing 00d4e9985d5e6294 - 12...\n",
      "Processing 00d4e9985d5e6294 - 13...\n",
      "Processing 00d4e9985d5e6294 - 14...\n",
      "Processing 00d4e9985d5e6294 - 15...\n",
      "Processing 00d4e9985d5e6294 - 16...\n",
      "Processing 00d4e9985d5e6294 - 17...\n",
      "Processing 00d4e9985d5e6294 - 18...\n",
      "Processing 00d4e9985d5e6294 - 19...\n",
      "Processing 00d4e9985d5e6294 - 20...\n",
      "Processing 00d4e9985d5e6294 - 21...\n",
      "Processing 00d4e9985d5e6294 - 22...\n",
      "Processing 00d4e9985d5e6294 - 23...\n",
      "Processing 00d4e9985d5e6294 - 24...\n",
      "Processing ./img/resize\\00d5257d3dbebc56.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 6 Human faces, 7 Mans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "14\n",
      "Processing 00d5257d3dbebc56 - 1...\n",
      "Processing 00d5257d3dbebc56 - 2...\n",
      "Processing 00d5257d3dbebc56 - 3...\n",
      "Processing 00d5257d3dbebc56 - 4...\n",
      "Processing 00d5257d3dbebc56 - 5...\n",
      "Processing 00d5257d3dbebc56 - 6...\n",
      "Processing 00d5257d3dbebc56 - 7...\n",
      "Processing 00d5257d3dbebc56 - 8...\n",
      "Processing 00d5257d3dbebc56 - 9...\n",
      "Processing 00d5257d3dbebc56 - 10...\n",
      "Processing 00d5257d3dbebc56 - 11...\n",
      "Processing 00d5257d3dbebc56 - 12...\n",
      "Processing 00d5257d3dbebc56 - 13...\n",
      "Processing 00d5257d3dbebc56 - 14...\n",
      "Processing ./img/resize\\00d5db1a9b4b4638.jpg...\n",
      "\n",
      "0: 480x640 1 Train, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00d5db1a9b4b4638 - 1...\n",
      "Processing ./img/resize\\00d6346cd9a08867.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00d64474d28d3028.jpg...\n",
      "\n",
      "0: 480x640 2 Ants, 1 Bathroom accessory, 3 Castles, 1 Clothing, 1 Fashion accessory, 19 Goggless, 1 Harbor seal, 1 Helmet, 1 Human face, 1 Human head, 2 Human noses, 1 Jacket, 1 Lighthouse, 1 Shower, 2 Suits, 1 Wheel, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "40\n",
      "Processing 00d64474d28d3028 - 1...\n",
      "Processing 00d64474d28d3028 - 2...\n",
      "Processing 00d64474d28d3028 - 3...\n",
      "Processing 00d64474d28d3028 - 4...\n",
      "Processing 00d64474d28d3028 - 5...\n",
      "Processing 00d64474d28d3028 - 6...\n",
      "Processing 00d64474d28d3028 - 7...\n",
      "Processing 00d64474d28d3028 - 8...\n",
      "Processing 00d64474d28d3028 - 9...\n",
      "Processing 00d64474d28d3028 - 10...\n",
      "Processing 00d64474d28d3028 - 11...\n",
      "Processing 00d64474d28d3028 - 12...\n",
      "Processing 00d64474d28d3028 - 13...\n",
      "Processing 00d64474d28d3028 - 14...\n",
      "Processing 00d64474d28d3028 - 15...\n",
      "Processing 00d64474d28d3028 - 16...\n",
      "Processing 00d64474d28d3028 - 17...\n",
      "Processing 00d64474d28d3028 - 18...\n",
      "Processing 00d64474d28d3028 - 19...\n",
      "Processing 00d64474d28d3028 - 20...\n",
      "Processing 00d64474d28d3028 - 21...\n",
      "Processing 00d64474d28d3028 - 22...\n",
      "Processing 00d64474d28d3028 - 23...\n",
      "Processing 00d64474d28d3028 - 24...\n",
      "Processing 00d64474d28d3028 - 25...\n",
      "Processing 00d64474d28d3028 - 26...\n",
      "Processing 00d64474d28d3028 - 27...\n",
      "Processing 00d64474d28d3028 - 28...\n",
      "Processing 00d64474d28d3028 - 29...\n",
      "Processing 00d64474d28d3028 - 30...\n",
      "Processing 00d64474d28d3028 - 31...\n",
      "Processing 00d64474d28d3028 - 32...\n",
      "Processing 00d64474d28d3028 - 33...\n",
      "Processing 00d64474d28d3028 - 34...\n",
      "Processing 00d64474d28d3028 - 35...\n",
      "Processing 00d64474d28d3028 - 36...\n",
      "Processing 00d64474d28d3028 - 37...\n",
      "Processing 00d64474d28d3028 - 38...\n",
      "Processing 00d64474d28d3028 - 39...\n",
      "Processing 00d64474d28d3028 - 40...\n",
      "Processing ./img/resize\\00d6872384ccdc16.jpg...\n",
      "\n",
      "0: 480x640 1 Goggles, 1 Human face, 1 Sun hat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00d6872384ccdc16 - 1...\n",
      "Processing 00d6872384ccdc16 - 2...\n",
      "Processing 00d6872384ccdc16 - 3...\n",
      "Processing ./img/resize\\00d687844745d725.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00d6ab89205aa58b.jpg...\n",
      "\n",
      "0: 480x640 2 Doors, 2 Door handles, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00d6ab89205aa58b - 1...\n",
      "Processing 00d6ab89205aa58b - 2...\n",
      "Processing 00d6ab89205aa58b - 3...\n",
      "Processing 00d6ab89205aa58b - 4...\n",
      "Processing ./img/resize\\00d6c10378c1ea45.jpg...\n",
      "\n",
      "0: 480x640 2 Wheels, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00d6c10378c1ea45 - 1...\n",
      "Processing 00d6c10378c1ea45 - 2...\n",
      "Processing ./img/resize\\00d6cfa114cacf60.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00d6d9e1d4c0fc90.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00d6d9e1d4c0fc90 - 1...\n",
      "Processing ./img/resize\\00d6ec409ec06398.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00d718ac2097a3ac.jpg...\n",
      "\n",
      "0: 480x640 2 Chairs, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00d718ac2097a3ac - 1...\n",
      "Processing 00d718ac2097a3ac - 2...\n",
      "Processing ./img/resize\\00d71a18afab7adb.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00d72484f05d5ad7.jpg...\n",
      "\n",
      "0: 480x640 1 Airplane, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00d72484f05d5ad7 - 1...\n",
      "Processed batch 1\n",
      "Processing ./img/resize\\00d770737ff40eff.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Clothing, 5 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00d770737ff40eff - 1...\n",
      "Processing 00d770737ff40eff - 2...\n",
      "Processing 00d770737ff40eff - 3...\n",
      "Processing 00d770737ff40eff - 4...\n",
      "Processing 00d770737ff40eff - 5...\n",
      "Processing 00d770737ff40eff - 6...\n",
      "Processing 00d770737ff40eff - 7...\n",
      "Processing ./img/resize\\00d7744dd9d36980.jpg...\n",
      "\n",
      "0: 480x640 1 Snack, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00d7744dd9d36980 - 1...\n",
      "Processing ./img/resize\\00d7bcaa88a56d72.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00d7c41c5bc6808f.jpg...\n",
      "\n",
      "0: 480x640 1 Bronze sculpture, 1 Building, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00d7c41c5bc6808f - 1...\n",
      "Processing 00d7c41c5bc6808f - 2...\n",
      "Processing ./img/resize\\00d82bfbaa06854f.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00d84612c4bc9982.jpg...\n",
      "\n",
      "0: 480x640 1 Airplane, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00d84612c4bc9982 - 1...\n",
      "Processing ./img/resize\\00d963a77c6f2193.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 1 Car, 3 Mans, 2 Womans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00d963a77c6f2193 - 1...\n",
      "Processing 00d963a77c6f2193 - 2...\n",
      "Processing 00d963a77c6f2193 - 3...\n",
      "Processing 00d963a77c6f2193 - 4...\n",
      "Processing 00d963a77c6f2193 - 5...\n",
      "Processing 00d963a77c6f2193 - 6...\n",
      "Processing 00d963a77c6f2193 - 7...\n",
      "Processing ./img/resize\\00d96af314a5368f.jpg...\n",
      "\n",
      "0: 480x640 1 Baked goods, 1 Bicycle, 2 Bicycle helmets, 1 Bicycle wheel, 1 Common sunflower, 1 Dress, 4 Goggless, 1 Human hair, 1 Human head, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "13\n",
      "Processing 00d96af314a5368f - 1...\n",
      "Processing 00d96af314a5368f - 2...\n",
      "Processing 00d96af314a5368f - 3...\n",
      "Processing 00d96af314a5368f - 4...\n",
      "Processing 00d96af314a5368f - 5...\n",
      "Processing 00d96af314a5368f - 6...\n",
      "Processing 00d96af314a5368f - 7...\n",
      "Processing 00d96af314a5368f - 8...\n",
      "Processing 00d96af314a5368f - 9...\n",
      "Processing 00d96af314a5368f - 10...\n",
      "Processing 00d96af314a5368f - 11...\n",
      "Processing 00d96af314a5368f - 12...\n",
      "Processing 00d96af314a5368f - 13...\n",
      "Processing ./img/resize\\00d97e1a0d9f938f.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00d9b6fd6b19e6c2.jpg...\n",
      "\n",
      "0: 480x640 1 Flag, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00d9b6fd6b19e6c2 - 1...\n",
      "Processing 00d9b6fd6b19e6c2 - 2...\n",
      "Processing ./img/resize\\00d9bdf9171fc8c6.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00d9bdf9171fc8c6 - 1...\n",
      "Processing 00d9bdf9171fc8c6 - 2...\n",
      "Processing ./img/resize\\00d9d08fc21858c3.jpg...\n",
      "\n",
      "0: 480x640 3 Apples, 1 Boy, 1 Car, 4 Coffee tables, 1 Flag, 2 Goggless, 1 Rose, 8 Scissorss, 1 Sun hat, 1 Wine glass, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "23\n",
      "Processing 00d9d08fc21858c3 - 1...\n",
      "Processing 00d9d08fc21858c3 - 2...\n",
      "Processing 00d9d08fc21858c3 - 3...\n",
      "Processing 00d9d08fc21858c3 - 4...\n",
      "Processing 00d9d08fc21858c3 - 5...\n",
      "Processing 00d9d08fc21858c3 - 6...\n",
      "Processing 00d9d08fc21858c3 - 7...\n",
      "Processing 00d9d08fc21858c3 - 8...\n",
      "Processing 00d9d08fc21858c3 - 9...\n",
      "Processing 00d9d08fc21858c3 - 10...\n",
      "Processing 00d9d08fc21858c3 - 11...\n",
      "Processing 00d9d08fc21858c3 - 12...\n",
      "Processing 00d9d08fc21858c3 - 13...\n",
      "Processing 00d9d08fc21858c3 - 14...\n",
      "Processing 00d9d08fc21858c3 - 15...\n",
      "Processing 00d9d08fc21858c3 - 16...\n",
      "Processing 00d9d08fc21858c3 - 17...\n",
      "Processing 00d9d08fc21858c3 - 18...\n",
      "Processing 00d9d08fc21858c3 - 19...\n",
      "Processing 00d9d08fc21858c3 - 20...\n",
      "Processing 00d9d08fc21858c3 - 21...\n",
      "Processing 00d9d08fc21858c3 - 22...\n",
      "Processing 00d9d08fc21858c3 - 23...\n",
      "Processing ./img/resize\\00d9db3d2c186504.jpg...\n",
      "\n",
      "0: 480x640 1 Bus, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00d9db3d2c186504 - 1...\n",
      "Processing ./img/resize\\00da4daeb67656b8.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 3 Mans, 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00da4daeb67656b8 - 1...\n",
      "Processing 00da4daeb67656b8 - 2...\n",
      "Processing 00da4daeb67656b8 - 3...\n",
      "Processing 00da4daeb67656b8 - 4...\n",
      "Processing 00da4daeb67656b8 - 5...\n",
      "Processing ./img/resize\\00da5768e32f6514.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00da5768e32f6514 - 1...\n",
      "Processing 00da5768e32f6514 - 2...\n",
      "Processing ./img/resize\\00da5f384e8071eb.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle helmet, 1 Hat, 1 Mushroom, 1 Swim cap, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00da5f384e8071eb - 1...\n",
      "Processing 00da5f384e8071eb - 2...\n",
      "Processing 00da5f384e8071eb - 3...\n",
      "Processing 00da5f384e8071eb - 4...\n",
      "Processing ./img/resize\\00da9e6282c52cb3.jpg...\n",
      "\n",
      "0: 480x640 3 Motorcycles, 2 Persons, 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00da9e6282c52cb3 - 1...\n",
      "Processing 00da9e6282c52cb3 - 2...\n",
      "Processing 00da9e6282c52cb3 - 3...\n",
      "Processing 00da9e6282c52cb3 - 4...\n",
      "Processing 00da9e6282c52cb3 - 5...\n",
      "Processing ./img/resize\\00dadebf247473de.jpg...\n",
      "\n",
      "0: 480x640 3 Persons, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00dadebf247473de - 1...\n",
      "Processing 00dadebf247473de - 2...\n",
      "Processing 00dadebf247473de - 3...\n",
      "Processing ./img/resize\\00db00539f49ae1a.jpg...\n",
      "\n",
      "0: 480x640 2 Human arms, 1 Human head, 3 Swimwears, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00db00539f49ae1a - 1...\n",
      "Processing 00db00539f49ae1a - 2...\n",
      "Processing 00db00539f49ae1a - 3...\n",
      "Processing 00db00539f49ae1a - 4...\n",
      "Processing 00db00539f49ae1a - 5...\n",
      "Processing 00db00539f49ae1a - 6...\n",
      "Processing ./img/resize\\00db0c99385099f7.jpg...\n",
      "\n",
      "0: 480x640 1 Footwear, 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00db0c99385099f7 - 1...\n",
      "Processing 00db0c99385099f7 - 2...\n",
      "Processing ./img/resize\\00db0eeeb512d452.jpg...\n",
      "\n",
      "0: 480x640 1 Poster, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00db0eeeb512d452 - 1...\n",
      "Processing ./img/resize\\00db14f9b28ac199.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle helmet, 2 Parrots, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00db14f9b28ac199 - 1...\n",
      "Processing 00db14f9b28ac199 - 2...\n",
      "Processing 00db14f9b28ac199 - 3...\n",
      "Processing ./img/resize\\00db278f9e2dc727.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00db6accad39db86.jpg...\n",
      "\n",
      "0: 480x640 1 House, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00db6accad39db86 - 1...\n",
      "Processing ./img/resize\\00db6fe704fdbd0e.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Digital clock, 3 Goggless, 1 Human face, 3 Mans, 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 00db6fe704fdbd0e - 1...\n",
      "Processing 00db6fe704fdbd0e - 2...\n",
      "Processing 00db6fe704fdbd0e - 3...\n",
      "Processing 00db6fe704fdbd0e - 4...\n",
      "Processing 00db6fe704fdbd0e - 5...\n",
      "Processing 00db6fe704fdbd0e - 6...\n",
      "Processing 00db6fe704fdbd0e - 7...\n",
      "Processing 00db6fe704fdbd0e - 8...\n",
      "Processing 00db6fe704fdbd0e - 9...\n",
      "Processing ./img/resize\\00dbac4e71c8d7d9.jpg...\n",
      "\n",
      "0: 480x640 1 Helmet, 2 Persons, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00dbac4e71c8d7d9 - 1...\n",
      "Processing 00dbac4e71c8d7d9 - 2...\n",
      "Processing 00dbac4e71c8d7d9 - 3...\n",
      "Processing ./img/resize\\00dbb568bb8551db.jpg...\n",
      "\n",
      "0: 480x640 3 Clothings, 1 Person, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00dbb568bb8551db - 1...\n",
      "Processing 00dbb568bb8551db - 2...\n",
      "Processing 00dbb568bb8551db - 3...\n",
      "Processing 00dbb568bb8551db - 4...\n",
      "Processing ./img/resize\\00dd982935d30942.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 2 Human faces, 1 Scarf, 2 Womans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00dd982935d30942 - 1...\n",
      "Processing 00dd982935d30942 - 2...\n",
      "Processing 00dd982935d30942 - 3...\n",
      "Processing 00dd982935d30942 - 4...\n",
      "Processing 00dd982935d30942 - 5...\n",
      "Processing 00dd982935d30942 - 6...\n",
      "Processing ./img/resize\\00de48d0ab9a014a.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Sun hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00de48d0ab9a014a - 1...\n",
      "Processing 00de48d0ab9a014a - 2...\n",
      "Processing ./img/resize\\00de7e3b6c92b3b3.jpg...\n",
      "\n",
      "0: 480x640 1 Sculpture, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00de7e3b6c92b3b3 - 1...\n",
      "Processing ./img/resize\\00deb92ff4cfd431.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00df11f2d5e82de6.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 1 Goggles, 1 Sun hat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00df11f2d5e82de6 - 1...\n",
      "Processing 00df11f2d5e82de6 - 2...\n",
      "Processing 00df11f2d5e82de6 - 3...\n",
      "Processing ./img/resize\\00df819bcaa2b17c.jpg...\n",
      "\n",
      "0: 480x640 1 Human body, 4 Mammals, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00df819bcaa2b17c - 1...\n",
      "Processing 00df819bcaa2b17c - 2...\n",
      "Processing 00df819bcaa2b17c - 3...\n",
      "Processing 00df819bcaa2b17c - 4...\n",
      "Processing 00df819bcaa2b17c - 5...\n",
      "Processing 00df819bcaa2b17c - 6...\n",
      "Processing ./img/resize\\00dfda92ea2cd38d.jpg...\n",
      "\n",
      "0: 480x640 1 Guitar, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00dfda92ea2cd38d - 1...\n",
      "Processing ./img/resize\\00dffd4d53cc7997.jpg...\n",
      "\n",
      "0: 480x640 5 Human faces, 5 Mans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "10\n",
      "Processing 00dffd4d53cc7997 - 1...\n",
      "Processing 00dffd4d53cc7997 - 2...\n",
      "Processing 00dffd4d53cc7997 - 3...\n",
      "Processing 00dffd4d53cc7997 - 4...\n",
      "Processing 00dffd4d53cc7997 - 5...\n",
      "Processing 00dffd4d53cc7997 - 6...\n",
      "Processing 00dffd4d53cc7997 - 7...\n",
      "Processing 00dffd4d53cc7997 - 8...\n",
      "Processing 00dffd4d53cc7997 - 9...\n",
      "Processing 00dffd4d53cc7997 - 10...\n",
      "Processing ./img/resize\\00e0938e5c1d367c.jpg...\n",
      "\n",
      "0: 480x640 1 Coffee table, 1 Egg (Food), 1 Sun hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00e0938e5c1d367c - 1...\n",
      "Processing 00e0938e5c1d367c - 2...\n",
      "Processing 00e0938e5c1d367c - 3...\n",
      "Processing ./img/resize\\00e0f402fcbc718c.jpg...\n",
      "\n",
      "0: 480x640 2 Alpacas, 2 Ambulances, 1 Artichoke, 1 Car, 5 Computer mouses, 1 Goggles, 1 Helicopter, 2 Lavender (Plant)s, 1 Mirror, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "16\n",
      "Processing 00e0f402fcbc718c - 1...\n",
      "Processing 00e0f402fcbc718c - 2...\n",
      "Processing 00e0f402fcbc718c - 3...\n",
      "Processing 00e0f402fcbc718c - 4...\n",
      "Processing 00e0f402fcbc718c - 5...\n",
      "Processing 00e0f402fcbc718c - 6...\n",
      "Processing 00e0f402fcbc718c - 7...\n",
      "Processing 00e0f402fcbc718c - 8...\n",
      "Processing 00e0f402fcbc718c - 9...\n",
      "Processing 00e0f402fcbc718c - 10...\n",
      "Processing 00e0f402fcbc718c - 11...\n",
      "Processing 00e0f402fcbc718c - 12...\n",
      "Processing 00e0f402fcbc718c - 13...\n",
      "Processing 00e0f402fcbc718c - 14...\n",
      "Processing 00e0f402fcbc718c - 15...\n",
      "Processing 00e0f402fcbc718c - 16...\n",
      "Processing ./img/resize\\00e166a2a88bc06f.jpg...\n",
      "\n",
      "0: 480x640 1 Guitar, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00e166a2a88bc06f - 1...\n",
      "Processing 00e166a2a88bc06f - 2...\n",
      "Processing ./img/resize\\00e171e90ce5838f.jpg...\n",
      "\n",
      "0: 480x640 2 Computer monitors, 1 Office building, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00e171e90ce5838f - 1...\n",
      "Processing 00e171e90ce5838f - 2...\n",
      "Processing 00e171e90ce5838f - 3...\n",
      "Processing ./img/resize\\00e1bc5ad01068ea.jpg...\n",
      "\n",
      "0: 480x640 2 Balls, 2 Bowls, 6 Boys, 1 Coffee table, 2 Egg (Food)s, 4 Goggless, 2 Grapefruits, 4 Human heads, 1 Sun hat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "24\n",
      "Processing 00e1bc5ad01068ea - 1...\n",
      "Processing 00e1bc5ad01068ea - 2...\n",
      "Processing 00e1bc5ad01068ea - 3...\n",
      "Processing 00e1bc5ad01068ea - 4...\n",
      "Processing 00e1bc5ad01068ea - 5...\n",
      "Processing 00e1bc5ad01068ea - 6...\n",
      "Processing 00e1bc5ad01068ea - 7...\n",
      "Processing 00e1bc5ad01068ea - 8...\n",
      "Processing 00e1bc5ad01068ea - 9...\n",
      "Processing 00e1bc5ad01068ea - 10...\n",
      "Processing 00e1bc5ad01068ea - 11...\n",
      "Processing 00e1bc5ad01068ea - 12...\n",
      "Processing 00e1bc5ad01068ea - 13...\n",
      "Processing 00e1bc5ad01068ea - 14...\n",
      "Processing 00e1bc5ad01068ea - 15...\n",
      "Processing 00e1bc5ad01068ea - 16...\n",
      "Processing 00e1bc5ad01068ea - 17...\n",
      "Processing 00e1bc5ad01068ea - 18...\n",
      "Processing 00e1bc5ad01068ea - 19...\n",
      "Processing 00e1bc5ad01068ea - 20...\n",
      "Processing 00e1bc5ad01068ea - 21...\n",
      "Processing 00e1bc5ad01068ea - 22...\n",
      "Processing 00e1bc5ad01068ea - 23...\n",
      "Processing 00e1bc5ad01068ea - 24...\n",
      "Processing ./img/resize\\00e1c2a241698b1e.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00e22a789b52a908.jpg...\n",
      "\n",
      "0: 480x640 2 Bicycles, 2 Bicycle wheels, 2 Wheels, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00e22a789b52a908 - 1...\n",
      "Processing 00e22a789b52a908 - 2...\n",
      "Processing 00e22a789b52a908 - 3...\n",
      "Processing 00e22a789b52a908 - 4...\n",
      "Processing 00e22a789b52a908 - 5...\n",
      "Processing 00e22a789b52a908 - 6...\n",
      "Processing ./img/resize\\00e23b8b935aafff.jpg...\n",
      "\n",
      "0: 480x640 6 Bicycles, 2 Bicycle wheels, 4 Persons, 2 Wheels, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "14\n",
      "Processing 00e23b8b935aafff - 1...\n",
      "Processing 00e23b8b935aafff - 2...\n",
      "Processing 00e23b8b935aafff - 3...\n",
      "Processing 00e23b8b935aafff - 4...\n",
      "Processing 00e23b8b935aafff - 5...\n",
      "Processing 00e23b8b935aafff - 6...\n",
      "Processing 00e23b8b935aafff - 7...\n",
      "Processing 00e23b8b935aafff - 8...\n",
      "Processing 00e23b8b935aafff - 9...\n",
      "Processing 00e23b8b935aafff - 10...\n",
      "Processing 00e23b8b935aafff - 11...\n",
      "Processing 00e23b8b935aafff - 12...\n",
      "Processing 00e23b8b935aafff - 13...\n",
      "Processing 00e23b8b935aafff - 14...\n",
      "Processing ./img/resize\\00e321bf9b2fc06b.jpg...\n",
      "\n",
      "0: 480x640 1 Chair, 1 House, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00e321bf9b2fc06b - 1...\n",
      "Processing 00e321bf9b2fc06b - 2...\n",
      "Processing ./img/resize\\00e32ed9219749a7.jpg...\n",
      "\n",
      "0: 480x640 1 Polar bear, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00e32ed9219749a7 - 1...\n",
      "Processing ./img/resize\\00e33d39d9b9ef85.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Coffee table, 1 Egg (Food), 1 Sun hat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00e33d39d9b9ef85 - 1...\n",
      "Processing 00e33d39d9b9ef85 - 2...\n",
      "Processing 00e33d39d9b9ef85 - 3...\n",
      "Processing 00e33d39d9b9ef85 - 4...\n",
      "Processing ./img/resize\\00e347dad7dd9dcf.jpg...\n",
      "\n",
      "0: 480x640 1 Airplane, 1 Wheel, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00e347dad7dd9dcf - 1...\n",
      "Processing 00e347dad7dd9dcf - 2...\n",
      "Processing ./img/resize\\00e359995608a9ba.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 1 Microphone, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00e359995608a9ba - 1...\n",
      "Processing 00e359995608a9ba - 2...\n",
      "Processing ./img/resize\\00e3993db63e5dd1.jpg...\n",
      "\n",
      "0: 480x640 1 Skyscraper, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00e3993db63e5dd1 - 1...\n",
      "Processing ./img/resize\\00e3efc1a8eeb4c4.jpg...\n",
      "\n",
      "0: 480x640 1 Swimming pool, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00e3efc1a8eeb4c4 - 1...\n",
      "Processing ./img/resize\\00e4091c7b1d2eae.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00e4091c7b1d2eae - 1...\n",
      "Processing ./img/resize\\00e44301fde50a9d.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 2 Coffee tables, 1 Egg (Food), 1 Goggles, 1 Human face, 1 Human head, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00e44301fde50a9d - 1...\n",
      "Processing 00e44301fde50a9d - 2...\n",
      "Processing 00e44301fde50a9d - 3...\n",
      "Processing 00e44301fde50a9d - 4...\n",
      "Processing 00e44301fde50a9d - 5...\n",
      "Processing 00e44301fde50a9d - 6...\n",
      "Processing 00e44301fde50a9d - 7...\n",
      "Processing 00e44301fde50a9d - 8...\n",
      "Processing ./img/resize\\00e46aa8a1d0a592.jpg...\n",
      "\n",
      "0: 480x640 2 Boxs, 1 Boy, 3 Cabinetrys, 2 Egg (Food)s, 6 Goggless, 1 Houseplant, 1 Human head, 1 Human leg, 1 Person, 3 Sun hats, 2 Trouserss, 32.0ms\n",
      "Speed: 1.0ms preprocess, 32.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "23\n",
      "Processing 00e46aa8a1d0a592 - 1...\n",
      "Processing 00e46aa8a1d0a592 - 2...\n",
      "Processing 00e46aa8a1d0a592 - 3...\n",
      "Processing 00e46aa8a1d0a592 - 4...\n",
      "Processing 00e46aa8a1d0a592 - 5...\n",
      "Processing 00e46aa8a1d0a592 - 6...\n",
      "Processing 00e46aa8a1d0a592 - 7...\n",
      "Processing 00e46aa8a1d0a592 - 8...\n",
      "Processing 00e46aa8a1d0a592 - 9...\n",
      "Processing 00e46aa8a1d0a592 - 10...\n",
      "Processing 00e46aa8a1d0a592 - 11...\n",
      "Processing 00e46aa8a1d0a592 - 12...\n",
      "Processing 00e46aa8a1d0a592 - 13...\n",
      "Processing 00e46aa8a1d0a592 - 14...\n",
      "Processing 00e46aa8a1d0a592 - 15...\n",
      "Processing 00e46aa8a1d0a592 - 16...\n",
      "Processing 00e46aa8a1d0a592 - 17...\n",
      "Processing 00e46aa8a1d0a592 - 18...\n",
      "Processing 00e46aa8a1d0a592 - 19...\n",
      "Processing 00e46aa8a1d0a592 - 20...\n",
      "Processing 00e46aa8a1d0a592 - 21...\n",
      "Processing 00e46aa8a1d0a592 - 22...\n",
      "Processing 00e46aa8a1d0a592 - 23...\n",
      "Processing ./img/resize\\00e49d11aa6c9b6f.jpg...\n",
      "\n",
      "0: 480x640 1 Dog, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00e49d11aa6c9b6f - 1...\n",
      "Processing ./img/resize\\00e575172c598e71.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00e575172c598e71 - 1...\n",
      "Processing 00e575172c598e71 - 2...\n",
      "Processing ./img/resize\\00e5815a44ce8815.jpg...\n",
      "\n",
      "0: 480x640 1 Helmet, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00e5815a44ce8815 - 1...\n",
      "Processing ./img/resize\\00e5988f1600409b.jpg...\n",
      "\n",
      "0: 480x640 1 Footwear, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00e5988f1600409b - 1...\n",
      "Processing ./img/resize\\00e5bdca6dadc300.jpg...\n",
      "\n",
      "0: 480x640 3 Footwears, 2 Jeanss, 4 Mans, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 00e5bdca6dadc300 - 1...\n",
      "Processing 00e5bdca6dadc300 - 2...\n",
      "Processing 00e5bdca6dadc300 - 3...\n",
      "Processing 00e5bdca6dadc300 - 4...\n",
      "Processing 00e5bdca6dadc300 - 5...\n",
      "Processing 00e5bdca6dadc300 - 6...\n",
      "Processing 00e5bdca6dadc300 - 7...\n",
      "Processing 00e5bdca6dadc300 - 8...\n",
      "Processing 00e5bdca6dadc300 - 9...\n",
      "Processing ./img/resize\\00e5c93e53ada7cd.jpg...\n",
      "\n",
      "0: 480x640 2 Flowerpots, 1 Houseplant, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00e5c93e53ada7cd - 1...\n",
      "Processing 00e5c93e53ada7cd - 2...\n",
      "Processing 00e5c93e53ada7cd - 3...\n",
      "Processing ./img/resize\\00e6bd5212b8f0b2.jpg...\n",
      "\n",
      "0: 480x640 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00e6bd5212b8f0b2 - 1...\n",
      "Processing ./img/resize\\00e6e6b183f3dd19.jpg...\n",
      "\n",
      "0: 480x640 2 Chairs, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00e6e6b183f3dd19 - 1...\n",
      "Processing 00e6e6b183f3dd19 - 2...\n",
      "Processing 00e6e6b183f3dd19 - 3...\n",
      "Processing ./img/resize\\00e703df7d48bc59.jpg...\n",
      "\n",
      "0: 480x640 1 Apple, 1 Human arm, 1 Human face, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00e703df7d48bc59 - 1...\n",
      "Processing 00e703df7d48bc59 - 2...\n",
      "Processing 00e703df7d48bc59 - 3...\n",
      "Processing ./img/resize\\00e713014d3136e6.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00e714bd8934e27d.jpg...\n",
      "\n",
      "0: 480x640 1 Apple, 1 Bicycle wheel, 1 Goggles, 1 Grapefruit, 1 Sun hat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00e714bd8934e27d - 1...\n",
      "Processing 00e714bd8934e27d - 2...\n",
      "Processing 00e714bd8934e27d - 3...\n",
      "Processing 00e714bd8934e27d - 4...\n",
      "Processing 00e714bd8934e27d - 5...\n",
      "Processing ./img/resize\\00e7a041fa358830.jpg...\n",
      "\n",
      "0: 480x640 3 Flowers, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00e7a041fa358830 - 1...\n",
      "Processing 00e7a041fa358830 - 2...\n",
      "Processing 00e7a041fa358830 - 3...\n",
      "Processing ./img/resize\\00e860a48c2a9158.jpg...\n",
      "\n",
      "0: 480x640 1 Snail, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00e860a48c2a9158 - 1...\n",
      "Processing ./img/resize\\00e8d6a2c2dde5e4.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00e8d6a2c2dde5e4 - 1...\n",
      "Processing ./img/resize\\00e9802f3dd7ad29.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00e9dba1299fc3be.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00ea64fe0fc2451a.jpg...\n",
      "\n",
      "0: 480x640 1 Apple, 1 Ball, 1 Bowl, 1 Boy, 1 Camera, 1 Coat, 1 Coffee cup, 1 Dress, 1 Fedora, 4 Goggless, 1 Human arm, 1 Human beard, 4 Human faces, 1 Human foot, 1 Human head, 1 Man, 2 Shirts, 1 Suit, 2 Sun hats, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "27\n",
      "Processing 00ea64fe0fc2451a - 1...\n",
      "Processing 00ea64fe0fc2451a - 2...\n",
      "Processing 00ea64fe0fc2451a - 3...\n",
      "Processing 00ea64fe0fc2451a - 4...\n",
      "Processing 00ea64fe0fc2451a - 5...\n",
      "Processing 00ea64fe0fc2451a - 6...\n",
      "Processing 00ea64fe0fc2451a - 7...\n",
      "Processing 00ea64fe0fc2451a - 8...\n",
      "Processing 00ea64fe0fc2451a - 9...\n",
      "Processing 00ea64fe0fc2451a - 10...\n",
      "Processing 00ea64fe0fc2451a - 11...\n",
      "Processing 00ea64fe0fc2451a - 12...\n",
      "Processing 00ea64fe0fc2451a - 13...\n",
      "Processing 00ea64fe0fc2451a - 14...\n",
      "Processing 00ea64fe0fc2451a - 15...\n",
      "Processing 00ea64fe0fc2451a - 16...\n",
      "Processing 00ea64fe0fc2451a - 17...\n",
      "Processing 00ea64fe0fc2451a - 18...\n",
      "Processing 00ea64fe0fc2451a - 19...\n",
      "Processing 00ea64fe0fc2451a - 20...\n",
      "Processing 00ea64fe0fc2451a - 21...\n",
      "Processing 00ea64fe0fc2451a - 22...\n",
      "Processing 00ea64fe0fc2451a - 23...\n",
      "Processing 00ea64fe0fc2451a - 24...\n",
      "Processing 00ea64fe0fc2451a - 25...\n",
      "Processing 00ea64fe0fc2451a - 26...\n",
      "Processing 00ea64fe0fc2451a - 27...\n",
      "Processing ./img/resize\\00eacfa72418a961.jpg...\n",
      "\n",
      "0: 480x640 2 Boys, 1 Coat, 1 Coffee table, 3 Goggless, 4 Human faces, 1 Human head, 1 Person, 2 Shirts, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "15\n",
      "Processing 00eacfa72418a961 - 1...\n",
      "Processing 00eacfa72418a961 - 2...\n",
      "Processing 00eacfa72418a961 - 3...\n",
      "Processing 00eacfa72418a961 - 4...\n",
      "Processing 00eacfa72418a961 - 5...\n",
      "Processing 00eacfa72418a961 - 6...\n",
      "Processing 00eacfa72418a961 - 7...\n",
      "Processing 00eacfa72418a961 - 8...\n",
      "Processing 00eacfa72418a961 - 9...\n",
      "Processing 00eacfa72418a961 - 10...\n",
      "Processing 00eacfa72418a961 - 11...\n",
      "Processing 00eacfa72418a961 - 12...\n",
      "Processing 00eacfa72418a961 - 13...\n",
      "Processing 00eacfa72418a961 - 14...\n",
      "Processing 00eacfa72418a961 - 15...\n",
      "Processing ./img/resize\\00ebd54d740318fe.jpg...\n",
      "\n",
      "0: 480x640 1 Dress, 3 Human faces, 1 Man, 2 Womans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00ebd54d740318fe - 1...\n",
      "Processing 00ebd54d740318fe - 2...\n",
      "Processing 00ebd54d740318fe - 3...\n",
      "Processing 00ebd54d740318fe - 4...\n",
      "Processing 00ebd54d740318fe - 5...\n",
      "Processing 00ebd54d740318fe - 6...\n",
      "Processing 00ebd54d740318fe - 7...\n",
      "Processing ./img/resize\\00ebd9518578826e.jpg...\n",
      "\n",
      "0: 480x640 1 Train, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00ebd9518578826e - 1...\n",
      "Processing ./img/resize\\00ec069e273cb31b.jpg...\n",
      "\n",
      "0: 480x640 2 Clothings, 2 Womans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00ec069e273cb31b - 1...\n",
      "Processing 00ec069e273cb31b - 2...\n",
      "Processing 00ec069e273cb31b - 3...\n",
      "Processing 00ec069e273cb31b - 4...\n",
      "Processing ./img/resize\\00ec431f19e5b895.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00ec76e71045e209.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 1 Tire, 1 Wheel, 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00ec76e71045e209 - 1...\n",
      "Processing 00ec76e71045e209 - 2...\n",
      "Processing 00ec76e71045e209 - 3...\n",
      "Processing ./img/resize\\00ec852caf537f58.jpg...\n",
      "\n",
      "0: 480x640 1 Ant, 10 Balls, 2 Bicycle wheels, 3 Bowls, 4 Boys, 3 Castles, 1 Coat, 1 Coffee table, 16 Goggless, 3 Grapefruits, 1 Harbor seal, 1 Helmet, 1 Human arm, 2 Human hairs, 2 Human heads, 2 Human noses, 1 Jacket, 1 Lighthouse, 2 Suits, 1 Sun hat, 29.0ms\n",
      "Speed: 4.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "58\n",
      "Processing 00ec852caf537f58 - 1...\n",
      "Processing 00ec852caf537f58 - 2...\n",
      "Processing 00ec852caf537f58 - 3...\n",
      "Processing 00ec852caf537f58 - 4...\n",
      "Processing 00ec852caf537f58 - 5...\n",
      "Processing 00ec852caf537f58 - 6...\n",
      "Processing 00ec852caf537f58 - 7...\n",
      "Processing 00ec852caf537f58 - 8...\n",
      "Processing 00ec852caf537f58 - 9...\n",
      "Processing 00ec852caf537f58 - 10...\n",
      "Processing 00ec852caf537f58 - 11...\n",
      "Processing 00ec852caf537f58 - 12...\n",
      "Processing 00ec852caf537f58 - 13...\n",
      "Processing 00ec852caf537f58 - 14...\n",
      "Processing 00ec852caf537f58 - 15...\n",
      "Processing 00ec852caf537f58 - 16...\n",
      "Processing 00ec852caf537f58 - 17...\n",
      "Processing 00ec852caf537f58 - 18...\n",
      "Processing 00ec852caf537f58 - 19...\n",
      "Processing 00ec852caf537f58 - 20...\n",
      "Processing 00ec852caf537f58 - 21...\n",
      "Processing 00ec852caf537f58 - 22...\n",
      "Processing 00ec852caf537f58 - 23...\n",
      "Processing 00ec852caf537f58 - 24...\n",
      "Processing 00ec852caf537f58 - 25...\n",
      "Processing 00ec852caf537f58 - 26...\n",
      "Processing 00ec852caf537f58 - 27...\n",
      "Processing 00ec852caf537f58 - 28...\n",
      "Processing 00ec852caf537f58 - 29...\n",
      "Processing 00ec852caf537f58 - 30...\n",
      "Processing 00ec852caf537f58 - 31...\n",
      "Processing 00ec852caf537f58 - 32...\n",
      "Processing 00ec852caf537f58 - 33...\n",
      "Processing 00ec852caf537f58 - 34...\n",
      "Processing 00ec852caf537f58 - 35...\n",
      "Processing 00ec852caf537f58 - 36...\n",
      "Processing 00ec852caf537f58 - 37...\n",
      "Processing 00ec852caf537f58 - 38...\n",
      "Processing 00ec852caf537f58 - 39...\n",
      "Processing 00ec852caf537f58 - 40...\n",
      "Processing 00ec852caf537f58 - 41...\n",
      "Processing 00ec852caf537f58 - 42...\n",
      "Processing 00ec852caf537f58 - 43...\n",
      "Processing 00ec852caf537f58 - 44...\n",
      "Processing 00ec852caf537f58 - 45...\n",
      "Processing 00ec852caf537f58 - 46...\n",
      "Processing 00ec852caf537f58 - 47...\n",
      "Processing 00ec852caf537f58 - 48...\n",
      "Processing 00ec852caf537f58 - 49...\n",
      "Processing 00ec852caf537f58 - 50...\n",
      "Processing 00ec852caf537f58 - 51...\n",
      "Processing 00ec852caf537f58 - 52...\n",
      "Processing 00ec852caf537f58 - 53...\n",
      "Processing 00ec852caf537f58 - 54...\n",
      "Processing 00ec852caf537f58 - 55...\n",
      "Processing 00ec852caf537f58 - 56...\n",
      "Processing 00ec852caf537f58 - 57...\n",
      "Processing 00ec852caf537f58 - 58...\n",
      "Processing ./img/resize\\00edc3611967df37.jpg...\n",
      "\n",
      "0: 480x640 2 Boys, 1 Dress, 2 Girls, 1 Human head, 1 Jeans, 1 Person, 1 Suit, 2 Wines, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "11\n",
      "Processing 00edc3611967df37 - 1...\n",
      "Processing 00edc3611967df37 - 2...\n",
      "Processing 00edc3611967df37 - 3...\n",
      "Processing 00edc3611967df37 - 4...\n",
      "Processing 00edc3611967df37 - 5...\n",
      "Processing 00edc3611967df37 - 6...\n",
      "Processing 00edc3611967df37 - 7...\n",
      "Processing 00edc3611967df37 - 8...\n",
      "Processing 00edc3611967df37 - 9...\n",
      "Processing 00edc3611967df37 - 10...\n",
      "Processing 00edc3611967df37 - 11...\n",
      "Processing ./img/resize\\00edc7c8b8861d1b.jpg...\n",
      "\n",
      "0: 480x640 2 Flags, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00edc7c8b8861d1b - 1...\n",
      "Processing 00edc7c8b8861d1b - 2...\n",
      "Processing ./img/resize\\00eeb20f84060e72.jpg...\n",
      "\n",
      "0: 480x640 1 Sea lion, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00eeb20f84060e72 - 1...\n",
      "Processing ./img/resize\\00ef228f781533f4.jpg...\n",
      "\n",
      "0: 480x640 1 Food, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00ef228f781533f4 - 1...\n",
      "Processing ./img/resize\\00ef298d1bbc1b89.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle, 2 Bicycle wheels, 2 Wheels, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00ef298d1bbc1b89 - 1...\n",
      "Processing 00ef298d1bbc1b89 - 2...\n",
      "Processing 00ef298d1bbc1b89 - 3...\n",
      "Processing 00ef298d1bbc1b89 - 4...\n",
      "Processing 00ef298d1bbc1b89 - 5...\n",
      "Processing ./img/resize\\00ef3723175b8dd4.jpg...\n",
      "\n",
      "0: 480x640 1 Bench, 4 Clothings, 1 Human body, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00ef3723175b8dd4 - 1...\n",
      "Processing 00ef3723175b8dd4 - 2...\n",
      "Processing 00ef3723175b8dd4 - 3...\n",
      "Processing 00ef3723175b8dd4 - 4...\n",
      "Processing 00ef3723175b8dd4 - 5...\n",
      "Processing 00ef3723175b8dd4 - 6...\n",
      "Processing ./img/resize\\00ef9830b7e6fd4f.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00ef9830b7e6fd4f - 1...\n",
      "Processing ./img/resize\\00efbea5ef21e69e.jpg...\n",
      "\n",
      "0: 480x640 1 Ant, 2 Artichokes, 1 Backpack, 3 Balls, 2 Baseball gloves, 4 Bicycle wheels, 3 Castles, 13 Goggless, 1 Harbor seal, 1 Helmet, 2 Human noses, 1 Jacket, 1 Lighthouse, 1 Suit, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "36\n",
      "Processing 00efbea5ef21e69e - 1...\n",
      "Processing 00efbea5ef21e69e - 2...\n",
      "Processing 00efbea5ef21e69e - 3...\n",
      "Processing 00efbea5ef21e69e - 4...\n",
      "Processing 00efbea5ef21e69e - 5...\n",
      "Processing 00efbea5ef21e69e - 6...\n",
      "Processing 00efbea5ef21e69e - 7...\n",
      "Processing 00efbea5ef21e69e - 8...\n",
      "Processing 00efbea5ef21e69e - 9...\n",
      "Processing 00efbea5ef21e69e - 10...\n",
      "Processing 00efbea5ef21e69e - 11...\n",
      "Processing 00efbea5ef21e69e - 12...\n",
      "Processing 00efbea5ef21e69e - 13...\n",
      "Processing 00efbea5ef21e69e - 14...\n",
      "Processing 00efbea5ef21e69e - 15...\n",
      "Processing 00efbea5ef21e69e - 16...\n",
      "Processing 00efbea5ef21e69e - 17...\n",
      "Processing 00efbea5ef21e69e - 18...\n",
      "Processing 00efbea5ef21e69e - 19...\n",
      "Processing 00efbea5ef21e69e - 20...\n",
      "Processing 00efbea5ef21e69e - 21...\n",
      "Processing 00efbea5ef21e69e - 22...\n",
      "Processing 00efbea5ef21e69e - 23...\n",
      "Processing 00efbea5ef21e69e - 24...\n",
      "Processing 00efbea5ef21e69e - 25...\n",
      "Processing 00efbea5ef21e69e - 26...\n",
      "Processing 00efbea5ef21e69e - 27...\n",
      "Processing 00efbea5ef21e69e - 28...\n",
      "Processing 00efbea5ef21e69e - 29...\n",
      "Processing 00efbea5ef21e69e - 30...\n",
      "Processing 00efbea5ef21e69e - 31...\n",
      "Processing 00efbea5ef21e69e - 32...\n",
      "Processing 00efbea5ef21e69e - 33...\n",
      "Processing 00efbea5ef21e69e - 34...\n",
      "Processing 00efbea5ef21e69e - 35...\n",
      "Processing 00efbea5ef21e69e - 36...\n",
      "Processing ./img/resize\\00efcd3b94a9834f.jpg...\n",
      "\n",
      "0: 480x640 1 Frog, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00efcd3b94a9834f - 1...\n",
      "Processing ./img/resize\\00efe42df185ef88.jpg...\n",
      "\n",
      "0: 480x640 1 Computer mouse, 1 Woman, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00efe42df185ef88 - 1...\n",
      "Processing 00efe42df185ef88 - 2...\n",
      "Processing ./img/resize\\00f021f335c45d1c.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle wheel, 2 Dresss, 3 Girls, 1 Human face, 1 Suit, 1 Wheel, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 00f021f335c45d1c - 1...\n",
      "Processing 00f021f335c45d1c - 2...\n",
      "Processing 00f021f335c45d1c - 3...\n",
      "Processing 00f021f335c45d1c - 4...\n",
      "Processing 00f021f335c45d1c - 5...\n",
      "Processing 00f021f335c45d1c - 6...\n",
      "Processing 00f021f335c45d1c - 7...\n",
      "Processing 00f021f335c45d1c - 8...\n",
      "Processing 00f021f335c45d1c - 9...\n",
      "Processing ./img/resize\\00f0463d9af5c346.jpg...\n",
      "\n",
      "0: 480x640 5 Computer mouses, 29.0ms\n",
      "Speed: 4.0ms preprocess, 29.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00f0463d9af5c346 - 1...\n",
      "Processing 00f0463d9af5c346 - 2...\n",
      "Processing 00f0463d9af5c346 - 3...\n",
      "Processing 00f0463d9af5c346 - 4...\n",
      "Processing 00f0463d9af5c346 - 5...\n",
      "Processing ./img/resize\\00f06d3432a38b24.jpg...\n",
      "\n",
      "0: 480x640 1 Bowl, 2 Boys, 1 Coffee table, 1 Egg (Food), 4 Goggless, 1 Human face, 1 Human foot, 1 Human hair, 1 Man, 2 Roses, 1 Shirt, 1 Suit, 1 Sun hat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "18\n",
      "Processing 00f06d3432a38b24 - 1...\n",
      "Processing 00f06d3432a38b24 - 2...\n",
      "Processing 00f06d3432a38b24 - 3...\n",
      "Processing 00f06d3432a38b24 - 4...\n",
      "Processing 00f06d3432a38b24 - 5...\n",
      "Processing 00f06d3432a38b24 - 6...\n",
      "Processing 00f06d3432a38b24 - 7...\n",
      "Processing 00f06d3432a38b24 - 8...\n",
      "Processing 00f06d3432a38b24 - 9...\n",
      "Processing 00f06d3432a38b24 - 10...\n",
      "Processing 00f06d3432a38b24 - 11...\n",
      "Processing 00f06d3432a38b24 - 12...\n",
      "Processing 00f06d3432a38b24 - 13...\n",
      "Processing 00f06d3432a38b24 - 14...\n",
      "Processing 00f06d3432a38b24 - 15...\n",
      "Processing 00f06d3432a38b24 - 16...\n",
      "Processing 00f06d3432a38b24 - 17...\n",
      "Processing 00f06d3432a38b24 - 18...\n",
      "Processing ./img/resize\\00f0f12cd06bb7f1.jpg...\n",
      "\n",
      "0: 480x640 1 Fedora, 1 Man, 1 Sunglasses, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00f0f12cd06bb7f1 - 1...\n",
      "Processing 00f0f12cd06bb7f1 - 2...\n",
      "Processing 00f0f12cd06bb7f1 - 3...\n",
      "Processing 00f0f12cd06bb7f1 - 4...\n",
      "Processing ./img/resize\\00f1964be80e3820.jpg...\n",
      "\n",
      "0: 480x640 1 Cat, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00f1964be80e3820 - 1...\n",
      "Processing ./img/resize\\00f1d8e44851dd2e.jpg...\n",
      "\n",
      "0: 480x640 1 Tank, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00f1d8e44851dd2e - 1...\n",
      "Processing ./img/resize\\00f23a4bd71ce535.jpg...\n",
      "\n",
      "0: 480x640 1 Kite, 1 Parachute, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00f23a4bd71ce535 - 1...\n",
      "Processing 00f23a4bd71ce535 - 2...\n",
      "Processing ./img/resize\\00f259fc130cbcc5.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00f2846f76c4a6f1.jpg...\n",
      "\n",
      "0: 480x640 2 Laptops, 1 Office building, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00f2846f76c4a6f1 - 1...\n",
      "Processing 00f2846f76c4a6f1 - 2...\n",
      "Processing 00f2846f76c4a6f1 - 3...\n",
      "Processing 00f2846f76c4a6f1 - 4...\n",
      "Processing ./img/resize\\00f28622328d5700.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00f28622328d5700 - 1...\n",
      "Processing ./img/resize\\00f2aadbc35373d1.jpg...\n",
      "\n",
      "0: 480x640 4 Swimwears, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 00f2aadbc35373d1 - 1...\n",
      "Processing 00f2aadbc35373d1 - 2...\n",
      "Processing 00f2aadbc35373d1 - 3...\n",
      "Processing 00f2aadbc35373d1 - 4...\n",
      "Processing ./img/resize\\00f32a741ab455c8.jpg...\n",
      "\n",
      "0: 480x640 1 Doll, 1 Human face, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00f32a741ab455c8 - 1...\n",
      "Processing 00f32a741ab455c8 - 2...\n",
      "Processing ./img/resize\\00f3732b89f6405e.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 31.0ms\n",
      "Speed: 3.0ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00f3732b89f6405e - 1...\n",
      "Processing ./img/resize\\00f4ec9ee8901d37.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 4 Human faces, 1 Woman, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00f4ec9ee8901d37 - 1...\n",
      "Processing 00f4ec9ee8901d37 - 2...\n",
      "Processing 00f4ec9ee8901d37 - 3...\n",
      "Processing 00f4ec9ee8901d37 - 4...\n",
      "Processing 00f4ec9ee8901d37 - 5...\n",
      "Processing 00f4ec9ee8901d37 - 6...\n",
      "Processing ./img/resize\\00f5987985a62fc5.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00f5987985a62fc5 - 1...\n",
      "Processing ./img/resize\\00f5dd76af679204.jpg...\n",
      "\n",
      "0: 480x640 1 Sheep, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00f5dd76af679204 - 1...\n",
      "Processing ./img/resize\\00f5ffaf93376d5d.jpg...\n",
      "\n",
      "0: 480x640 1 Aircraft, 1 Bicycle wheel, 1 Bronze sculpture, 1 Human head, 1 Person, 2 Toys, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00f5ffaf93376d5d - 1...\n",
      "Processing 00f5ffaf93376d5d - 2...\n",
      "Processing 00f5ffaf93376d5d - 3...\n",
      "Processing 00f5ffaf93376d5d - 4...\n",
      "Processing 00f5ffaf93376d5d - 5...\n",
      "Processing 00f5ffaf93376d5d - 6...\n",
      "Processing 00f5ffaf93376d5d - 7...\n",
      "Processing ./img/resize\\00f622f36aeca0df.jpg...\n",
      "\n",
      "0: 480x640 4 Bicycle wheels, 2 Human bodys, 1 Lighthouse, 1 Person, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00f622f36aeca0df - 1...\n",
      "Processing 00f622f36aeca0df - 2...\n",
      "Processing 00f622f36aeca0df - 3...\n",
      "Processing 00f622f36aeca0df - 4...\n",
      "Processing 00f622f36aeca0df - 5...\n",
      "Processing 00f622f36aeca0df - 6...\n",
      "Processing 00f622f36aeca0df - 7...\n",
      "Processing 00f622f36aeca0df - 8...\n",
      "Processing ./img/resize\\00f65a1fc2d0bf25.jpg...\n",
      "\n",
      "0: 480x640 1 Poster, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00f65a1fc2d0bf25 - 1...\n",
      "Processing ./img/resize\\00f6866f84c5bbe1.jpg...\n",
      "\n",
      "0: 480x640 1 Human eye, 2 Human faces, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00f6866f84c5bbe1 - 1...\n",
      "Processing 00f6866f84c5bbe1 - 2...\n",
      "Processing 00f6866f84c5bbe1 - 3...\n",
      "Processing ./img/resize\\00f6b8189211d6b6.jpg...\n",
      "\n",
      "0: 480x640 4 Candles, 2 Dolls, 4 Dresss, 2 Girls, 3 Human bodys, 2 Human hairs, 1 Microphone, 2 Persons, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "20\n",
      "Processing 00f6b8189211d6b6 - 1...\n",
      "Processing 00f6b8189211d6b6 - 2...\n",
      "Processing 00f6b8189211d6b6 - 3...\n",
      "Processing 00f6b8189211d6b6 - 4...\n",
      "Processing 00f6b8189211d6b6 - 5...\n",
      "Processing 00f6b8189211d6b6 - 6...\n",
      "Processing 00f6b8189211d6b6 - 7...\n",
      "Processing 00f6b8189211d6b6 - 8...\n",
      "Processing 00f6b8189211d6b6 - 9...\n",
      "Processing 00f6b8189211d6b6 - 10...\n",
      "Processing 00f6b8189211d6b6 - 11...\n",
      "Processing 00f6b8189211d6b6 - 12...\n",
      "Processing 00f6b8189211d6b6 - 13...\n",
      "Processing 00f6b8189211d6b6 - 14...\n",
      "Processing 00f6b8189211d6b6 - 15...\n",
      "Processing 00f6b8189211d6b6 - 16...\n",
      "Processing 00f6b8189211d6b6 - 17...\n",
      "Processing 00f6b8189211d6b6 - 18...\n",
      "Processing 00f6b8189211d6b6 - 19...\n",
      "Processing 00f6b8189211d6b6 - 20...\n",
      "Processing ./img/resize\\00f6eb3588480ae7.jpg...\n",
      "\n",
      "0: 480x640 1 Saucer, 1 Spoon, 1 Sun hat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00f6eb3588480ae7 - 1...\n",
      "Processing 00f6eb3588480ae7 - 2...\n",
      "Processing 00f6eb3588480ae7 - 3...\n",
      "Processing ./img/resize\\00f78515f1de5f87.jpg...\n",
      "\n",
      "0: 480x640 1 Dress, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00f78515f1de5f87 - 1...\n",
      "Processing ./img/resize\\00f7a28203ccfda4.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00f7ce7ec25b8962.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 2 Human faces, 2 Mans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 00f7ce7ec25b8962 - 1...\n",
      "Processing 00f7ce7ec25b8962 - 2...\n",
      "Processing 00f7ce7ec25b8962 - 3...\n",
      "Processing 00f7ce7ec25b8962 - 4...\n",
      "Processing 00f7ce7ec25b8962 - 5...\n",
      "Processing ./img/resize\\00f7f375379ee063.jpg...\n",
      "\n",
      "0: 480x640 3 Balloons, 1 Girl, 1 Home appliance, 1 Television, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00f7f375379ee063 - 1...\n",
      "Processing 00f7f375379ee063 - 2...\n",
      "Processing 00f7f375379ee063 - 3...\n",
      "Processing 00f7f375379ee063 - 4...\n",
      "Processing 00f7f375379ee063 - 5...\n",
      "Processing 00f7f375379ee063 - 6...\n",
      "Processing ./img/resize\\00f926d1f24a8837.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle helmet, 1 Dress, 1 Fashion accessory, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00f926d1f24a8837 - 1...\n",
      "Processing 00f926d1f24a8837 - 2...\n",
      "Processing 00f926d1f24a8837 - 3...\n",
      "Processing ./img/resize\\00f94b6b6cc565e0.jpg...\n",
      "\n",
      "0: 480x640 1 Boy, 1 Computer mouse, 4 Girls, 2 Human arms, 1 Human face, 2 Human legs, 4 Mirrors, 2 Televisions, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "17\n",
      "Processing 00f94b6b6cc565e0 - 1...\n",
      "Processing 00f94b6b6cc565e0 - 2...\n",
      "Processing 00f94b6b6cc565e0 - 3...\n",
      "Processing 00f94b6b6cc565e0 - 4...\n",
      "Processing 00f94b6b6cc565e0 - 5...\n",
      "Processing 00f94b6b6cc565e0 - 6...\n",
      "Processing 00f94b6b6cc565e0 - 7...\n",
      "Processing 00f94b6b6cc565e0 - 8...\n",
      "Processing 00f94b6b6cc565e0 - 9...\n",
      "Processing 00f94b6b6cc565e0 - 10...\n",
      "Processing 00f94b6b6cc565e0 - 11...\n",
      "Processing 00f94b6b6cc565e0 - 12...\n",
      "Processing 00f94b6b6cc565e0 - 13...\n",
      "Processing 00f94b6b6cc565e0 - 14...\n",
      "Processing 00f94b6b6cc565e0 - 15...\n",
      "Processing 00f94b6b6cc565e0 - 16...\n",
      "Processing 00f94b6b6cc565e0 - 17...\n",
      "Processing ./img/resize\\00f9d635ff9ce897.jpg...\n",
      "\n",
      "0: 480x640 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00f9d635ff9ce897 - 1...\n",
      "Processing ./img/resize\\00fa86e0d255d545.jpg...\n",
      "\n",
      "0: 480x640 1 Ball, 1 Clothing, 4 Persons, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 00fa86e0d255d545 - 1...\n",
      "Processing 00fa86e0d255d545 - 2...\n",
      "Processing 00fa86e0d255d545 - 3...\n",
      "Processing 00fa86e0d255d545 - 4...\n",
      "Processing 00fa86e0d255d545 - 5...\n",
      "Processing 00fa86e0d255d545 - 6...\n",
      "Processing ./img/resize\\00facfa1a6fa3842.jpg...\n",
      "\n",
      "0: 480x640 1 Flower, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00facfa1a6fa3842 - 1...\n",
      "Processing ./img/resize\\00fb104f215aa83d.jpg...\n",
      "\n",
      "0: 480x640 1 Dragonfly, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00fb104f215aa83d - 1...\n",
      "Processing ./img/resize\\00fb5269d9a06566.jpg...\n",
      "\n",
      "0: 480x640 1 Coffee table, 1 Egg (Food), 2 Human faces, 1 Human foot, 1 Human leg, 1 Sun hat, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00fb5269d9a06566 - 1...\n",
      "Processing 00fb5269d9a06566 - 2...\n",
      "Processing 00fb5269d9a06566 - 3...\n",
      "Processing 00fb5269d9a06566 - 4...\n",
      "Processing 00fb5269d9a06566 - 5...\n",
      "Processing 00fb5269d9a06566 - 6...\n",
      "Processing 00fb5269d9a06566 - 7...\n",
      "Processing ./img/resize\\00fb62be50bc2353.jpg...\n",
      "\n",
      "0: 480x640 3 Bicycle wheels, 1 Bookcase, 1 Man, 4 Persons, 1 Tower, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "10\n",
      "Processing 00fb62be50bc2353 - 1...\n",
      "Processing 00fb62be50bc2353 - 2...\n",
      "Processing 00fb62be50bc2353 - 3...\n",
      "Processing 00fb62be50bc2353 - 4...\n",
      "Processing 00fb62be50bc2353 - 5...\n",
      "Processing 00fb62be50bc2353 - 6...\n",
      "Processing 00fb62be50bc2353 - 7...\n",
      "Processing 00fb62be50bc2353 - 8...\n",
      "Processing 00fb62be50bc2353 - 9...\n",
      "Processing 00fb62be50bc2353 - 10...\n",
      "Processing ./img/resize\\00fb9b3e54b12a95.jpg...\n",
      "\n",
      "0: 480x640 2 Coffee tables, 1 Sun hat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 00fb9b3e54b12a95 - 1...\n",
      "Processing 00fb9b3e54b12a95 - 2...\n",
      "Processing 00fb9b3e54b12a95 - 3...\n",
      "Processing ./img/resize\\00fc015e8084be33.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00fc015e8084be33 - 1...\n",
      "Processing ./img/resize\\00fc0589b2120e21.jpg...\n",
      "\n",
      "0: 480x640 1 Parachute, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00fc0589b2120e21 - 1...\n",
      "Processing 00fc0589b2120e21 - 2...\n",
      "Processing ./img/resize\\00fce9f060ba3884.jpg...\n",
      "\n",
      "0: 480x640 2 Buss, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00fce9f060ba3884 - 1...\n",
      "Processing 00fce9f060ba3884 - 2...\n",
      "Processing ./img/resize\\00fcff0d0f6a58de.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Girl, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00fcff0d0f6a58de - 1...\n",
      "Processing 00fcff0d0f6a58de - 2...\n",
      "Processing ./img/resize\\00fd5930c02bc76e.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00fd5930c02bc76e - 1...\n",
      "Processing ./img/resize\\00fdac794066ac50.jpg...\n",
      "\n",
      "0: 480x640 1 Ant, 2 Bathroom accessorys, 2 Bicycle wheels, 1 Building, 1 Fashion accessory, 4 Goggless, 1 Human head, 1 Wheel, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "13\n",
      "Processing 00fdac794066ac50 - 1...\n",
      "Processing 00fdac794066ac50 - 2...\n",
      "Processing 00fdac794066ac50 - 3...\n",
      "Processing 00fdac794066ac50 - 4...\n",
      "Processing 00fdac794066ac50 - 5...\n",
      "Processing 00fdac794066ac50 - 6...\n",
      "Processing 00fdac794066ac50 - 7...\n",
      "Processing 00fdac794066ac50 - 8...\n",
      "Processing 00fdac794066ac50 - 9...\n",
      "Processing 00fdac794066ac50 - 10...\n",
      "Processing 00fdac794066ac50 - 11...\n",
      "Processing 00fdac794066ac50 - 12...\n",
      "Processing 00fdac794066ac50 - 13...\n",
      "Processing ./img/resize\\00fdae92723aa65c.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00fdae92723aa65c - 1...\n",
      "Processing ./img/resize\\00fdd35440969250.jpg...\n",
      "\n",
      "0: 480x640 1 Bird, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00fdd35440969250 - 1...\n",
      "Processing ./img/resize\\00fe0d5110794c28.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00fe0d5110794c28 - 1...\n",
      "Processing ./img/resize\\00fe19f6324beb0c.jpg...\n",
      "\n",
      "0: 480x640 2 Clothings, 4 Human faces, 1 Table, 2 Womans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 00fe19f6324beb0c - 1...\n",
      "Processing 00fe19f6324beb0c - 2...\n",
      "Processing 00fe19f6324beb0c - 3...\n",
      "Processing 00fe19f6324beb0c - 4...\n",
      "Processing 00fe19f6324beb0c - 5...\n",
      "Processing 00fe19f6324beb0c - 6...\n",
      "Processing 00fe19f6324beb0c - 7...\n",
      "Processing 00fe19f6324beb0c - 8...\n",
      "Processing 00fe19f6324beb0c - 9...\n",
      "Processing ./img/resize\\00fe4fe5cedd3bf5.jpg...\n",
      "\n",
      "0: 480x640 1 Curtain, 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00fe4fe5cedd3bf5 - 1...\n",
      "Processing ./img/resize\\00fe670dda70e4b4.jpg...\n",
      "\n",
      "0: 480x640 8 Persons, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 00fe670dda70e4b4 - 1...\n",
      "Processing 00fe670dda70e4b4 - 2...\n",
      "Processing 00fe670dda70e4b4 - 3...\n",
      "Processing 00fe670dda70e4b4 - 4...\n",
      "Processing 00fe670dda70e4b4 - 5...\n",
      "Processing 00fe670dda70e4b4 - 6...\n",
      "Processing 00fe670dda70e4b4 - 7...\n",
      "Processing 00fe670dda70e4b4 - 8...\n",
      "Processing ./img/resize\\00ff1bf898beb6ea.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\00ff2977d18d3ac9.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 00ff2977d18d3ac9 - 1...\n",
      "Processing ./img/resize\\00ff6b0cae0cc120.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle helmet, 2 Boats, 1 Computer monitor, 2 Egg (Food)s, 2 Goggless, 2 Human heads, 2 Sun hats, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "12\n",
      "Processing 00ff6b0cae0cc120 - 1...\n",
      "Processing 00ff6b0cae0cc120 - 2...\n",
      "Processing 00ff6b0cae0cc120 - 3...\n",
      "Processing 00ff6b0cae0cc120 - 4...\n",
      "Processing 00ff6b0cae0cc120 - 5...\n",
      "Processing 00ff6b0cae0cc120 - 6...\n",
      "Processing 00ff6b0cae0cc120 - 7...\n",
      "Processing 00ff6b0cae0cc120 - 8...\n",
      "Processing 00ff6b0cae0cc120 - 9...\n",
      "Processing 00ff6b0cae0cc120 - 10...\n",
      "Processing 00ff6b0cae0cc120 - 11...\n",
      "Processing 00ff6b0cae0cc120 - 12...\n",
      "Processing ./img/resize\\00ffc05d4de94301.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Person, 4 Picture frames, 1 Wall clock, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 00ffc05d4de94301 - 1...\n",
      "Processing 00ffc05d4de94301 - 2...\n",
      "Processing 00ffc05d4de94301 - 3...\n",
      "Processing 00ffc05d4de94301 - 4...\n",
      "Processing 00ffc05d4de94301 - 5...\n",
      "Processing 00ffc05d4de94301 - 6...\n",
      "Processing 00ffc05d4de94301 - 7...\n",
      "Processing ./img/resize\\00ffc40f6a6e00f4.jpg...\n",
      "\n",
      "0: 480x640 2 Human faces, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00ffc40f6a6e00f4 - 1...\n",
      "Processing 00ffc40f6a6e00f4 - 2...\n",
      "Processing ./img/resize\\00ffcc9dbc28fd84.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 00ffcc9dbc28fd84 - 1...\n",
      "Processing 00ffcc9dbc28fd84 - 2...\n",
      "Processing ./img/resize\\010015e0e985866a.jpg...\n",
      "\n",
      "0: 480x640 4 Apples, 1 Baked goods, 4 Bicycle wheels, 5 Coffee tables, 1 Fedora, 5 Goggless, 1 Human foot, 1 Human hair, 5 Human heads, 2 Mans, 2 Muffins, 1 Person, 1 Shirt, 2 Suits, 1 Tie, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "36\n",
      "Processing 010015e0e985866a - 1...\n",
      "Processing 010015e0e985866a - 2...\n",
      "Processing 010015e0e985866a - 3...\n",
      "Processing 010015e0e985866a - 4...\n",
      "Processing 010015e0e985866a - 5...\n",
      "Processing 010015e0e985866a - 6...\n",
      "Processing 010015e0e985866a - 7...\n",
      "Processing 010015e0e985866a - 8...\n",
      "Processing 010015e0e985866a - 9...\n",
      "Processing 010015e0e985866a - 10...\n",
      "Processing 010015e0e985866a - 11...\n",
      "Processing 010015e0e985866a - 12...\n",
      "Processing 010015e0e985866a - 13...\n",
      "Processing 010015e0e985866a - 14...\n",
      "Processing 010015e0e985866a - 15...\n",
      "Processing 010015e0e985866a - 16...\n",
      "Processing 010015e0e985866a - 17...\n",
      "Processing 010015e0e985866a - 18...\n",
      "Processing 010015e0e985866a - 19...\n",
      "Processing 010015e0e985866a - 20...\n",
      "Processing 010015e0e985866a - 21...\n",
      "Processing 010015e0e985866a - 22...\n",
      "Processing 010015e0e985866a - 23...\n",
      "Processing 010015e0e985866a - 24...\n",
      "Processing 010015e0e985866a - 25...\n",
      "Processing 010015e0e985866a - 26...\n",
      "Processing 010015e0e985866a - 27...\n",
      "Processing 010015e0e985866a - 28...\n",
      "Processing 010015e0e985866a - 29...\n",
      "Processing 010015e0e985866a - 30...\n",
      "Processing 010015e0e985866a - 31...\n",
      "Processing 010015e0e985866a - 32...\n",
      "Processing 010015e0e985866a - 33...\n",
      "Processing 010015e0e985866a - 34...\n",
      "Processing 010015e0e985866a - 35...\n",
      "Processing 010015e0e985866a - 36...\n",
      "Processing ./img/resize\\01005cf764611062.jpg...\n",
      "\n",
      "0: 480x640 1 Skyscraper, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 01005cf764611062 - 1...\n",
      "Processing ./img/resize\\0100734567753372.jpg...\n",
      "\n",
      "0: 480x640 1 Fish, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0100734567753372 - 1...\n",
      "Processing ./img/resize\\01007c6e49cc92de.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 01007c6e49cc92de - 1...\n",
      "Processing ./img/resize\\01008d84a3dc93ee.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0100c67a7714cba4.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0101127511e36fe8.jpg...\n",
      "\n",
      "0: 480x640 1 Dinosaur, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0101127511e36fe8 - 1...\n",
      "Processing ./img/resize\\0101298b74cca6b4.jpg...\n",
      "\n",
      "0: 480x640 3 Drums, 1 Guitar, 1 Person, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "5\n",
      "Processing 0101298b74cca6b4 - 1...\n",
      "Processing 0101298b74cca6b4 - 2...\n",
      "Processing 0101298b74cca6b4 - 3...\n",
      "Processing 0101298b74cca6b4 - 4...\n",
      "Processing 0101298b74cca6b4 - 5...\n",
      "Processing ./img/resize\\010174b218e16fc8.jpg...\n",
      "\n",
      "0: 480x640 1 Umbrella, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010174b218e16fc8 - 1...\n",
      "Processing ./img/resize\\0101dace3778eb22.jpg...\n",
      "\n",
      "0: 480x640 2 Persons, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0101dace3778eb22 - 1...\n",
      "Processing 0101dace3778eb22 - 2...\n",
      "Processing ./img/resize\\01022e0712a5b5d2.jpg...\n",
      "\n",
      "0: 480x640 1 Girl, 1 Human face, 1 Sun hat, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 01022e0712a5b5d2 - 1...\n",
      "Processing 01022e0712a5b5d2 - 2...\n",
      "Processing 01022e0712a5b5d2 - 3...\n",
      "Processing ./img/resize\\0102849a0b4b64b7.jpg...\n",
      "\n",
      "0: 480x640 1 Train, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0102849a0b4b64b7 - 1...\n",
      "Processing ./img/resize\\0102bc443592c22b.jpg...\n",
      "\n",
      "0: 480x640 4 Birds, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0102bc443592c22b - 1...\n",
      "Processing 0102bc443592c22b - 2...\n",
      "Processing 0102bc443592c22b - 3...\n",
      "Processing 0102bc443592c22b - 4...\n",
      "Processing ./img/resize\\0103666f416102e1.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0103666f416102e1 - 1...\n",
      "Processing ./img/resize\\01037e6a78f2f66d.jpg...\n",
      "\n",
      "0: 480x640 1 Coffee table, 1 Dress, 1 Human arm, 1 Human head, 1 Stairs, 3 Sun hats, 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "8\n",
      "Processing 01037e6a78f2f66d - 1...\n",
      "Processing 01037e6a78f2f66d - 2...\n",
      "Processing 01037e6a78f2f66d - 3...\n",
      "Processing 01037e6a78f2f66d - 4...\n",
      "Processing 01037e6a78f2f66d - 5...\n",
      "Processing 01037e6a78f2f66d - 6...\n",
      "Processing 01037e6a78f2f66d - 7...\n",
      "Processing 01037e6a78f2f66d - 8...\n",
      "Processing ./img/resize\\0103f947900f31b6.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0103f947900f31b6 - 1...\n",
      "Processing ./img/resize\\010416e67737c73c.jpg...\n",
      "\n",
      "0: 480x640 1 Ant, 2 Bathroom accessorys, 3 Bicycle wheels, 1 Fashion accessory, 3 Goggless, 1 Human face, 1 Human head, 1 Jacket, 1 Man, 2 Shirts, 1 Shower, 2 Ties, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "19\n",
      "Processing 010416e67737c73c - 1...\n",
      "Processing 010416e67737c73c - 2...\n",
      "Processing 010416e67737c73c - 3...\n",
      "Processing 010416e67737c73c - 4...\n",
      "Processing 010416e67737c73c - 5...\n",
      "Processing 010416e67737c73c - 6...\n",
      "Processing 010416e67737c73c - 7...\n",
      "Processing 010416e67737c73c - 8...\n",
      "Processing 010416e67737c73c - 9...\n",
      "Processing 010416e67737c73c - 10...\n",
      "Processing 010416e67737c73c - 11...\n",
      "Processing 010416e67737c73c - 12...\n",
      "Processing 010416e67737c73c - 13...\n",
      "Processing 010416e67737c73c - 14...\n",
      "Processing 010416e67737c73c - 15...\n",
      "Processing 010416e67737c73c - 16...\n",
      "Processing 010416e67737c73c - 17...\n",
      "Processing 010416e67737c73c - 18...\n",
      "Processing 010416e67737c73c - 19...\n",
      "Processing ./img/resize\\01041d7ed9f4a25b.jpg...\n",
      "\n",
      "0: 480x640 1 Poster, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 01041d7ed9f4a25b - 1...\n",
      "Processing ./img/resize\\010448367146e339.jpg...\n",
      "\n",
      "0: 480x640 1 Truck, 33.0ms\n",
      "Speed: 4.0ms preprocess, 33.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010448367146e339 - 1...\n",
      "Processing ./img/resize\\0104594a5c288645.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle, 2 Bicycle wheels, 1 Egg (Food), 1 Human hair, 1 Human head, 1 Person, 3 Sun hats, 2 Tires, 2 Wheels, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 12.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "14\n",
      "Processing 0104594a5c288645 - 1...\n",
      "Processing 0104594a5c288645 - 2...\n",
      "Processing 0104594a5c288645 - 3...\n",
      "Processing 0104594a5c288645 - 4...\n",
      "Processing 0104594a5c288645 - 5...\n",
      "Processing 0104594a5c288645 - 6...\n",
      "Processing 0104594a5c288645 - 7...\n",
      "Processing 0104594a5c288645 - 8...\n",
      "Processing 0104594a5c288645 - 9...\n",
      "Processing 0104594a5c288645 - 10...\n",
      "Processing 0104594a5c288645 - 11...\n",
      "Processing 0104594a5c288645 - 12...\n",
      "Processing 0104594a5c288645 - 13...\n",
      "Processing 0104594a5c288645 - 14...\n",
      "Processing ./img/resize\\0104f303a8bb8006.jpg...\n",
      "\n",
      "0: 480x640 1 Football helmet, 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0104f303a8bb8006 - 1...\n",
      "Processing 0104f303a8bb8006 - 2...\n",
      "Processing ./img/resize\\01064c7e28e96190.jpg...\n",
      "\n",
      "0: 480x640 2 Trees, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 01064c7e28e96190 - 1...\n",
      "Processing 01064c7e28e96190 - 2...\n",
      "Processing ./img/resize\\0106d215070dab90.jpg...\n",
      "\n",
      "0: 480x640 2 Airplanes, 1 Animal, 2 Auto parts, 1 Baked goods, 1 Ball, 1 Beer, 1 Bottle, 2 Buss, 1 Car, 1 Glasses, 2 Goggless, 1 Horse, 1 Human face, 2 Owls, 3 Persons, 1 Tire, 1 Truck, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "24\n",
      "Processing 0106d215070dab90 - 1...\n",
      "Processing 0106d215070dab90 - 2...\n",
      "Processing 0106d215070dab90 - 3...\n",
      "Processing 0106d215070dab90 - 4...\n",
      "Processing 0106d215070dab90 - 5...\n",
      "Processing 0106d215070dab90 - 6...\n",
      "Processing 0106d215070dab90 - 7...\n",
      "Processing 0106d215070dab90 - 8...\n",
      "Processing 0106d215070dab90 - 9...\n",
      "Processing 0106d215070dab90 - 10...\n",
      "Processing 0106d215070dab90 - 11...\n",
      "Processing 0106d215070dab90 - 12...\n",
      "Processing 0106d215070dab90 - 13...\n",
      "Processing 0106d215070dab90 - 14...\n",
      "Processing 0106d215070dab90 - 15...\n",
      "Processing 0106d215070dab90 - 16...\n",
      "Processing 0106d215070dab90 - 17...\n",
      "Processing 0106d215070dab90 - 18...\n",
      "Processing 0106d215070dab90 - 19...\n",
      "Processing 0106d215070dab90 - 20...\n",
      "Processing 0106d215070dab90 - 21...\n",
      "Processing 0106d215070dab90 - 22...\n",
      "Processing 0106d215070dab90 - 23...\n",
      "Processing 0106d215070dab90 - 24...\n",
      "Processing ./img/resize\\0106fcd08df1f179.jpg...\n",
      "\n",
      "0: 480x640 3 Bicycle wheels, 2 Dogs, 1 Tick, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 0106fcd08df1f179 - 1...\n",
      "Processing 0106fcd08df1f179 - 2...\n",
      "Processing 0106fcd08df1f179 - 3...\n",
      "Processing 0106fcd08df1f179 - 4...\n",
      "Processing 0106fcd08df1f179 - 5...\n",
      "Processing 0106fcd08df1f179 - 6...\n",
      "Processing ./img/resize\\0107395b9550040b.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0107840f3eb1eba0.jpg...\n",
      "\n",
      "0: 480x640 1 Truck, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0107840f3eb1eba0 - 1...\n",
      "Processing ./img/resize\\0108015334c2abf2.jpg...\n",
      "\n",
      "0: 480x640 1 Girl, 1 Skirt, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0108015334c2abf2 - 1...\n",
      "Processing 0108015334c2abf2 - 2...\n",
      "Processing ./img/resize\\010869c722558baf.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010869c722558baf - 1...\n",
      "Processing ./img/resize\\0108defde32c6d24.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0108defde32c6d24 - 1...\n",
      "Processing ./img/resize\\0108e48a74c55830.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 1 Infant bed, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0108e48a74c55830 - 1...\n",
      "Processing 0108e48a74c55830 - 2...\n",
      "Processing ./img/resize\\0108f3fd4b5a6cf4.jpg...\n",
      "\n",
      "0: 480x640 1 Guitar, 3 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "4\n",
      "Processing 0108f3fd4b5a6cf4 - 1...\n",
      "Processing 0108f3fd4b5a6cf4 - 2...\n",
      "Processing 0108f3fd4b5a6cf4 - 3...\n",
      "Processing 0108f3fd4b5a6cf4 - 4...\n",
      "Processing ./img/resize\\0108f97ca12aaf61.jpg...\n",
      "\n",
      "0: 480x640 3 Roses, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0108f97ca12aaf61 - 1...\n",
      "Processing 0108f97ca12aaf61 - 2...\n",
      "Processing 0108f97ca12aaf61 - 3...\n",
      "Processing ./img/resize\\010963259ce4ddf7.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010963259ce4ddf7 - 1...\n",
      "Processing ./img/resize\\01098d27152789ad.jpg...\n",
      "\n",
      "0: 480x640 1 Plant, 1 Tiger, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 01098d27152789ad - 1...\n",
      "Processing 01098d27152789ad - 2...\n",
      "Processing ./img/resize\\01098f74a2de0652.jpg...\n",
      "\n",
      "0: 480x640 1 Ant, 1 Bee, 2 Beetles, 1 Harbor seal, 2 Sea lions, 1 Shrimp, 1 Tart, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 01098f74a2de0652 - 1...\n",
      "Processing 01098f74a2de0652 - 2...\n",
      "Processing 01098f74a2de0652 - 3...\n",
      "Processing 01098f74a2de0652 - 4...\n",
      "Processing 01098f74a2de0652 - 5...\n",
      "Processing 01098f74a2de0652 - 6...\n",
      "Processing 01098f74a2de0652 - 7...\n",
      "Processing 01098f74a2de0652 - 8...\n",
      "Processing 01098f74a2de0652 - 9...\n",
      "Processing ./img/resize\\0109a261f4eea927.jpg...\n",
      "\n",
      "0: 480x640 1 Deer, 1 Stop sign, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0109a261f4eea927 - 1...\n",
      "Processing 0109a261f4eea927 - 2...\n",
      "Processing ./img/resize\\010a203782042ef8.jpg...\n",
      "\n",
      "0: 480x640 1 Tree, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010a203782042ef8 - 1...\n",
      "Processing ./img/resize\\010ad05dc6298d29.jpg...\n",
      "\n",
      "0: 480x640 1 Tower, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010ad05dc6298d29 - 1...\n",
      "Processing ./img/resize\\010b2a5f7a79cf09.jpg...\n",
      "\n",
      "0: 480x640 1 Human face, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010b2a5f7a79cf09 - 1...\n",
      "Processing ./img/resize\\010b4b27836063ea.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\010b87bd30accfc4.jpg...\n",
      "\n",
      "0: 480x640 1 Building, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010b87bd30accfc4 - 1...\n",
      "Processing ./img/resize\\010bbe2a3b29d196.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010bbe2a3b29d196 - 1...\n",
      "Processing ./img/resize\\010bc2ca2d3a9875.jpg...\n",
      "\n",
      "0: 480x640 1 Football, 5 Mans, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 010bc2ca2d3a9875 - 1...\n",
      "Processing 010bc2ca2d3a9875 - 2...\n",
      "Processing 010bc2ca2d3a9875 - 3...\n",
      "Processing 010bc2ca2d3a9875 - 4...\n",
      "Processing 010bc2ca2d3a9875 - 5...\n",
      "Processing 010bc2ca2d3a9875 - 6...\n",
      "Processing ./img/resize\\010c325f45f539c6.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\010c5676c725fc04.jpg...\n",
      "\n",
      "0: 480x640 1 Car, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010c5676c725fc04 - 1...\n",
      "Processing ./img/resize\\010c611f83122d42.jpg...\n",
      "\n",
      "0: 480x640 1 Necklace, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010c611f83122d42 - 1...\n",
      "Processing ./img/resize\\010c681f640afc3b.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 010c681f640afc3b - 1...\n",
      "Processing 010c681f640afc3b - 2...\n",
      "Processing ./img/resize\\010c6f39b6d9b7a4.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\010c96f14cb87a3d.jpg...\n",
      "\n",
      "0: 480x640 1 Person, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010c96f14cb87a3d - 1...\n",
      "Processing ./img/resize\\010caf0314876f5d.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\010d4df2a4e92e15.jpg...\n",
      "\n",
      "0: 480x640 1 Teddy bear, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010d4df2a4e92e15 - 1...\n",
      "Processing ./img/resize\\010d62036f2059dc.jpg...\n",
      "\n",
      "0: 480x640 2 Boats, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 010d62036f2059dc - 1...\n",
      "Processing 010d62036f2059dc - 2...\n",
      "Processing ./img/resize\\010d8bbefbdd3363.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\010dce7cb9251d5e.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 36.9ms\n",
      "Speed: 2.1ms preprocess, 36.9ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\010e02e57e65ee77.jpg...\n",
      "\n",
      "0: 480x640 2 Boys, 4 Coffee tables, 2 Dresss, 1 Egg (Food), 1 Goggles, 6 Human arms, 1 Human body, 1 Laptop, 2 Mans, 5 Persons, 2 Sun hats, 1 Vehicle registration plate, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "28\n",
      "Processing 010e02e57e65ee77 - 1...\n",
      "Processing 010e02e57e65ee77 - 2...\n",
      "Processing 010e02e57e65ee77 - 3...\n",
      "Processing 010e02e57e65ee77 - 4...\n",
      "Processing 010e02e57e65ee77 - 5...\n",
      "Processing 010e02e57e65ee77 - 6...\n",
      "Processing 010e02e57e65ee77 - 7...\n",
      "Processing 010e02e57e65ee77 - 8...\n",
      "Processing 010e02e57e65ee77 - 9...\n",
      "Processing 010e02e57e65ee77 - 10...\n",
      "Processing 010e02e57e65ee77 - 11...\n",
      "Processing 010e02e57e65ee77 - 12...\n",
      "Processing 010e02e57e65ee77 - 13...\n",
      "Processing 010e02e57e65ee77 - 14...\n",
      "Processing 010e02e57e65ee77 - 15...\n",
      "Processing 010e02e57e65ee77 - 16...\n",
      "Processing 010e02e57e65ee77 - 17...\n",
      "Processing 010e02e57e65ee77 - 18...\n",
      "Processing 010e02e57e65ee77 - 19...\n",
      "Processing 010e02e57e65ee77 - 20...\n",
      "Processing 010e02e57e65ee77 - 21...\n",
      "Processing 010e02e57e65ee77 - 22...\n",
      "Processing 010e02e57e65ee77 - 23...\n",
      "Processing 010e02e57e65ee77 - 24...\n",
      "Processing 010e02e57e65ee77 - 25...\n",
      "Processing 010e02e57e65ee77 - 26...\n",
      "Processing 010e02e57e65ee77 - 27...\n",
      "Processing 010e02e57e65ee77 - 28...\n",
      "Processing ./img/resize\\010e5e008a3c73dc.jpg...\n",
      "\n",
      "0: 480x640 2 Womans, 30.0ms\n",
      "Speed: 4.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 010e5e008a3c73dc - 1...\n",
      "Processing 010e5e008a3c73dc - 2...\n",
      "Processing ./img/resize\\010e8b547a3297d5.jpg...\n",
      "\n",
      "0: 480x640 1 Apple, 1 Computer monitor, 2 Egg (Food)s, 1 Fashion accessory, 2 Goggless, 1 Grapefruit, 1 Human face, 1 Human foot, 1 Person, 1 Rose, 1 Swim cap, 1 Umbrella, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "14\n",
      "Processing 010e8b547a3297d5 - 1...\n",
      "Processing 010e8b547a3297d5 - 2...\n",
      "Processing 010e8b547a3297d5 - 3...\n",
      "Processing 010e8b547a3297d5 - 4...\n",
      "Processing 010e8b547a3297d5 - 5...\n",
      "Processing 010e8b547a3297d5 - 6...\n",
      "Processing 010e8b547a3297d5 - 7...\n",
      "Processing 010e8b547a3297d5 - 8...\n",
      "Processing 010e8b547a3297d5 - 9...\n",
      "Processing 010e8b547a3297d5 - 10...\n",
      "Processing 010e8b547a3297d5 - 11...\n",
      "Processing 010e8b547a3297d5 - 12...\n",
      "Processing 010e8b547a3297d5 - 13...\n",
      "Processing 010e8b547a3297d5 - 14...\n",
      "Processing ./img/resize\\010e90db475b9e4f.jpg...\n",
      "\n",
      "0: 480x640 1 Camel, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010e90db475b9e4f - 1...\n",
      "Processing ./img/resize\\010e94dfcf4be882.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\010ea0c070d0d89e.jpg...\n",
      "\n",
      "0: 480x640 1 Clothing, 1 Man, 1 Woman, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 010ea0c070d0d89e - 1...\n",
      "Processing 010ea0c070d0d89e - 2...\n",
      "Processing 010ea0c070d0d89e - 3...\n",
      "Processing ./img/resize\\010ef7c8ff2fde5c.jpg...\n",
      "\n",
      "0: 480x640 5 Flags, 2 Mans, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "7\n",
      "Processing 010ef7c8ff2fde5c - 1...\n",
      "Processing 010ef7c8ff2fde5c - 2...\n",
      "Processing 010ef7c8ff2fde5c - 3...\n",
      "Processing 010ef7c8ff2fde5c - 4...\n",
      "Processing 010ef7c8ff2fde5c - 5...\n",
      "Processing 010ef7c8ff2fde5c - 6...\n",
      "Processing 010ef7c8ff2fde5c - 7...\n",
      "Processing ./img/resize\\010efe09223dbbfc.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 010efe09223dbbfc - 1...\n",
      "Processing 010efe09223dbbfc - 2...\n",
      "Processing 010efe09223dbbfc - 3...\n",
      "Processing ./img/resize\\010f8d5b1161028f.jpg...\n",
      "\n",
      "0: 480x640 1 Butterfly, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 010f8d5b1161028f - 1...\n",
      "Processing ./img/resize\\010fabbea877b274.jpg...\n",
      "\n",
      "0: 480x640 2 Fishs, 1 Shark, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 010fabbea877b274 - 1...\n",
      "Processing 010fabbea877b274 - 2...\n",
      "Processing 010fabbea877b274 - 3...\n",
      "Processing ./img/resize\\01100ad81fcaa3c6.jpg...\n",
      "\n",
      "0: 480x640 2 Street lights, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 01100ad81fcaa3c6 - 1...\n",
      "Processing 01100ad81fcaa3c6 - 2...\n",
      "Processing ./img/resize\\01103c2cf406b068.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0110474634a76977.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 4 Human faces, 1 Man, 3 Womans, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "9\n",
      "Processing 0110474634a76977 - 1...\n",
      "Processing 0110474634a76977 - 2...\n",
      "Processing 0110474634a76977 - 3...\n",
      "Processing 0110474634a76977 - 4...\n",
      "Processing 0110474634a76977 - 5...\n",
      "Processing 0110474634a76977 - 6...\n",
      "Processing 0110474634a76977 - 7...\n",
      "Processing 0110474634a76977 - 8...\n",
      "Processing 0110474634a76977 - 9...\n",
      "Processing ./img/resize\\0110bf3b3f62c05a.jpg...\n",
      "\n",
      "0: 480x640 1 Guitar, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0110bf3b3f62c05a - 1...\n",
      "Processing ./img/resize\\0111eeda8d35038e.jpg...\n",
      "\n",
      "0: 480x640 1 Glasses, 1 Human face, 1 Man, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 0111eeda8d35038e - 1...\n",
      "Processing 0111eeda8d35038e - 2...\n",
      "Processing 0111eeda8d35038e - 3...\n",
      "Processing ./img/resize\\01121fdcca8318fc.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\0112203694bcdfda.jpg...\n",
      "\n",
      "0: 480x640 1 Bicycle wheel, 1 Tree, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0112203694bcdfda - 1...\n",
      "Processing 0112203694bcdfda - 2...\n",
      "Processing ./img/resize\\0112ee98d70904dc.jpg...\n",
      "\n",
      "0: 480x640 1 Boat, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 0112ee98d70904dc - 1...\n",
      "Processing ./img/resize\\01131ee36cce4358.jpg...\n",
      "\n",
      "0: 480x640 2 Cars, 1 Tree, 30.0ms\n",
      "Speed: 0.9ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 01131ee36cce4358 - 1...\n",
      "Processing 01131ee36cce4358 - 2...\n",
      "Processing 01131ee36cce4358 - 3...\n",
      "Processing ./img/resize\\01136d0450db721e.jpg...\n",
      "\n",
      "0: 480x640 1 Grape, 30.0ms\n",
      "Speed: 1.0ms preprocess, 30.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "Processing 01136d0450db721e - 1...\n",
      "Processing ./img/resize\\01141bbabb8502da.jpg...\n",
      "\n",
      "0: 480x640 2 Clothings, 1 Flag, 2 Persons, 1 Table, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "6\n",
      "Processing 01141bbabb8502da - 1...\n",
      "Processing 01141bbabb8502da - 2...\n",
      "Processing 01141bbabb8502da - 3...\n",
      "Processing 01141bbabb8502da - 4...\n",
      "Processing 01141bbabb8502da - 5...\n",
      "Processing 01141bbabb8502da - 6...\n",
      "Processing ./img/resize\\0114223477d4a23e.jpg...\n",
      "\n",
      "0: 480x640 1 Man, 1 Sports uniform, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2\n",
      "Processing 0114223477d4a23e - 1...\n",
      "Processing 0114223477d4a23e - 2...\n",
      "Processing ./img/resize\\01143463441b301c.jpg...\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Processing ./img/resize\\01149f98161de228.jpg...\n",
      "\n",
      "0: 480x640 2 Mans, 1 Woman, 36.0ms\n",
      "Speed: 2.0ms preprocess, 36.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "3\n",
      "Processing 01149f98161de228 - 1...\n",
      "Processing 01149f98161de228 - 2...\n",
      "Processing 01149f98161de228 - 3...\n",
      "Processing ./img/resize\\0114aa586fa747f5.jpg...\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msave_obj_img_to_bovw\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_img_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m, in \u001b[0;36msave_obj_img_to_bovw\u001b[1;34m(img_files, model)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m batch_files:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[43mget_item_from_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m objs:\n\u001b[0;32m     11\u001b[0m         results\u001b[38;5;241m.\u001b[39mextend(objs)\n",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36mget_item_from_img\u001b[1;34m(img_path, model)\u001b[0m\n\u001b[0;32m      2\u001b[0m img_cv2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[0;32m      3\u001b[0m img_id \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(img_path))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_cv2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_hist.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m objs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:554\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:253\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(im0s)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m--> 253\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprofilers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\ops.py:51\u001b[0m, in \u001b[0;36mProfile.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Stop timing.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart  \u001b[38;5;66;03m# delta-time\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\ops.py:61\u001b[0m, in \u001b[0;36mProfile.time\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get current time.\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda:\n\u001b[1;32m---> 61\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\cuda\\__init__.py:954\u001b[0m, in \u001b[0;36msynchronize\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    952\u001b[0m _lazy_init()\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m--> 954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "save_obj_img_to_bovw(sub_img_files, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./bovw/json/bovw_class11.json\", \"w\") as f:\n",
    "    json.dump(list_bovw, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 256x640 (no detections), 349.9ms\n",
      "Speed: 4.1ms preprocess, 349.9ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'Accordion', 1: 'Adhesive tape', 2: 'Aircraft', 3: 'Airplane', 4: 'Alarm clock', 5: 'Alpaca', 6: 'Ambulance', 7: 'Animal', 8: 'Ant', 9: 'Antelope', 10: 'Apple', 11: 'Armadillo', 12: 'Artichoke', 13: 'Auto part', 14: 'Axe', 15: 'Backpack', 16: 'Bagel', 17: 'Baked goods', 18: 'Balance beam', 19: 'Ball', 20: 'Balloon', 21: 'Banana', 22: 'Band-aid', 23: 'Banjo', 24: 'Barge', 25: 'Barrel', 26: 'Baseball bat', 27: 'Baseball glove', 28: 'Bat (Animal)', 29: 'Bathroom accessory', 30: 'Bathroom cabinet', 31: 'Bathtub', 32: 'Beaker', 33: 'Bear', 34: 'Bed', 35: 'Bee', 36: 'Beehive', 37: 'Beer', 38: 'Beetle', 39: 'Bell pepper', 40: 'Belt', 41: 'Bench', 42: 'Bicycle', 43: 'Bicycle helmet', 44: 'Bicycle wheel', 45: 'Bidet', 46: 'Billboard', 47: 'Billiard table', 48: 'Binoculars', 49: 'Bird', 50: 'Blender', 51: 'Blue jay', 52: 'Boat', 53: 'Bomb', 54: 'Book', 55: 'Bookcase', 56: 'Boot', 57: 'Bottle', 58: 'Bottle opener', 59: 'Bow and arrow', 60: 'Bowl', 61: 'Bowling equipment', 62: 'Box', 63: 'Boy', 64: 'Brassiere', 65: 'Bread', 66: 'Briefcase', 67: 'Broccoli', 68: 'Bronze sculpture', 69: 'Brown bear', 70: 'Building', 71: 'Bull', 72: 'Burrito', 73: 'Bus', 74: 'Bust', 75: 'Butterfly', 76: 'Cabbage', 77: 'Cabinetry', 78: 'Cake', 79: 'Cake stand', 80: 'Calculator', 81: 'Camel', 82: 'Camera', 83: 'Can opener', 84: 'Canary', 85: 'Candle', 86: 'Candy', 87: 'Cannon', 88: 'Canoe', 89: 'Cantaloupe', 90: 'Car', 91: 'Carnivore', 92: 'Carrot', 93: 'Cart', 94: 'Cassette deck', 95: 'Castle', 96: 'Cat', 97: 'Cat furniture', 98: 'Caterpillar', 99: 'Cattle', 100: 'Ceiling fan', 101: 'Cello', 102: 'Centipede', 103: 'Chainsaw', 104: 'Chair', 105: 'Cheese', 106: 'Cheetah', 107: 'Chest of drawers', 108: 'Chicken', 109: 'Chime', 110: 'Chisel', 111: 'Chopsticks', 112: 'Christmas tree', 113: 'Clock', 114: 'Closet', 115: 'Clothing', 116: 'Coat', 117: 'Cocktail', 118: 'Cocktail shaker', 119: 'Coconut', 120: 'Coffee', 121: 'Coffee cup', 122: 'Coffee table', 123: 'Coffeemaker', 124: 'Coin', 125: 'Common fig', 126: 'Common sunflower', 127: 'Computer keyboard', 128: 'Computer monitor', 129: 'Computer mouse', 130: 'Container', 131: 'Convenience store', 132: 'Cookie', 133: 'Cooking spray', 134: 'Corded phone', 135: 'Cosmetics', 136: 'Couch', 137: 'Countertop', 138: 'Cowboy hat', 139: 'Crab', 140: 'Cream', 141: 'Cricket ball', 142: 'Crocodile', 143: 'Croissant', 144: 'Crown', 145: 'Crutch', 146: 'Cucumber', 147: 'Cupboard', 148: 'Curtain', 149: 'Cutting board', 150: 'Dagger', 151: 'Dairy Product', 152: 'Deer', 153: 'Desk', 154: 'Dessert', 155: 'Diaper', 156: 'Dice', 157: 'Digital clock', 158: 'Dinosaur', 159: 'Dishwasher', 160: 'Dog', 161: 'Dog bed', 162: 'Doll', 163: 'Dolphin', 164: 'Door', 165: 'Door handle', 166: 'Doughnut', 167: 'Dragonfly', 168: 'Drawer', 169: 'Dress', 170: 'Drill (Tool)', 171: 'Drink', 172: 'Drinking straw', 173: 'Drum', 174: 'Duck', 175: 'Dumbbell', 176: 'Eagle', 177: 'Earrings', 178: 'Egg (Food)', 179: 'Elephant', 180: 'Envelope', 181: 'Eraser', 182: 'Face powder', 183: 'Facial tissue holder', 184: 'Falcon', 185: 'Fashion accessory', 186: 'Fast food', 187: 'Fax', 188: 'Fedora', 189: 'Filing cabinet', 190: 'Fire hydrant', 191: 'Fireplace', 192: 'Fish', 193: 'Flag', 194: 'Flashlight', 195: 'Flower', 196: 'Flowerpot', 197: 'Flute', 198: 'Flying disc', 199: 'Food', 200: 'Food processor', 201: 'Football', 202: 'Football helmet', 203: 'Footwear', 204: 'Fork', 205: 'Fountain', 206: 'Fox', 207: 'French fries', 208: 'French horn', 209: 'Frog', 210: 'Fruit', 211: 'Frying pan', 212: 'Furniture', 213: 'Garden Asparagus', 214: 'Gas stove', 215: 'Giraffe', 216: 'Girl', 217: 'Glasses', 218: 'Glove', 219: 'Goat', 220: 'Goggles', 221: 'Goldfish', 222: 'Golf ball', 223: 'Golf cart', 224: 'Gondola', 225: 'Goose', 226: 'Grape', 227: 'Grapefruit', 228: 'Grinder', 229: 'Guacamole', 230: 'Guitar', 231: 'Hair dryer', 232: 'Hair spray', 233: 'Hamburger', 234: 'Hammer', 235: 'Hamster', 236: 'Hand dryer', 237: 'Handbag', 238: 'Handgun', 239: 'Harbor seal', 240: 'Harmonica', 241: 'Harp', 242: 'Harpsichord', 243: 'Hat', 244: 'Headphones', 245: 'Heater', 246: 'Hedgehog', 247: 'Helicopter', 248: 'Helmet', 249: 'High heels', 250: 'Hiking equipment', 251: 'Hippopotamus', 252: 'Home appliance', 253: 'Honeycomb', 254: 'Horizontal bar', 255: 'Horse', 256: 'Hot dog', 257: 'House', 258: 'Houseplant', 259: 'Human arm', 260: 'Human beard', 261: 'Human body', 262: 'Human ear', 263: 'Human eye', 264: 'Human face', 265: 'Human foot', 266: 'Human hair', 267: 'Human hand', 268: 'Human head', 269: 'Human leg', 270: 'Human mouth', 271: 'Human nose', 272: 'Humidifier', 273: 'Ice cream', 274: 'Indoor rower', 275: 'Infant bed', 276: 'Insect', 277: 'Invertebrate', 278: 'Ipod', 279: 'Isopod', 280: 'Jacket', 281: 'Jacuzzi', 282: 'Jaguar (Animal)', 283: 'Jeans', 284: 'Jellyfish', 285: 'Jet ski', 286: 'Jug', 287: 'Juice', 288: 'Kangaroo', 289: 'Kettle', 290: 'Kitchen & dining room table', 291: 'Kitchen appliance', 292: 'Kitchen knife', 293: 'Kitchen utensil', 294: 'Kitchenware', 295: 'Kite', 296: 'Knife', 297: 'Koala', 298: 'Ladder', 299: 'Ladle', 300: 'Ladybug', 301: 'Lamp', 302: 'Land vehicle', 303: 'Lantern', 304: 'Laptop', 305: 'Lavender (Plant)', 306: 'Lemon', 307: 'Leopard', 308: 'Light bulb', 309: 'Light switch', 310: 'Lighthouse', 311: 'Lily', 312: 'Limousine', 313: 'Lion', 314: 'Lipstick', 315: 'Lizard', 316: 'Lobster', 317: 'Loveseat', 318: 'Luggage and bags', 319: 'Lynx', 320: 'Magpie', 321: 'Mammal', 322: 'Man', 323: 'Mango', 324: 'Maple', 325: 'Maracas', 326: 'Marine invertebrates', 327: 'Marine mammal', 328: 'Measuring cup', 329: 'Mechanical fan', 330: 'Medical equipment', 331: 'Microphone', 332: 'Microwave oven', 333: 'Milk', 334: 'Miniskirt', 335: 'Mirror', 336: 'Missile', 337: 'Mixer', 338: 'Mixing bowl', 339: 'Mobile phone', 340: 'Monkey', 341: 'Moths and butterflies', 342: 'Motorcycle', 343: 'Mouse', 344: 'Muffin', 345: 'Mug', 346: 'Mule', 347: 'Mushroom', 348: 'Musical instrument', 349: 'Musical keyboard', 350: 'Nail (Construction)', 351: 'Necklace', 352: 'Nightstand', 353: 'Oboe', 354: 'Office building', 355: 'Office supplies', 356: 'Orange', 357: 'Organ (Musical Instrument)', 358: 'Ostrich', 359: 'Otter', 360: 'Oven', 361: 'Owl', 362: 'Oyster', 363: 'Paddle', 364: 'Palm tree', 365: 'Pancake', 366: 'Panda', 367: 'Paper cutter', 368: 'Paper towel', 369: 'Parachute', 370: 'Parking meter', 371: 'Parrot', 372: 'Pasta', 373: 'Pastry', 374: 'Peach', 375: 'Pear', 376: 'Pen', 377: 'Pencil case', 378: 'Pencil sharpener', 379: 'Penguin', 380: 'Perfume', 381: 'Person', 382: 'Personal care', 383: 'Personal flotation device', 384: 'Piano', 385: 'Picnic basket', 386: 'Picture frame', 387: 'Pig', 388: 'Pillow', 389: 'Pineapple', 390: 'Pitcher (Container)', 391: 'Pizza', 392: 'Pizza cutter', 393: 'Plant', 394: 'Plastic bag', 395: 'Plate', 396: 'Platter', 397: 'Plumbing fixture', 398: 'Polar bear', 399: 'Pomegranate', 400: 'Popcorn', 401: 'Porch', 402: 'Porcupine', 403: 'Poster', 404: 'Potato', 405: 'Power plugs and sockets', 406: 'Pressure cooker', 407: 'Pretzel', 408: 'Printer', 409: 'Pumpkin', 410: 'Punching bag', 411: 'Rabbit', 412: 'Raccoon', 413: 'Racket', 414: 'Radish', 415: 'Ratchet (Device)', 416: 'Raven', 417: 'Rays and skates', 418: 'Red panda', 419: 'Refrigerator', 420: 'Remote control', 421: 'Reptile', 422: 'Rhinoceros', 423: 'Rifle', 424: 'Ring binder', 425: 'Rocket', 426: 'Roller skates', 427: 'Rose', 428: 'Rugby ball', 429: 'Ruler', 430: 'Salad', 431: 'Salt and pepper shakers', 432: 'Sandal', 433: 'Sandwich', 434: 'Saucer', 435: 'Saxophone', 436: 'Scale', 437: 'Scarf', 438: 'Scissors', 439: 'Scoreboard', 440: 'Scorpion', 441: 'Screwdriver', 442: 'Sculpture', 443: 'Sea lion', 444: 'Sea turtle', 445: 'Seafood', 446: 'Seahorse', 447: 'Seat belt', 448: 'Segway', 449: 'Serving tray', 450: 'Sewing machine', 451: 'Shark', 452: 'Sheep', 453: 'Shelf', 454: 'Shellfish', 455: 'Shirt', 456: 'Shorts', 457: 'Shotgun', 458: 'Shower', 459: 'Shrimp', 460: 'Sink', 461: 'Skateboard', 462: 'Ski', 463: 'Skirt', 464: 'Skull', 465: 'Skunk', 466: 'Skyscraper', 467: 'Slow cooker', 468: 'Snack', 469: 'Snail', 470: 'Snake', 471: 'Snowboard', 472: 'Snowman', 473: 'Snowmobile', 474: 'Snowplow', 475: 'Soap dispenser', 476: 'Sock', 477: 'Sofa bed', 478: 'Sombrero', 479: 'Sparrow', 480: 'Spatula', 481: 'Spice rack', 482: 'Spider', 483: 'Spoon', 484: 'Sports equipment', 485: 'Sports uniform', 486: 'Squash (Plant)', 487: 'Squid', 488: 'Squirrel', 489: 'Stairs', 490: 'Stapler', 491: 'Starfish', 492: 'Stationary bicycle', 493: 'Stethoscope', 494: 'Stool', 495: 'Stop sign', 496: 'Strawberry', 497: 'Street light', 498: 'Stretcher', 499: 'Studio couch', 500: 'Submarine', 501: 'Submarine sandwich', 502: 'Suit', 503: 'Suitcase', 504: 'Sun hat', 505: 'Sunglasses', 506: 'Surfboard', 507: 'Sushi', 508: 'Swan', 509: 'Swim cap', 510: 'Swimming pool', 511: 'Swimwear', 512: 'Sword', 513: 'Syringe', 514: 'Table', 515: 'Table tennis racket', 516: 'Tablet computer', 517: 'Tableware', 518: 'Taco', 519: 'Tank', 520: 'Tap', 521: 'Tart', 522: 'Taxi', 523: 'Tea', 524: 'Teapot', 525: 'Teddy bear', 526: 'Telephone', 527: 'Television', 528: 'Tennis ball', 529: 'Tennis racket', 530: 'Tent', 531: 'Tiara', 532: 'Tick', 533: 'Tie', 534: 'Tiger', 535: 'Tin can', 536: 'Tire', 537: 'Toaster', 538: 'Toilet', 539: 'Toilet paper', 540: 'Tomato', 541: 'Tool', 542: 'Toothbrush', 543: 'Torch', 544: 'Tortoise', 545: 'Towel', 546: 'Tower', 547: 'Toy', 548: 'Traffic light', 549: 'Traffic sign', 550: 'Train', 551: 'Training bench', 552: 'Treadmill', 553: 'Tree', 554: 'Tree house', 555: 'Tripod', 556: 'Trombone', 557: 'Trousers', 558: 'Truck', 559: 'Trumpet', 560: 'Turkey', 561: 'Turtle', 562: 'Umbrella', 563: 'Unicycle', 564: 'Van', 565: 'Vase', 566: 'Vegetable', 567: 'Vehicle', 568: 'Vehicle registration plate', 569: 'Violin', 570: 'Volleyball (Ball)', 571: 'Waffle', 572: 'Waffle iron', 573: 'Wall clock', 574: 'Wardrobe', 575: 'Washing machine', 576: 'Waste container', 577: 'Watch', 578: 'Watercraft', 579: 'Watermelon', 580: 'Weapon', 581: 'Whale', 582: 'Wheel', 583: 'Wheelchair', 584: 'Whisk', 585: 'Whiteboard', 586: 'Willow', 587: 'Window', 588: 'Window blind', 589: 'Wine', 590: 'Wine glass', 591: 'Wine rack', 592: 'Winter melon', 593: 'Wok', 594: 'Woman', 595: 'Wood-burning stove', 596: 'Woodpecker', 597: 'Worm', 598: 'Wrench', 599: 'Zebra', 600: 'Zucchini'}\n",
      "obb: None\n",
      "orig_img: array([[[ 60,  85, 101],\n",
      "        [ 57,  88, 119],\n",
      "        [ 34,  75, 124],\n",
      "        ...,\n",
      "        [253, 255, 255],\n",
      "        [253, 255, 255],\n",
      "        [255, 255, 254]],\n",
      "\n",
      "       [[ 61,  88, 108],\n",
      "        [ 57,  94, 120],\n",
      "        [ 38,  81, 120],\n",
      "        ...,\n",
      "        [235, 241, 240],\n",
      "        [236, 243, 240],\n",
      "        [238, 244, 239]],\n",
      "\n",
      "       [[ 26,  58,  81],\n",
      "        [ 20,  58,  82],\n",
      "        [ 14,  58,  81],\n",
      "        ...,\n",
      "        [143, 157, 155],\n",
      "        [134, 147, 145],\n",
      "        [148, 160, 154]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  8,  71, 129],\n",
      "        [ 10,  72, 132],\n",
      "        [ 14,  75, 137],\n",
      "        ...,\n",
      "        [ 19,  56,  90],\n",
      "        [ 27,  64,  98],\n",
      "        [ 11,  47,  83]],\n",
      "\n",
      "       [[ 11,  75, 130],\n",
      "        [ 12,  76, 131],\n",
      "        [ 19,  82, 140],\n",
      "        ...,\n",
      "        [ 22,  59,  97],\n",
      "        [ 17,  57,  92],\n",
      "        [ 12,  55,  88]],\n",
      "\n",
      "       [[ 16,  79, 137],\n",
      "        [  8,  72, 127],\n",
      "        [ 15,  79, 134],\n",
      "        ...,\n",
      "        [ 22,  61, 100],\n",
      "        [ 17,  59,  96],\n",
      "        [ 18,  60,  95]]], dtype=uint8)\n",
      "orig_shape: (382, 1024)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict'\n",
      "speed: {'preprocess': 4.050016403198242, 'inference': 349.9455451965332, 'postprocess': 1.0001659393310547}]\n"
     ]
    }
   ],
   "source": [
    "img_path = \"C:/Users/Admin/fiftyone/open-images-v7/train/data/0207ea1877c62bf1.jpg\"\n",
    "\n",
    "img_cv2 = cv2.imread(img_path)\n",
    "\n",
    "results = model(source=img_cv2, conf=0.5)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ObjID': '04dd8510015ed600_1', 'ImgID': '04dd8510015ed600', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/04dd8510015ed600_hist.txt'}\n",
      "{'ObjID': '0c37b2fb66423018_122', 'ImgID': '0c37b2fb66423018', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0c37b2fb66423018_hist.txt'}\n",
      "{'ObjID': '0c37b2fb66423018_147', 'ImgID': '0c37b2fb66423018', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0c37b2fb66423018_hist.txt'}\n",
      "{'ObjID': '0c37b2fb66423018_172', 'ImgID': '0c37b2fb66423018', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0c37b2fb66423018_hist.txt'}\n",
      "{'ObjID': '0c37b2fb66423018_199', 'ImgID': '0c37b2fb66423018', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0c37b2fb66423018_hist.txt'}\n",
      "{'ObjID': '0c37b2fb66423018_231', 'ImgID': '0c37b2fb66423018', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0c37b2fb66423018_hist.txt'}\n",
      "{'ObjID': '0c37b2fb66423018_264', 'ImgID': '0c37b2fb66423018', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0c37b2fb66423018_hist.txt'}\n",
      "{'ObjID': '0c37b2fb66423018_295', 'ImgID': '0c37b2fb66423018', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0c37b2fb66423018_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_58', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_59', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_60', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_85', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_87', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_88', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_89', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_113', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_116', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_141', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_142', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_170', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '1cefef01a98feca0_206', 'ImgID': '1cefef01a98feca0', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/1cefef01a98feca0_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_65', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_73', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_183', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_184', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_185', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_187', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_190', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_211', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_216', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_217', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_223', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_224', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_225', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_226', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_227', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_228', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_229', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_230', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_231', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_232', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_233', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_234', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_235', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_236', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_237', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_241', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_242', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_243', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_260', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_261', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_262', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_263', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_277', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_278', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_279', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_281', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_283', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_295', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_296', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '20d684f4f484c017_297', 'ImgID': '20d684f4f484c017', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/20d684f4f484c017_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_16', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_17', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_44', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_45', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_47', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_48', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_49', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_60', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_62', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_63', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_64', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_65', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_82', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_84', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_85', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_86', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_87', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_112', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_113', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_114', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_138', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_139', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_140', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_141', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_167', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_168', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_169', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_194', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_195', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_196', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_197', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_224', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_225', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_226', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_227', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_254', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_255', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_256', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_257', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_258', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_281', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_282', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_283', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_284', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_285', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_286', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_287', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_288', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_289', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_290', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_291', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_292', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_293', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_294', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_295', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_296', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_297', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_298', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_299', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '2e434532b3491702_300', 'ImgID': '2e434532b3491702', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/2e434532b3491702_hist.txt'}\n",
      "{'ObjID': '31705f96656f6e59_1', 'ImgID': '31705f96656f6e59', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/31705f96656f6e59_hist.txt'}\n",
      "{'ObjID': '3307bdbcfcf72a45_1', 'ImgID': '3307bdbcfcf72a45', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3307bdbcfcf72a45_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_27', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_28', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_29', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_30', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_31', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_32', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_33', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_52', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_53', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_54', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_55', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_56', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_57', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_58', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_59', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_60', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_61', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_62', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_63', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_64', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_65', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_66', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_67', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_68', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_69', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_70', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_71', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_72', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_73', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_74', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_75', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_76', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_77', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_78', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_79', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_80', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_81', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_82', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_83', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_84', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_85', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_86', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_87', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_96', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_104', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_105', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_106', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_107', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_108', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_109', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_110', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_111', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_112', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_113', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_114', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_115', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_116', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_117', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_118', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_119', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_120', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_121', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_122', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_123', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_124', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_125', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_126', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_127', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_128', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_129', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_130', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_131', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_132', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_133', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_134', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_135', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_136', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_137', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_138', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_139', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_140', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_141', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_144', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_145', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_146', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_173', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_174', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_175', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_176', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_177', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_178', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_179', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_180', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_181', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_182', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_183', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_184', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_185', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_186', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_187', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_188', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_189', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_191', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_192', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_193', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_194', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_222', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_223', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_224', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_225', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_226', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_227', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_228', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_229', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_230', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_231', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_232', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_233', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_234', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_235', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_236', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_237', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_238', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_239', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_240', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_267', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_268', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_269', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_270', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_271', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_272', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_273', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_274', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_275', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_276', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_277', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_278', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_279', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_280', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_281', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_282', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '3494ed22c1e051b7_283', 'ImgID': '3494ed22c1e051b7', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3494ed22c1e051b7_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_1', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_2', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_3', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_32', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_33', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_35', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_59', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_60', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_61', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_62', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_64', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_65', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_66', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_67', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_68', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_69', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_70', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_71', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_72', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_73', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_74', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_75', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_76', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_77', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_78', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_79', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_80', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_81', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_82', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_83', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_84', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_85', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_86', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_87', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_88', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_89', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_90', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_91', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_92', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_93', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_94', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_95', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_96', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_97', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_98', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_99', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_100', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_101', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_102', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_103', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_104', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_105', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_106', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_107', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_108', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_109', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_110', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_111', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_112', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_113', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_114', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_115', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_116', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_117', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_118', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_119', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_120', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_121', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_122', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_123', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_124', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_125', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_126', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_127', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_128', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_129', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_130', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_131', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_132', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_133', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_134', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_135', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_136', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_137', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_138', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_139', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_140', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_141', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_142', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_143', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_144', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_145', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_146', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_147', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_148', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_149', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_150', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_151', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_152', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_153', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_154', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_155', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_156', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_157', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_158', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_159', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_160', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_161', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_162', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_163', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_164', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_165', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_166', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_167', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_168', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_169', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_170', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_171', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_172', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_173', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_174', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_175', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_176', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_177', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_178', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_179', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_180', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_181', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_182', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_183', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_184', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_185', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_186', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_187', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_188', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_189', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_190', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_191', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_196', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_197', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_198', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_199', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_200', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_215', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_216', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_217', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_218', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_219', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_220', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_221', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_222', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38920716f0f0f8a3_223', 'ImgID': '38920716f0f0f8a3', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38920716f0f0f8a3_hist.txt'}\n",
      "{'ObjID': '38c7e5d0926a8e46_4', 'ImgID': '38c7e5d0926a8e46', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38c7e5d0926a8e46_hist.txt'}\n",
      "{'ObjID': '38c7e5d0926a8e46_225', 'ImgID': '38c7e5d0926a8e46', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38c7e5d0926a8e46_hist.txt'}\n",
      "{'ObjID': '38c7e5d0926a8e46_248', 'ImgID': '38c7e5d0926a8e46', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38c7e5d0926a8e46_hist.txt'}\n",
      "{'ObjID': '38c7e5d0926a8e46_265', 'ImgID': '38c7e5d0926a8e46', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/38c7e5d0926a8e46_hist.txt'}\n",
      "{'ObjID': '3a7dc4954067bf04_272', 'ImgID': '3a7dc4954067bf04', 'Class': 'Accordion', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/3a7dc4954067bf04_hist.txt'}\n"
     ]
    }
   ],
   "source": [
    "for bovw in list_bovw:\n",
    "    if bovw[\"Class\"] == \"Accordion\":\n",
    "        print(bovw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 386.4ms\n",
      "Speed: 718.9ms preprocess, 386.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Footwear, 1 Man, 72.2ms\n",
      "Speed: 7.0ms preprocess, 72.2ms inference, 3.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x480 (no detections), 86.5ms\n",
      "Speed: 0.0ms preprocess, 86.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 7 Mans, 9 Womans, 80.7ms\n",
      "Speed: 3.5ms preprocess, 80.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x384 1 Toy, 64.1ms\n",
      "Speed: 0.0ms preprocess, 64.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 448x640 1 Car, 74.4ms\n",
      "Speed: 6.0ms preprocess, 74.4ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 4 Persons, 83.2ms\n",
      "Speed: 2.4ms preprocess, 83.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Window, 71.8ms\n",
      "Speed: 0.0ms preprocess, 71.8ms inference, 8.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Human face, 1 Man, 90.0ms\n",
      "Speed: 0.0ms preprocess, 90.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 House, 81.0ms\n",
      "Speed: 2.5ms preprocess, 81.0ms inference, 8.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[{'ObjID': '0000286a5c6a3eb5_1', 'ImgID': '0000286a5c6a3eb5', 'Class': 'Man', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0000286a5c6a3eb5_hist.txt'}, {'ObjID': '0000286a5c6a3eb5_2', 'ImgID': '0000286a5c6a3eb5', 'Class': 'Footwear', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0000286a5c6a3eb5_hist.txt'}, {'ObjID': '000045257f66b9e2_1', 'ImgID': '000045257f66b9e2', 'Class': 'Man', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_2', 'ImgID': '000045257f66b9e2', 'Class': 'Man', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_3', 'ImgID': '000045257f66b9e2', 'Class': 'Man', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_4', 'ImgID': '000045257f66b9e2', 'Class': 'Woman', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_5', 'ImgID': '000045257f66b9e2', 'Class': 'Woman', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_6', 'ImgID': '000045257f66b9e2', 'Class': 'Woman', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_7', 'ImgID': '000045257f66b9e2', 'Class': 'Man', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_8', 'ImgID': '000045257f66b9e2', 'Class': 'Man', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_9', 'ImgID': '000045257f66b9e2', 'Class': 'Woman', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_10', 'ImgID': '000045257f66b9e2', 'Class': 'Woman', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_11', 'ImgID': '000045257f66b9e2', 'Class': 'Woman', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_12', 'ImgID': '000045257f66b9e2', 'Class': 'Woman', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_13', 'ImgID': '000045257f66b9e2', 'Class': 'Man', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_14', 'ImgID': '000045257f66b9e2', 'Class': 'Woman', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_15', 'ImgID': '000045257f66b9e2', 'Class': 'Man', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '000045257f66b9e2_16', 'ImgID': '000045257f66b9e2', 'Class': 'Woman', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000045257f66b9e2_hist.txt'}, {'ObjID': '0000530c47410921_1', 'ImgID': '0000530c47410921', 'Class': 'Toy', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0000530c47410921_hist.txt'}, {'ObjID': '00005bf623ff1ac2_1', 'ImgID': '00005bf623ff1ac2', 'Class': 'Car', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/00005bf623ff1ac2_hist.txt'}, {'ObjID': '00009cadede2ed69_1', 'ImgID': '00009cadede2ed69', 'Class': 'Person', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/00009cadede2ed69_hist.txt'}, {'ObjID': '00009cadede2ed69_2', 'ImgID': '00009cadede2ed69', 'Class': 'Person', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/00009cadede2ed69_hist.txt'}, {'ObjID': '00009cadede2ed69_3', 'ImgID': '00009cadede2ed69', 'Class': 'Person', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/00009cadede2ed69_hist.txt'}, {'ObjID': '00009cadede2ed69_4', 'ImgID': '00009cadede2ed69', 'Class': 'Person', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/00009cadede2ed69_hist.txt'}, {'ObjID': '0000a54dd13a67a7_1', 'ImgID': '0000a54dd13a67a7', 'Class': 'Window', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0000a54dd13a67a7_hist.txt'}, {'ObjID': '0000d01325742829_1', 'ImgID': '0000d01325742829', 'Class': 'Human face', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0000d01325742829_hist.txt'}, {'ObjID': '0000d01325742829_2', 'ImgID': '0000d01325742829', 'Class': 'Man', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/0000d01325742829_hist.txt'}, {'ObjID': '000123034b89f3df_1', 'ImgID': '000123034b89f3df', 'Class': 'House', 'Feature': 'C:/Users/Admin/OneDrive - Hochiminh City University of Education/Documents/Y3_TXA_NDTN/YOLO/bovw/hist/000123034b89f3df_hist.txt'}]\n"
     ]
    }
   ],
   "source": [
    "img_paths = glob(\"C:/Users/Admin/fiftyone/open-images-v7/train/data/*.jpg\")\n",
    "list_objs = []\n",
    "\n",
    "for img_path in img_paths[0:10]:\n",
    "    objs = get_item_from_img(img_path, model)\n",
    "    if objs is not None:\n",
    "        list_objs.extend(objs)\n",
    "\n",
    "print(list_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3050 Laptop GPU'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
