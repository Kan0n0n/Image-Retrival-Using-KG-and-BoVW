{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz\n",
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Person', 'Clothing', 'Plant', 'Human body', 'Tree', 'Vehicle', 'Building', 'Land vehicle', 'Animal', 'Footwear']\n"
     ]
    }
   ],
   "source": [
    "images_freq = pd.read_csv(\"../data_files/number_of_images_per_parent.csv\")\n",
    "images_freq = images_freq[:10]\n",
    "classes = images_freq[\"Parent\"].tolist()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to 'C:\\Users\\Admin\\fiftyone\\open-images-v7\\validation' if necessary\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading existing dataset 'open-images-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "# Load the Open Images V7 validation split with detections\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"open-images-v7\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"detections\"],\n",
    "    dataset_name=\"open-images-validation\",\n",
    "    shuffle=True,  # Randomize the order for varied selection\n",
    "    seed=51,       # For reproducibility\n",
    "    classes=classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        open-images-validation\n",
      "Media type:  image\n",
      "Num samples: 19208\n",
      "Persistent:  False\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image download and organization complete!\n"
     ]
    }
   ],
   "source": [
    "# Create a base directory to store class folders\n",
    "base_dir = \"open_images_classes\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Process each class\n",
    "for class_name in classes:\n",
    "    # Create a folder for this class\n",
    "    class_dir = os.path.join(base_dir, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "    # Filter dataset for samples with at least one detection of this class\n",
    "    view = dataset.match(F(\"detections.detections\").filter(F(\"label\") == class_name).length() > 0)\n",
    "\n",
    "    # Take up to 500 samples (or fewer if less are available)\n",
    "    samples = view[:500]\n",
    "\n",
    "    # Copy each sample's image to the class folder\n",
    "    for sample in samples:\n",
    "        src_path = sample.filepath  # Path to the downloaded image\n",
    "        dst_path = os.path.join(class_dir, f\"{sample.id}.jpg\")  # Unique filename using sample ID\n",
    "        shutil.copyfile(src_path, dst_path)\n",
    "\n",
    "print(\"Image download and organization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Person has 7144 samples\n",
      " 100% |█████████████████| 100/100 [380.0ms elapsed, 0s remaining, 263.1 samples/s]      \n",
      "Exported Person to open_images_classes_1/Person\n",
      "Class: Clothing has 6626 samples\n",
      " 100% |█████████████████| 100/100 [606.0ms elapsed, 0s remaining, 165.0 samples/s]      \n",
      "Exported Clothing to open_images_classes_1/Clothing\n",
      "Class: Plant has 3838 samples\n",
      " 100% |█████████████████| 100/100 [859.9ms elapsed, 0s remaining, 116.3 samples/s]      \n",
      "Exported Plant to open_images_classes_1/Plant\n",
      "Class: Human body has 5686 samples\n",
      " 100% |█████████████████| 100/100 [533.2ms elapsed, 0s remaining, 187.5 samples/s]      \n",
      "Exported Human body to open_images_classes_1/Human body\n",
      "Class: Tree has 3611 samples\n",
      " 100% |█████████████████| 100/100 [856.8ms elapsed, 0s remaining, 116.7 samples/s]      \n",
      "Exported Tree to open_images_classes_1/Tree\n",
      "Class: Vehicle has 1545 samples\n",
      " 100% |█████████████████| 100/100 [866.7ms elapsed, 0s remaining, 115.4 samples/s]      \n",
      "Exported Vehicle to open_images_classes_1/Vehicle\n",
      "Class: Building has 1884 samples\n",
      " 100% |█████████████████| 100/100 [799.0ms elapsed, 0s remaining, 125.2 samples/s]      \n",
      "Exported Building to open_images_classes_1/Building\n",
      "Class: Land vehicle has 1720 samples\n",
      " 100% |█████████████████| 100/100 [681.0ms elapsed, 0s remaining, 146.9 samples/s]      \n",
      "Exported Land vehicle to open_images_classes_1/Land vehicle\n",
      "Class: Animal has 211 samples\n",
      " 100% |█████████████████| 100/100 [1.0s elapsed, 0s remaining, 95.6 samples/s]          \n",
      "Exported Animal to open_images_classes_1/Animal\n",
      "Class: Footwear has 1907 samples\n",
      " 100% |█████████████████| 100/100 [773.0ms elapsed, 0s remaining, 129.4 samples/s]      \n",
      "Exported Footwear to open_images_classes_1/Footwear\n"
     ]
    }
   ],
   "source": [
    "label_f = \"ground_truth\"\n",
    "base_dir = \"open_images_classes_1\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "for cls in classes:\n",
    "    view = dataset.filter_labels(label_f, fo.ViewField(\"label\") == cls)\n",
    "    print(f\"Class: {cls} has {len(view)} samples\")\n",
    "    export_dir = f\"{base_dir}/{cls}\"\n",
    "    view = view[:100]\n",
    "    \n",
    "    view.export(export_dir, dataset_type=fo.types.YOLOv5Dataset, label_field=label_f)\n",
    "    print(f\"Exported {cls} to {export_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████████| 64/64 [3.0s elapsed, 0s remaining, 21.3 samples/s]      \n",
      " 100% |█████████████████████| 1/1 [2.6s elapsed, 0s remaining, 0.4 samples/s] \n",
      " 100% |█████████████████████| 6/6 [2.5s elapsed, 0s remaining, 2.4 samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.3s elapsed, 0s remaining, 0.4 samples/s] \n",
      " 100% |███████████████████| 14/14 [2.1s elapsed, 0s remaining, 6.7 samples/s] \n",
      " 100% |█████████████████████| 8/8 [2.0s elapsed, 0s remaining, 4.1 samples/s] \n",
      " 100% |███████████████████| 13/13 [2.0s elapsed, 0s remaining, 6.4 samples/s] \n",
      " 100% |█████████████████████| 0/0 [2.0s elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.1s elapsed, 0s remaining, 0.5 samples/s] \n",
      " 100% |█████████████████████| 8/8 [2.1s elapsed, 0s remaining, 3.9 samples/s] \n",
      " 100% |█████████████████████| 9/9 [2.0s elapsed, 0s remaining, 4.5 samples/s] \n",
      " 100% |█████████████████████| 0/0 [2.0s elapsed, ? remaining, ? samples/s] \n",
      " 100% |███████████████████| 11/11 [2.0s elapsed, 0s remaining, 5.4 samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.0s elapsed, 0s remaining, 0.5 samples/s] \n",
      " 100% |█████████████████████| 2/2 [2.1s elapsed, 0s remaining, 1.0 samples/s] \n",
      " 100% |█████████████████████| 4/4 [2.0s elapsed, 0s remaining, 2.0 samples/s] \n",
      " 100% |█████████████████████| 4/4 [2.0s elapsed, 0s remaining, 2.0 samples/s] \n",
      " 100% |█████████████████████| 1/1 [1.9s elapsed, 0s remaining, 0.5 samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.1s elapsed, 0s remaining, 0.5 samples/s] \n",
      " 100% |█████████████████████| 8/8 [2.1s elapsed, 0s remaining, 3.8 samples/s] \n",
      " 100% |█████████████████████| 0/0 [2.0s elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 0/0 [2.0s elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 4/4 [2.0s elapsed, 0s remaining, 2.0 samples/s] \n",
      " 100% |█████████████████████| 6/6 [2.0s elapsed, 0s remaining, 3.0 samples/s] \n",
      " 100% |█████████████████████| 5/5 [2.0s elapsed, 0s remaining, 2.5 samples/s] \n",
      " 100% |█████████████████████| 5/5 [2.0s elapsed, 0s remaining, 2.5 samples/s] \n",
      " 100% |█████████████████████| 8/8 [2.0s elapsed, 0s remaining, 4.0 samples/s] \n",
      " 100% |█████████████████████| 3/3 [2.0s elapsed, 0s remaining, 1.5 samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.0s elapsed, 0s remaining, 0.5 samples/s] \n",
      " 100% |█████████████████████| 0/0 [2.0s elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 0/0 [2.0s elapsed, ? remaining, ? samples/s] \n",
      " 100% |███████████████████| 15/15 [2.2s elapsed, 0s remaining, 6.8 samples/s] \n",
      " 100% |█████████████████████| 5/5 [2.1s elapsed, 0s remaining, 2.4 samples/s] \n",
      " 100% |█████████████████████| 9/9 [2.2s elapsed, 0s remaining, 4.1 samples/s] \n",
      " 100% |█████████████████████| 1/1 [1.9s elapsed, 0s remaining, 0.5 samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.0s elapsed, 0s remaining, 0.5 samples/s] \n",
      " 100% |█████████████████████| 0/0 [1.9s elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 5/5 [2.0s elapsed, 0s remaining, 2.5 samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.0s elapsed, 0s remaining, 0.5 samples/s] \n",
      " 100% |█████████████████████| 1/1 [1.9s elapsed, 0s remaining, 0.5 samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.1s elapsed, 0s remaining, 0.5 samples/s] \n",
      " 100% |███████████████| 1685/1685 [10.9s elapsed, 0s remaining, 190.7 samples/s]      \n",
      " 100% |█████████████████████| 0/0 [2.2s elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.1s elapsed, 0s remaining, 0.5 samples/s] \n",
      " 100% |███████████████████| 10/10 [2.5s elapsed, 0s remaining, 3.9 samples/s] \n",
      " 100% |█████████████████████| 0/0 [2.2s elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.1s elapsed, 0s remaining, 0.5 samples/s] \n",
      " 100% |███████████████████| 23/23 [2.7s elapsed, 0s remaining, 8.5 samples/s]      \n",
      " 100% |█████████████████████| 9/9 [2.4s elapsed, 0s remaining, 3.7 samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.3s elapsed, 0s remaining, 0.4 samples/s] \n",
      " 100% |███████████████████| 13/13 [2.3s elapsed, 0s remaining, 5.7 samples/s] \n",
      " 100% |█████████████████████| 3/3 [2.5s elapsed, 0s remaining, 1.2 samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.4s elapsed, 0s remaining, 0.4 samples/s] \n",
      " 100% |███████████████████| 10/10 [2.4s elapsed, 0s remaining, 4.2 samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.3s elapsed, 0s remaining, 0.4 samples/s] \n",
      " 100% |█████████████████████| 2/2 [2.3s elapsed, 0s remaining, 0.9 samples/s] \n",
      " 100% |███████████████████| 14/14 [2.8s elapsed, 0s remaining, 5.0 samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.3s elapsed, 0s remaining, 0.4 samples/s] \n",
      " 100% |███████████████████| 19/19 [2.5s elapsed, 0s remaining, 7.5 samples/s]      \n",
      " 100% |█████████████████████| 2/2 [2.7s elapsed, 0s remaining, 0.8 samples/s] \n",
      " 100% |███████████████████| 20/20 [2.8s elapsed, 0s remaining, 7.2 samples/s]      \n",
      " 100% |█████████████████████| 2/2 [2.5s elapsed, 0s remaining, 0.8 samples/s] \n",
      " 100% |█████████████████████| 3/3 [2.7s elapsed, 0s remaining, 1.1 samples/s] \n",
      " 100% |█████████████████████| 8/8 [2.6s elapsed, 0s remaining, 3.1 samples/s] \n",
      " 100% |█████████████████████| 2/2 [2.4s elapsed, 0s remaining, 0.8 samples/s] \n",
      " 100% |█████████████████████| 2/2 [2.2s elapsed, 0s remaining, 0.9 samples/s] \n",
      " 100% |█████████████████████| 3/3 [2.2s elapsed, 0s remaining, 1.4 samples/s] \n",
      " 100% |███████████████████| 10/10 [2.3s elapsed, 0s remaining, 4.3 samples/s] \n",
      " 100% |█████████████████████| 2/2 [2.4s elapsed, 0s remaining, 0.8 samples/s] \n",
      " 100% |█████████████████████| 4/4 [2.3s elapsed, 0s remaining, 1.8 samples/s] \n",
      " 100% |█████████████████████| 3/3 [2.2s elapsed, 0s remaining, 1.3 samples/s] \n",
      " 100% |███████████████████| 14/14 [2.3s elapsed, 0s remaining, 6.2 samples/s] \n",
      " 100% |█████████████████████| 7/7 [2.2s elapsed, 0s remaining, 3.1 samples/s] \n",
      " 100% |█████████████████████| 9/9 [2.3s elapsed, 0s remaining, 3.8 samples/s] \n",
      " 100% |█████████████████████| 1/1 [2.3s elapsed, 0s remaining, 0.4 samples/s] \n",
      " 100% |█████████████████████| 7/7 [2.1s elapsed, 0s remaining, 3.4 samples/s] \n",
      " 100% |█████████████████████| 0/0 [2.1s elapsed, ? remaining, ? samples/s] \n",
      " 100% |█████████████████████| 3/3 [2.3s elapsed, 0s remaining, 1.3 samples/s] \n"
     ]
    }
   ],
   "source": [
    "subsets = []\n",
    "with open(\"../data_files/classes_with_none_objects.json\", \"r\") as f:\n",
    "    subsets = json.load(f)\n",
    "\n",
    "label_field = \"ground_truth\"\n",
    "\n",
    "base_export_dir = \"./main/dataset\"\n",
    "\n",
    "for cls in subsets:\n",
    "    view = dataset.filter_labels(label_field, fo.ViewField(\"label\") == cls)\n",
    "    export_dir = f\"{base_export_dir}/{cls}\"\n",
    "\n",
    "    view.export(\n",
    "        export_dir=export_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        label_field=label_field,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = []\n",
    "for cls in subsets:\n",
    "    img_path = glob(f\"./main/dataset/{cls}/images/val/*.jpg\")\n",
    "    for path in img_path:\n",
    "        img_ids.append(path.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1])\n",
    "\n",
    "img_path_none_detect = []\n",
    "with open(\"./main/img_undetected.json\", \"r\") as f:\n",
    "    img_path_none_detect = json.load(f)\n",
    "\n",
    "img_id_none_detect = []\n",
    "for img_id in img_path_none_detect:\n",
    "    img_id_temp = img_id.split(\"/\")[-1].split(\".\")[0].split(\"\\\\\")[-1]\n",
    "    img_id_none_detect.append(img_id_temp)\n",
    "\n",
    "for img_id in img_id_none_detect:\n",
    "    if img_id in img_ids:\n",
    "        img_ids.remove(img_id)\n",
    "\n",
    "with open(\"./main/img_undected2.json\", \"w\") as f:\n",
    "    json.dump(img_ids, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
