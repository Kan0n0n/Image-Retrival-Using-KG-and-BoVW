{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Performance Analysis with YOLOv8 and Neo4j\n",
    "\n",
    "## Overview\n",
    "This notebook evaluates the performance of YOLOv8 object detection model by comparing its predictions against ground truth data. The results are stored and queried using a Neo4j graph database, allowing for efficient analysis of relationships between detected objects.\n",
    "\n",
    "## Environment Setup\n",
    "- **YOLOv8**: Using the 'yolov8x-oiv7.pt' model for object detection\n",
    "- **Neo4j**: Graph database for storing and querying image-object relationships\n",
    "- **Database Connection**: Using local Neo4j instance (localhost:7687)\n",
    "\n",
    "## Data Sources\n",
    "- `ground_truth_top_level.csv`: Contains ground truth annotations\n",
    "- `objects_extract_smaller_set.csv`: Object detection results\n",
    "- `parent_map.csv`: Hierarchical mapping between object classes\n",
    "- `child_map.csv`: Child-parent relationships between object classes\n",
    "\n",
    "## Workflow\n",
    "1. **Data Loading**: Import CSVs containing ground truth and object detection data\n",
    "2. **Data Preprocessing**: Convert object detection descriptions to proper format\n",
    "3. **Class Hierarchy Mapping**: Map detected objects to their top-level parent classes\n",
    "4. **Neo4j Queries**: Execute queries to find images containing specific objects\n",
    "5. **Evaluation**: Calculate precision and recall metrics to evaluate model performance\n",
    "6. **Analysis**: Compare \"ALL\" vs \"ANY\" matching strategies for object detection\n",
    "\n",
    "## Key Functions\n",
    "- `get_top_parent()`: Maps object classes to their parent classes\n",
    "- `convert_to_top_level()`: Converts detailed object descriptions to top-level categories\n",
    "- `query_images()`: Finds images containing ALL specified objects\n",
    "- `query_images_any()`: Finds images containing ANY of the specified objects\n",
    "- `find_images_in_ground_truth()`: Searches ground truth data for images with specific classes\n",
    "\n",
    "## Results\n",
    "The notebook calculates precision and recall metrics for both strict (ALL) and relaxed (ANY) matching strategies to evaluate detection performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from glob import glob\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection and Model Setup\n",
    "\n",
    "This section initializes the key components needed for our analysis:\n",
    "\n",
    "### Neo4j Database Connection\n",
    "- **URI**: Connection to local Neo4j instance at `localhost:7687`\n",
    "- **Credentials**: Using default username (`neo4j`) and configured password\n",
    "\n",
    "### YOLOv8 Model\n",
    "- Loading pre-trained YOLOv8x model with Open Images V7 weights\n",
    "- This model will be used for object detection in images\n",
    "- The model contains 601 classes for diverse object recognition\n",
    "\n",
    "These components enable us to:\n",
    "1. Run object detection on images\n",
    "2. Store detection results in the graph database\n",
    "3. Query relationships between images and detected objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = \"neo4j://localhost:7687\"  \n",
    "USERNAME = \"neo4j\"            \n",
    "PASSWORD = \"Tai123321\"     \n",
    "model = YOLO('yolov8x-oiv7.pt') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv(\"ground_truth.csv\")\n",
    "object_detection = pd.read_csv(\"./objects_extract_fixed.csv\")\n",
    "parent_map = pd.read_csv(\"parent_map.csv\")\n",
    "child_map = pd.read_csv(\"child_map.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ImageID                                        Description\n",
      "0  0000253ea4ecbf19  ['Carnivore', 'Human leg', 'Mammal', 'Plant', ...\n",
      "1  0000286a5c6a3eb5  ['Human eye', 'Sunglasses', 'Shorts', 'Person'...\n",
      "2  00003bfccf5f36c2  ['Person', 'Lantern', 'Chair', 'Table', 'Tree'...\n",
      "3  000045257f66b9e2  ['Boy', 'Person', 'Cowboy hat', 'Hat', 'Fedora...\n",
      "4  0000530c47410921          ['Toy', 'Bird', 'Duck', 'Tire', 'Animal']\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ImageID                                        Description\n",
      "0  00408efc3cabdc4e  [Food, Fast food, Waffle, Pancake, Burrito, Sn...\n",
      "1  0059eb01bba96297  [Food, Fast food, Waffle, Pancake, Burrito, Sn...\n",
      "2  0055444dd2ab3489                    [Person, Man, Woman, Boy, Girl]\n",
      "3  0028e126ab55ebfc  [Land vehicle, Person, Furniture, Clothing, Am...\n",
      "4  00336bd08f30f7f0  [Person, Human body, Clothing, Man, Woman, Boy...\n"
     ]
    }
   ],
   "source": [
    "object_detection[\"Description\"] = object_detection[\"Description\"].apply(lambda x: ast.literal_eval(x))\n",
    "print(object_detection.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Parent                                              Child\n",
      "0     Aircraft                     [Helicopter, Airplane, Rocket]\n",
      "1       Animal  [Shellfish, Bird, Invertebrate, Mammal, Reptil...\n",
      "2    Auto part  [Vehicle registration plate, Wheel, Seat belt,...\n",
      "3  Baked goods    [Pretzel, Cookie, Muffin, Bagel, Bread, Pastry]\n",
      "4         Ball  [Football, Cricket ball, Volleyball (Ball), Te...\n"
     ]
    }
   ],
   "source": [
    "child_map[\"Child\"] = child_map[\"Child\"].apply(lambda x: ast.literal_eval(x))\n",
    "print(child_map.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ImageID                                        Description\n",
      "0  0000253ea4ecbf19  [Carnivore, Human leg, Mammal, Plant, Tree, Hu...\n",
      "1  0000286a5c6a3eb5  [Human eye, Sunglasses, Shorts, Person, Human ...\n",
      "2  00003bfccf5f36c2  [Person, Lantern, Chair, Table, Tree, Furnitur...\n",
      "3  000045257f66b9e2  [Boy, Person, Cowboy hat, Hat, Fedora, Human b...\n",
      "4  0000530c47410921                    [Toy, Bird, Duck, Tire, Animal]\n"
     ]
    }
   ],
   "source": [
    "ground_truth[\"Description\"] = ground_truth[\"Description\"].apply(lambda x: ast.literal_eval(x))\n",
    "print(ground_truth.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97273, 2)\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo4j get driver function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neo4j_driver():\n",
    "    return GraphDatabase.driver(URI, auth=(USERNAME, PASSWORD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to query images in Neo4j containing all specified objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_images(sorted_classes):\n",
    "    image_ids = []\n",
    "    with get_neo4j_driver().session() as session:\n",
    "                query = \"\"\"\n",
    "                    WITH $classes AS classes\n",
    "                    MATCH (img:Image)\n",
    "                    WHERE ALL(class IN classes WHERE class IN[(img)-[:HAS_A]->(cls:Class) | cls.name]) \n",
    "                    RETURN img.image_Id AS image_id\n",
    "                \"\"\"\n",
    "                result = session.run(query, classes=list(sorted_classes))\n",
    "                for record in result:\n",
    "                    if record[\"image_id\"] not in image_ids:\n",
    "                        image_ids.append(record[\"image_id\"])\n",
    "    if image_ids:\n",
    "        return image_ids\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to query images in Neo4j containing any specified objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_images_any(sorted_classes):\n",
    "    image_ids = []\n",
    "    with get_neo4j_driver().session() as session:\n",
    "                query = \"\"\"\n",
    "                    WITH $classes AS classes\n",
    "                    MATCH (img:Image)\n",
    "                    WHERE ANY(class IN classes WHERE class IN[(img)-[:HAS_A]->(cls:Class) | cls.name])\n",
    "                    RETURN img.image_Id AS image_id\n",
    "                \"\"\"\n",
    "                result = session.run(query, classes=list(sorted_classes))\n",
    "                for record in result:\n",
    "                    if record[\"image_id\"] not in image_ids:\n",
    "                        image_ids.append(record[\"image_id\"])\n",
    "    if image_ids:\n",
    "        return image_ids\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function need fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! function need some modification\n",
    "def find_images_in_ground_truth(sorted_classes):\n",
    "    image_ids = []\n",
    "    for index, row in ground_truth.iterrows():\n",
    "        death_flag = False\n",
    "        for class_name in sorted_classes:\n",
    "            if class_name not in row[\"Top Level Classes\"]:\n",
    "                death_flag = True\n",
    "                break\n",
    "        if not death_flag:\n",
    "            image_ids.append(row[\"ImageID\"])\n",
    "    if image_ids:\n",
    "        return image_ids\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a function to get all images that contain at least one of the queried objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_in_ground_truth(classes_list):\n",
    "    image_ids = []\n",
    "    for index, row in ground_truth.iterrows():\n",
    "        for class_name in classes_list:\n",
    "            if row[\"Description\"].count(class_name) > 0:\n",
    "                image_ids.append(row[\"ImageID\"])\n",
    "                break\n",
    "    if image_ids:\n",
    "        return image_ids\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_rec_filter = pd.read_csv(\"./pre_rec_single_class_any_filtered_with_fpr.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent: Aircraft, Number of Images: 829\n",
      "Parent: Animal, Number of Images: 9592\n",
      "Parent: Auto part, Number of Images: 5142\n",
      "Parent: Baked goods, Number of Images: 835\n",
      "Parent: Ball, Number of Images: 528\n",
      "Parent: Bathroom accessory, Number of Images: 74\n",
      "Parent: Bear, Number of Images: 162\n",
      "Parent: Bed, Number of Images: 263\n",
      "Parent: Beetle, Number of Images: 148\n",
      "Parent: Bird, Number of Images: 2047\n",
      "Parent: Boat, Number of Images: 1581\n",
      "Parent: Building, Number of Images: 12404\n",
      "Parent: Car, Number of Images: 5936\n",
      "Parent: Carnivore, Number of Images: 2432\n",
      "Parent: Clock, Number of Images: 305\n",
      "Parent: Clothing, Number of Images: 36380\n",
      "Parent: Container, Number of Images: 1762\n",
      "Parent: Cosmetics, Number of Images: 114\n",
      "Parent: Couch, Number of Images: 273\n",
      "Parent: Dairy Product, Number of Images: 169\n",
      "Parent: Dessert, Number of Images: 808\n",
      "Parent: Door, Number of Images: 780\n",
      "Parent: Drink, Number of Images: 1812\n",
      "Parent: Fashion accessory, Number of Images: 3631\n",
      "Parent: Fast food, Number of Images: 1098\n",
      "Parent: Fish, Number of Images: 408\n",
      "Parent: Flower, Number of Images: 4505\n",
      "Parent: Food, Number of Images: 5132\n",
      "Parent: Footwear, Number of Images: 7648\n",
      "Parent: Fruit, Number of Images: 673\n",
      "Parent: Furniture, Number of Images: 5552\n",
      "Parent: Hat, Number of Images: 880\n",
      "Parent: Helmet, Number of Images: 878\n",
      "Parent: Home appliance, Number of Images: 239\n",
      "Parent: Human body, Number of Images: 21700\n",
      "Parent: Insect, Number of Images: 1134\n",
      "Parent: Invertebrate, Number of Images: 1367\n",
      "Parent: Kitchen appliance, Number of Images: 175\n",
      "Parent: Kitchen utensil, Number of Images: 187\n",
      "Parent: Kitchenware, Number of Images: 1082\n",
      "Parent: Land vehicle, Number of Images: 10122\n",
      "Parent: Luggage and bags, Number of Images: 203\n",
      "Parent: Mammal, Number of Images: 5768\n",
      "Parent: Marine invertebrates, Number of Images: 194\n",
      "Parent: Marine mammal, Number of Images: 207\n",
      "Parent: Medical equipment, Number of Images: 51\n",
      "Parent: Moths and butterflies, Number of Images: 447\n",
      "Parent: Musical instrument, Number of Images: 1957\n",
      "Parent: Office supplies, Number of Images: 1297\n",
      "Parent: Pastry, Number of Images: 101\n",
      "Parent: Person, Number of Images: 46552\n",
      "Parent: Personal care, Number of Images: 2959\n",
      "Parent: Plant, Number of Images: 25566\n",
      "Parent: Plumbing fixture, Number of Images: 276\n",
      "Parent: Racket, Number of Images: 109\n",
      "Parent: Reptile, Number of Images: 409\n",
      "Parent: Sandwich, Number of Images: 109\n",
      "Parent: Sculpture, Number of Images: 1227\n",
      "Parent: Shellfish, Number of Images: 135\n",
      "Parent: Skirt, Number of Images: 106\n",
      "Parent: Snack, Number of Images: 534\n",
      "Parent: Sports equipment, Number of Images: 3945\n",
      "Parent: Squash (Plant), Number of Images: 104\n",
      "Parent: Table, Number of Images: 2814\n",
      "Parent: Tableware, Number of Images: 1299\n",
      "Parent: Telephone, Number of Images: 322\n",
      "Parent: Tool, Number of Images: 615\n",
      "Parent: Toy, Number of Images: 1416\n",
      "Parent: Traffic sign, Number of Images: 189\n",
      "Parent: Tree, Number of Images: 17804\n",
      "Parent: Trousers, Number of Images: 2106\n",
      "Parent: Turtle, Number of Images: 90\n",
      "Parent: Vegetable, Number of Images: 715\n",
      "Parent: Vehicle, Number of Images: 13232\n",
      "Parent: Watercraft, Number of Images: 1715\n",
      "Parent: Weapon, Number of Images: 412\n"
     ]
    }
   ],
   "source": [
    "number_of_images_per_parent = pd.DataFrame(columns=[\"Parent\", \"Number of Images\"])\n",
    "for index, row in child_map.iterrows():\n",
    "    parent = row[\"Parent\"]\n",
    "    if parent not in pre_rec_filter[\"Class\"].values:\n",
    "        continue\n",
    "    children = row[\"Child\"]\n",
    "    children.append(parent)\n",
    "    \n",
    "    image_ids = get_image_in_ground_truth(children)\n",
    "    if image_ids is not None:\n",
    "        number_of_images_per_parent.loc[len(number_of_images_per_parent)] = [parent, len(image_ids)]\n",
    "        print(f\"Parent: {parent}, Number of Images: {len(image_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Parent  Number of Images\n",
      "50        Person             46552\n",
      "15      Clothing             36380\n",
      "52         Plant             25566\n",
      "34    Human body             21700\n",
      "69          Tree             17804\n",
      "73       Vehicle             13232\n",
      "11      Building             12404\n",
      "40  Land vehicle             10122\n",
      "1         Animal              9592\n",
      "28      Footwear              7648\n",
      "Amount of Images: 201000\n"
     ]
    }
   ],
   "source": [
    "number_of_images_per_parent = number_of_images_per_parent.sort_values(by=\"Number of Images\", ascending=False)\n",
    "number_of_images_per_parent.to_csv(\"number_of_images_per_parent.csv\", index=False)\n",
    "ten_most_images = number_of_images_per_parent.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Parent  Number of Images\n",
      "50        Person             46552\n",
      "15      Clothing             36380\n",
      "52         Plant             25566\n",
      "34    Human body             21700\n",
      "69          Tree             17804\n",
      "40  Land vehicle             10122\n",
      "28      Footwear              7648\n",
      "12           Car              5936\n",
      "2      Auto part              5142\n",
      "['Person' 'Clothing' 'Plant' 'Human body' 'Tree' 'Land vehicle' 'Footwear' 'Car' 'Auto part']\n"
     ]
    }
   ],
   "source": [
    "for index, row in number_of_images_per_parent.iterrows():\n",
    "    parent = row[\"Parent\"]\n",
    "    if parent not in pre_rec_filter[\"Class\"].values:\n",
    "        number_of_images_per_parent = number_of_images_per_parent.drop(index)\n",
    "        continue\n",
    "\n",
    "for index, row in number_of_images_per_parent.iterrows():\n",
    "    if row[\"Parent\"] == \"Building\":\n",
    "        number_of_images_per_parent = number_of_images_per_parent.drop(index)\n",
    "    elif row[\"Parent\"] == \"Furniture\":\n",
    "        number_of_images_per_parent = number_of_images_per_parent.drop(index)\n",
    "    elif row[\"Parent\"] == \"Food\":\n",
    "        number_of_images_per_parent = number_of_images_per_parent.drop(index)\n",
    "        \n",
    "print(number_of_images_per_parent.head(9))\n",
    "classes_to_query = number_of_images_per_parent[\"Parent\"].head(9).values\n",
    "print(classes_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5142\n",
      "--------------------------------------------------\n",
      "8455\n",
      "--------------------------------------------------\n",
      "43196\n",
      "--------------------------------------------------\n",
      "43226\n",
      "--------------------------------------------------\n",
      "47713\n",
      "--------------------------------------------------\n",
      "49269\n",
      "--------------------------------------------------\n",
      "56473\n",
      "--------------------------------------------------\n",
      "73749\n",
      "--------------------------------------------------\n",
      "73833\n",
      "--------------------------------------------------\n",
      "73833\n"
     ]
    }
   ],
   "source": [
    "actual_ground_truth = []  \n",
    "for index, row in child_map.iterrows():\n",
    "    parent = row[\"Parent\"]\n",
    "    if parent in classes_to_query:\n",
    "        children = row[\"Child\"]\n",
    "        children.append(parent)\n",
    "        all_images = get_image_in_ground_truth(children)\n",
    "        if all_images:\n",
    "            for image in all_images:\n",
    "                if image not in actual_ground_truth:\n",
    "                    actual_ground_truth.append(image)\n",
    "    \n",
    "        print(len(actual_ground_truth))\n",
    "        print(\"-\"*50)\n",
    "\n",
    "print(len(actual_ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_in_ground_truth_small(classes_list):\n",
    "    image_ids = []\n",
    "    for index, row in object_detection.iterrows():\n",
    "        for class_name in classes_list:\n",
    "            if row[\"Description\"].count(class_name) > 0:\n",
    "                image_ids.append(row[\"ImageID\"])\n",
    "                break\n",
    "    if image_ids:\n",
    "        return image_ids\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_in_ground_truth_small(image_id):\n",
    "    for index, row in object_detection.iterrows():\n",
    "        if row[\"ImageID\"] == image_id:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  Auto part\n",
      "Precision:  0.6525511975008678\n",
      "Recall:  0.7312329832749903\n",
      "False Positive Rate:  0.02914501171914807\n",
      "True Positive:  3760\n",
      "False Positive:  2002\n",
      "Total:  5142\n",
      "Output:  5762\n",
      "__________________________________________________\n",
      "Class:  Car\n",
      "Precision:  0.8087472201630838\n",
      "Recall:  0.9189690026954178\n",
      "False Positive Rate:  0.018999366687777075\n",
      "True Positive:  5455\n",
      "False Positive:  1290\n",
      "Total:  5936\n",
      "Output:  6745\n",
      "__________________________________________________\n",
      "Class:  Clothing\n",
      "Precision:  0.8410331438861066\n",
      "Recall:  0.8216602528862013\n",
      "False Positive Rate:  0.15085573919312203\n",
      "True Positive:  29892\n",
      "False Positive:  5650\n",
      "Total:  36380\n",
      "Output:  35542\n",
      "__________________________________________________\n",
      "Class:  Footwear\n",
      "Precision:  0.6752136752136753\n",
      "Recall:  0.7333943514644351\n",
      "False Positive Rate:  0.040764523683614114\n",
      "True Positive:  5609\n",
      "False Positive:  2698\n",
      "Total:  7648\n",
      "Output:  8307\n",
      "__________________________________________________\n",
      "Class:  Human body\n",
      "Precision:  0.7658016682113068\n",
      "Recall:  0.7615668202764977\n",
      "False Positive Rate:  0.09694435386415515\n",
      "True Positive:  16526\n",
      "False Positive:  5054\n",
      "Total:  21700\n",
      "Output:  21580\n",
      "__________________________________________________\n",
      "Class:  Land vehicle\n",
      "Precision:  0.8944126704795424\n",
      "Recall:  0.8033985378383719\n",
      "False Positive Rate:  0.01506804162546499\n",
      "True Positive:  8132\n",
      "False Positive:  960\n",
      "Total:  10122\n",
      "Output:  9092\n",
      "__________________________________________________\n",
      "Class:  Person\n",
      "Precision:  0.9278665217027683\n",
      "Recall:  0.9532995360027496\n",
      "False Positive Rate:  0.12646163996920934\n",
      "True Positive:  44378\n",
      "False Positive:  3450\n",
      "Total:  46552\n",
      "Output:  47828\n",
      "__________________________________________________\n",
      "Class:  Plant\n",
      "Precision:  0.8439925750928113\n",
      "Recall:  0.7825236642415708\n",
      "False Positive Rate:  0.07661549298692688\n",
      "True Positive:  20006\n",
      "False Positive:  3698\n",
      "Total:  25566\n",
      "Output:  23704\n",
      "__________________________________________________\n",
      "Class:  Tree\n",
      "Precision:  0.8015415296717512\n",
      "Recall:  0.8352617389350707\n",
      "False Positive Rate:  0.06571596851630405\n",
      "True Positive:  14871\n",
      "False Positive:  3682\n",
      "Total:  17804\n",
      "Output:  18553\n",
      "__________________________________________________\n",
      "Average Precision Any:  0.8012400224357683\n",
      "Average Recall Any:  0.8157007652905894\n",
      "Average False Positive Rate:  0.06895223758285796\n"
     ]
    }
   ],
   "source": [
    "# list_precision = []\n",
    "# list_recall = []\n",
    "list_precision_any = []\n",
    "list_recall_any = []\n",
    "list_false_positive_rate = []\n",
    "pre_rec_single_class_pd = pd.DataFrame(columns=[\"Class\", \"Precision\", \"Recall\", \"False Positive Rate\"])\n",
    "ground_truth_len = len(actual_ground_truth)\n",
    "\n",
    "for index, row in child_map.iterrows():\n",
    "    parent_class = row[\"Parent\"]\n",
    "\n",
    "    if parent_class not in classes_to_query:\n",
    "        continue\n",
    "    \n",
    "    child_class = row[\"Child\"]\n",
    "    child_class.append(row[\"Parent\"])\n",
    "    \n",
    "    child_class = sorted(child_class)\n",
    "    \n",
    "    all_images = get_image_in_ground_truth(child_class)\n",
    "    \n",
    "    output_images_any = query_images_any(child_class)\n",
    "\n",
    "    if all_images is None or output_images_any is None:\n",
    "        continue\n",
    "\n",
    "    if len(all_images) == 0 or len(output_images_any) == 0:\n",
    "        continue\n",
    "\n",
    "    actual_negative = ground_truth_len - len(all_images)\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "\n",
    "    for image_id in output_images_any:\n",
    "        if image_id in all_images:\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            false_positive += 1\n",
    "\n",
    "    true_negative = actual_negative - false_positive\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    recall = true_positive / len(all_images)\n",
    "    fpr = false_positive / actual_negative\n",
    "\n",
    "    print(\"Class: \", parent_class)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"False Positive Rate: \", fpr)\n",
    "    print(\"True Positive: \", true_positive)\n",
    "    print(\"False Positive: \", false_positive)\n",
    "    print(\"Total: \", len(all_images))\n",
    "    print(\"Output: \", len(output_images_any))\n",
    "    print(\"_\"*50)\n",
    "\n",
    "    list_precision_any.append(precision)\n",
    "    list_recall_any.append(recall)\n",
    "    list_false_positive_rate.append(fpr)\n",
    "    pre_rec_single_class_pd.loc[len(pre_rec_single_class_pd)] = [parent_class, precision, recall, fpr]\n",
    "\n",
    "# print(\"Average Precision: \", np.mean(list_precision))\n",
    "# print(\"Average Recall: \", np.mean(list_recall))\n",
    "\n",
    "print(\"Average Precision Any: \", np.mean(list_precision_any))\n",
    "print(\"Average Recall Any: \", np.mean(list_recall_any))\n",
    "print(\"Average False Positive Rate: \", np.mean(list_false_positive_rate))\n",
    "## add average precision and recall to pre_rec_single_class_pd\n",
    "# pre_rec_single_class_pd.loc[len(pre_rec_single_class_pd)] = [\"Average\", np.mean(list_precision_any), np.mean(list_recall_any), np.mean(list_false_positive_rate)]\n",
    "# pre_rec_single_class_pd.to_csv(\"pre_rec_single_class_any_with_fpr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_rec_single_class_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class  Precision    Recall\n",
      "0     Aircraft   0.877622  0.908323\n",
      "1       Animal   0.901511  0.192765\n",
      "2    Auto part   0.652551  0.731233\n",
      "3  Baked goods   0.809035  0.471856\n",
      "4         Ball   0.737475  0.696970\n",
      "(77, 3)\n"
     ]
    }
   ],
   "source": [
    "precision_recall_single_class = pd.read_csv(\"pre_rec_single_class_any.csv\")\n",
    "print(precision_recall_single_class.head())\n",
    "print(precision_recall_single_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop row that has pre or recall less than 0.5\n",
    "precision_recall_single_class = precision_recall_single_class.drop(precision_recall_single_class[(precision_recall_single_class[\"Precision\"] < 0.5) | (precision_recall_single_class[\"Recall\"] < 0.5)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class  Precision    Recall\n",
      "71      Turtle   0.781250  0.833333\n",
      "72   Vegetable   0.799205  0.562238\n",
      "74  Watercraft   0.824324  0.853644\n",
      "75      Weapon   0.713528  0.652913\n",
      "76     Average   0.744093  0.619837\n",
      "(57, 3)\n"
     ]
    }
   ],
   "source": [
    "print(precision_recall_single_class.tail())\n",
    "print(precision_recall_single_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 3)\n",
      "         Class  Precision    Recall\n",
      "70    Trousers   0.526421  0.624406\n",
      "71      Turtle   0.781250  0.833333\n",
      "72   Vegetable   0.799205  0.562238\n",
      "74  Watercraft   0.824324  0.853644\n",
      "75      Weapon   0.713528  0.652913\n"
     ]
    }
   ],
   "source": [
    "precision_recall_single_class = precision_recall_single_class.drop(precision_recall_single_class[precision_recall_single_class[\"Class\"] == \"Average\"].index)\n",
    "print(precision_recall_single_class.shape)\n",
    "print(precision_recall_single_class.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision:  0.755617985855299\n",
      "Average Recall:  0.7292268225094621\n",
      "         Class  Precision    Recall\n",
      "70    Trousers   0.526421  0.624406\n",
      "71      Turtle   0.781250  0.833333\n",
      "72   Vegetable   0.799205  0.562238\n",
      "74  Watercraft   0.824324  0.853644\n",
      "75      Weapon   0.713528  0.652913\n"
     ]
    }
   ],
   "source": [
    "copy_precision_recall_single_class = precision_recall_single_class.copy()\n",
    "average_precision = np.mean(copy_precision_recall_single_class[\"Precision\"])\n",
    "average_recall = np.mean(copy_precision_recall_single_class[\"Recall\"])\n",
    "print(\"Average Precision: \", average_precision)\n",
    "print(\"Average Recall: \", average_recall)\n",
    "copy_precision_recall_single_class.loc[len(copy_precision_recall_single_class)] = [\"Average\", average_precision, average_recall]\n",
    "print(copy_precision_recall_single_class.tail())\n",
    "copy_precision_recall_single_class.to_csv(\"pre_rec_single_class_any_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate True Positives Rate (TPR) and False Positives Rate (FPR) into new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class  Precision    Recall  False Positive Rate\n",
      "0     Aircraft   0.877622  0.908323             0.001089\n",
      "1       Animal   0.901511  0.192765             0.002304\n",
      "2    Auto part   0.652551  0.731233             0.021730\n",
      "3  Baked goods   0.809035  0.471856             0.000964\n",
      "4         Ball   0.737475  0.696970             0.001354\n"
     ]
    }
   ],
   "source": [
    "precision_recall_fpr = pd.read_csv(\"pre_rec_single_class_any_with_fpr.csv\")\n",
    "print(precision_recall_fpr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 4)\n",
      "         Class  Precision    Recall  False Positive Rate\n",
      "71      Turtle   0.781250  0.833333             0.000216\n",
      "72   Vegetable   0.799205  0.562238             0.001046\n",
      "74  Watercraft   0.824324  0.853644             0.003265\n",
      "75      Weapon   0.713528  0.652913             0.001115\n",
      "76     Average   0.744093  0.619837             0.008089\n"
     ]
    }
   ],
   "source": [
    "precision_recall_fpr = precision_recall_fpr.drop(precision_recall_fpr[(precision_recall_fpr[\"Precision\"] < 0.5) | (precision_recall_fpr[\"Recall\"] < 0.5)].index)\n",
    "print(precision_recall_fpr.shape)\n",
    "print(precision_recall_fpr.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 4)\n",
      "         Class  Precision    Recall  False Positive Rate\n",
      "70    Trousers   0.526421  0.624406             0.012431\n",
      "71      Turtle   0.781250  0.833333             0.000216\n",
      "72   Vegetable   0.799205  0.562238             0.001046\n",
      "74  Watercraft   0.824324  0.853644             0.003265\n",
      "75      Weapon   0.713528  0.652913             0.001115\n"
     ]
    }
   ],
   "source": [
    "precision_recall_fpr = precision_recall_fpr.drop(precision_recall_fpr[precision_recall_fpr[\"Class\"] == \"Average\"].index)\n",
    "precision_recall_fpr.reindex()\n",
    "print(precision_recall_fpr.shape)\n",
    "print(precision_recall_fpr.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class  Precision    Recall  False Positive Rate\n",
      "70    Trousers   0.526421  0.624406             0.012431\n",
      "71      Turtle   0.781250  0.833333             0.000216\n",
      "72   Vegetable   0.799205  0.562238             0.001046\n",
      "74  Watercraft   0.824324  0.853644             0.003265\n",
      "75      Weapon   0.713528  0.652913             0.001115\n"
     ]
    }
   ],
   "source": [
    "precision_recall_fpr.loc[len(precision_recall_fpr)] = [\"Average\", np.mean(precision_recall_fpr[\"Precision\"]), np.mean(precision_recall_fpr[\"Recall\"]), np.mean(precision_recall_fpr[\"False Positive Rate\"])]\n",
    "print(precision_recall_fpr.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_fpr.to_csv(\"pre_rec_single_class_any_filtered_with_fpr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision:  0.662120942963803\n",
      "Average Recall:  0.5520499073785102\n"
     ]
    }
   ],
   "source": [
    "pre_rec = pd.read_csv(\"precision_recall_single_class.csv\")\n",
    "\n",
    "for index, row in pre_rec.iterrows():\n",
    "    if row[\"Precision\"] == 0 and row[\"Recall\"] == 0:\n",
    "        pre_rec.drop(index, inplace=True)\n",
    "\n",
    "print(\"Average Precision: \", pre_rec[\"Precision\"].mean())\n",
    "print(\"Average Recall: \", pre_rec[\"Recall\"].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
